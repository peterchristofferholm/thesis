\chapter{Conclusions and Future Perspectives}
\label{chap:conclusions}
\section{Objective 1}

As outlined in \cref{chap:data-foundation}, 
the studies presented in this thesis draws on hospital data from 
more than \num{2.6} million individuals, which originates from
combination of different data sources, including
electronic health records, national registries, 
and clinical quality databases.
In the context of this thesis project,
a major challenge have been
processing, combinining, cleaning, and 
organizing these diverse sources of data
into curated datasets appropriate for 
\ac{ML} applications.






\begin{enumerate}
    \item 
        From a comprehensive database including 
        hospital data on over \num{2.6} million individuals 

        with data 
        originating from electronic health records and
        national and clinical registries, extract and curate 
        high-quality data and setup \ac{ML} experiments and analyses.
        This includes:
    \begin{enumerate}
        \item Writing data-processing code to 
            consolidate, clean, and organize heterogeneous
            data from various sources.
        \item Ensuring the maintenance of robust scientific software 
            engineering practices, including version control, workflow
            managers, and containerization for reproducibility.
        \item Creating definition algorithms for the precise identification of 
            patient populations, disease onset, and clinical outcomes.
    \end{enumerate}
\end{enumerate}

By leveraging a large-scale electronic health database encompassing over
\num{2.6} million individuals, this research has successfully navigated the
complexities of data extraction, cleaning, and organization, while maintaining
rigorous scientific software engineering practices. These efforts have resulted
in the creation of robust, reproducible data-processing pipelines and
definition algorithms, essential for accurate patient identification and
clinical outcome analysis.

Electronical health records are a rich source of health data,
and can be used to find connections between risk factors and diseases.

Precision medicine is prevention and treatment approaches

that takes individual variation into account.


Challenges in developing machine learning models from electronic health records
includes syntactic interoperability, 
which specifies the format and structure of the data.
Many different interopability formats exists, 
but their adoption varies considerably.

Benefits of interopable digital health data
~\autocite{lehneWhy2019}.

\begin{itemize}
    \item Large-scale observational studies.
    \item Less time spend on data cleaning and pre-processing.
    \item Interoperable exchange format could further cross-institutional
    and international collaboration, which would make it easier 
    to reproduce and externally validate e.g. prognostic applications.
    In the case of rare diseases with very limited number of patients, 
    international pooling of data could enable analysis
    that otherwise would not be possible.
    \item Faster research and development process.
    \item If data is known to conform to a well-defined format,
    computer software can be written without explicit access to the data.
    This solve many issues related to sensitive data or
    data that are otherwise subject to strict data protection regulations.
\end{itemize}

Healthcare data are usually private and scattered across various applications,
which makes it difficult to share data and generate robust results 
that translate to different and diverse populations.

AI approaches rely on data that accurately represent
the real-life distribution of the underlying problem.
We can not exclusively rely on data that have been carefully curated 
from few and often very similar sources. 
In order to capture subtle relationships 
between health and disease patterns,
we need to include many and diverse cases~%
\autocite{riekeFuture2020}.

