@article{aalenEmpirical1978,
  title = {An {{Empirical Transition Matrix}} for {{Non-Homogeneous Markov Chains Based}} on {{Censored Observations}}},
  author = {Aalen, Odd O. and Johansen, Søren},
  date = {1978},
  journaltitle = {Scandinavian Journal of Statistics},
  volume = {5},
  number = {3},
  pages = {141--150},
  publisher = {{[Board of the Foundation of the Scandinavian Journal of Statistics, Wiley]}},
  issn = {0303-6898},
  url = {https://www.jstor.org/stable/4615704},
  urldate = {2023-11-08},
  abstract = {A product limit estimator is suggested for the transition probabilities of a non-homogeneous Markov chain with finitely many states. The estimator is expressed as a product integral and its properties are studied by means of the theory of square integrable martingales.},
  file = {C:\Users\sdp490\Zotero\storage\JYVEQ5DP\Aalen and Johansen - 1978 - An Empirical Transition Matrix for Non-Homogeneous.pdf}
}

@online{aasExplaining2020,
  title = {Explaining Individual Predictions When Features Are Dependent: {{More}} Accurate Approximations to {{Shapley}} Values},
  shorttitle = {Explaining Individual Predictions When Features Are Dependent},
  author = {Aas, Kjersti and Jullum, Martin and Løland, Anders},
  date = {2020-02-06},
  eprint = {1903.10464},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1903.10464},
  urldate = {2023-11-03},
  abstract = {Explaining complex or seemingly simple machine learning models is an important practical problem. We want to explain individual predictions from a complex machine learning model by learning simple, interpretable explanations. Shapley values is a game theoretic concept that can be used for this purpose. The Shapley value framework has a series of desirable theoretical properties, and can in principle handle any predictive model. Kernel SHAP is a computationally efficient approximation to Shapley values in higher dimensions. Like several other existing methods, this approach assumes that the features are independent, which may give very wrong explanations. This is the case even if a simple linear model is used for predictions. In this paper, we extend the Kernel SHAP method to handle dependent features. We provide several examples of linear and non-linear models with various degrees of feature dependence, where our method gives more accurate approximations to the true Shapley values. We also propose a method for aggregating individual Shapley values, such that the prediction can be explained by groups of dependent variables.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\X7FN6KBX\\Aas et al. - 2020 - Explaining individual predictions when features ar.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\5PIJGP9D\\1903.html}
}

@article{adesCardiac2001,
  title = {Cardiac {{Rehabilitation}} and {{Secondary Prevention}} of {{Coronary Heart Disease}}},
  author = {Ades, Philip A.},
  date = {2001-09-20},
  journaltitle = {New England Journal of Medicine},
  volume = {345},
  number = {12},
  eprint = {11565523},
  eprinttype = {pmid},
  pages = {892--902},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJMra001529},
  abstract = {Coronary heart disease is the leading cause of death in the United States among men and women.1 It is also a major cause of physical disability, particularly in the rapidly growing population of elderly persons.2,3 In 1997, acute myocardial infarction was diagnosed in 1.1 million Americans, and 800,000 patients underwent coronary revascularization.1 The prevention of subsequent coronary events and the maintenance of physical functioning in such patients are major challenges in preventive care. Cardiac-rehabilitation programs were first developed in the 1960s,4–6 once the benefits of ambulation during prolonged hospitalization for coronary events had been recognized.7 After discharge from . . .}
}

@inproceedings{akibaOptuna2019,
  title = {Optuna: {{A Next-generation Hyperparameter Optimization Framework}}},
  shorttitle = {Optuna},
  author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
  date = {2019-07-25},
  pages = {2623--2631},
  publisher = {{ACM}},
  location = {{Anchorage AK USA}},
  doi = {10.1145/3292500.3330701},
  eventtitle = {{{KDD}} '19: {{The}} 25th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  isbn = {978-1-4503-6201-6},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\G3FVXQ8S\Akiba et al. - 2019 - Optuna A Next-generation Hyperparameter Optimizat.pdf}
}

@article{austinIntroduction2016,
  title = {Introduction to the {{Analysis}} of {{Survival Data}} in the {{Presence}} of {{Competing Risks}}},
  author = {Austin, Peter C. and Lee, Douglas S. and Fine, Jason P.},
  date = {2016-02-09},
  journaltitle = {Circulation},
  volume = {133},
  number = {6},
  pages = {601--609},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIRCULATIONAHA.115.017719},
  abstract = {Competing risks occur frequently in the analysis of survival data. A competing risk is an event whose occurrence precludes the occurrence of the primary event of interest. In a study examining time to death attributable to cardiovascular causes, death attributable to noncardiovascular causes is a competing risk. When estimating the crude incidence of outcomes, analysts should use the cumulative incidence function, rather than the complement of the Kaplan-Meier survival function. The use of the Kaplan-Meier survival function results in estimates of incidence that are biased upward, regardless of whether the competing events are independent of one another. When fitting regression models in the presence of competing risks, researchers can choose from 2 different families of models: modeling the effect of covariates on the cause-specific hazard of the outcome or modeling the effect of covariates on the cumulative incidence function. The former allows one to estimate the effect of the covariates on the rate of occurrence of the outcome in those subjects who are currently event free. The latter allows one to estimate the effect of covariates on the absolute risk of the outcome over time. The former family of models may be better suited for addressing etiologic questions, whereas the latter model may be better suited for estimating a patient’s clinical prognosis. We illustrate the application of these methods by examining cause-specific mortality in patients hospitalized with heart failure. Statistical software code in both R and SAS is provided.},
  keywords = {cumulative incidence function,{data interpretation, statistical},incidence,{models, statistical},proportional hazards models,risk assessment,survival analysis},
  file = {C:\Users\sdp490\Zotero\storage\YEFHQGIS\Austin et al. - 2016 - Introduction to the Analysis of Survival Data in t.pdf}
}

@article{bergstraRandom2012,
  title = {Random {{Search}} for {{Hyper-Parameter Optimization}}},
  author = {Bergstra, James and Bengio, Yoshua},
  date = {2012},
  journaltitle = {Journal of Machine Learning Research},
  volume = {13},
  number = {10},
  pages = {281--305},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v13/bergstra12a.html},
  urldate = {2023-10-29},
  abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent "High Throughput" methods achieve surprising success−they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
  file = {C:\Users\sdp490\Zotero\storage\KZ2DG8CS\Bergstra and Bengio - 2012 - Random Search for Hyper-Parameter Optimization.pdf}
}

@article{biganzoliFeed1998,
  title = {Feed Forward Neural Networks for the Analysis of Censored Survival Data: A Partial Logistic Regression Approach},
  shorttitle = {Feed Forward Neural Networks for the Analysis of Censored Survival Data},
  author = {Biganzoli, Elia and Boracchi, Patrizia and Mariani, Luigi and Marubini, Ettore},
  date = {1998},
  journaltitle = {Statistics in Medicine},
  volume = {17},
  number = {10},
  pages = {1169--1186},
  issn = {1097-0258},
  doi = {10.1002/(SICI)1097-0258(19980530)17:10<1169::AID-SIM796>3.0.CO;2-D},
  abstract = {Flexible modelling in survival analysis can be useful both for exploratory and predictive purposes. Feed forward neural networks were recently considered for flexible non-linear modelling of censored survival data through the generalization of both discrete and continuous time models. We show that by treating the time interval as an input variable in a standard feed forward network with logistic activation and entropy error function, it is possible to estimate smoothed discrete hazards as conditional probabilities of failure. We considered an easily implementable approach with a fast selection criteria of the best configurations. Examples on data sets from two clinical trials are provided. The proposed artificial neural network (ANN) approach can be applied for the estimation of the functional relationships between covariates and time in survival data to improve model predictivity in the presence of complex prognostic relationships. © 1998 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\QA8QP2FL\(SICI)1097-0258(19980530)17101169AID-SIM7963.0.html}
}

@book{bishopNeural1995,
  title = {Neural {{Networks}} for {{Pattern Recognition}}},
  author = {Bishop, Christopher M.},
  date = {1995-11-23},
  eprint = {T0S0BgAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Clarendon Press}},
  abstract = {This book provides the first comprehensive treatment of feed-forward neural networks from the perspective of statistical pattern recognition. After introducing the basic concepts of pattern recognition, the book describes techniques for modelling probability density functions, and discusses the properties and relative merits of the multi-layer perceptron and radial basis function network models. It also motivates the use of various forms of error functions, and reviews the principal algorithms for error function minimization. As well as providing a detailed discussion of learning and generalization in neural networks, the book also covers the important topics of data processing, feature extraction, and prior knowledge. The book concludes with an extensive treatment of Bayesian techniques and their applications to neural networks.},
  isbn = {978-0-19-853864-6},
  langid = {english},
  pagetotal = {501},
  keywords = {Computers / Artificial Intelligence / General,Computers / Data Science / Neural Networks,Computers / Optical Data Processing,Mathematics / Probability \& Statistics / General}
}

@article{brownUse1997,
  title = {On the Use of Artificial Neural Networks for the Analysis of Survival Data},
  author = {Brown, S.F. and Branford, A.J. and Moran, W.},
  date = {1997-09},
  journaltitle = {IEEE Transactions on Neural Networks},
  volume = {8},
  number = {5},
  pages = {1071--1077},
  issn = {1941-0093},
  doi = {10.1109/72.623209},
  abstract = {Artificial neural networks are a powerful tool for analyzing data sets where there are complicated nonlinear interactions between the measured inputs and the quantity to be predicted. We show that the results obtained when neural networks are applied to survival data depend critically on the treatment of censoring in the data. When the censoring is modeled correctly, neural networks are a robust model independent technique for the analysis of very large sets of survival data.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}}},
  keywords = {Artificial neural networks,Data analysis,Diseases,Independent component analysis,Neural networks,Particle measurements,Robustness,Statistical analysis,Statistics,Time measurement},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\F5XAYN5M\\Brown et al. - 1997 - On the use of artificial neural networks for the a.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\E48Q87MT\\623209.html}
}

@article{byrne20232023,
  title = {2023 {{ESC Guidelines}} for the Management of Acute Coronary Syndromes},
  shorttitle = {2023 {{ESC Guidelines}} for the Management of Acute Coronary Syndromes},
  author = {Byrne, Robert A and Rossello, Xavier and Coughlan, J J and Barbato, Emanuele and Berry, Colin and Chieffo, Alaide and Claeys, Marc J and Dan, Gheorghe-Andrei and Dweck, Marc R and Galbraith, Mary and Gilard, Martine and Hinterbuchner, Lynne and Jankowska, Ewa A and Jüni, Peter and Kimura, Takeshi and Kunadian, Vijay and Leosdottir, Margret and Lorusso, Roberto and Pedretti, Roberto F E and Rigopoulos, Angelos G and Rubini Gimenez, Maria and Thiele, Holger and Vranckx, Pascal and Wassmann, Sven and Wenger, Nanette Kass and Ibanez, Borja and {ESC Scientific Document Group}},
  date = {2023-08-25},
  journaltitle = {European Heart Journal},
  shortjournal = {European Heart Journal},
  pages = {ehad191},
  issn = {0195-668X},
  doi = {10.1093/eurheartj/ehad191},
  file = {C:\Users\sdp490\Zotero\storage\QRTH4DEH\Byrne et al. - 2023 - 2023 ESC Guidelines for the management of acute co.pdf}
}

@book{charniakIntroduction2019,
  title = {Introduction to {{Deep Learning}}},
  author = {Charniak, Eugene},
  date = {2019-01-29},
  edition = {Illustrated},
  publisher = {{The MIT Press}},
  location = {{Cambridge, Massachusetts}},
  abstract = {A project-based guide to the basics of deep learning.This concise, project-driven guide to deep learning takes readers through a series of program-writing tasks that introduce them to the use of deep learning in such areas of artificial intelligence as computer vision, natural-language processing, and reinforcement learning. The author, a longtime artificial intelligence researcher specializing in natural-language processing, covers feed-forward neural nets, convolutional neural nets, word embeddings, recurrent neural nets, sequence-to-sequence learning, deep reinforcement learning, unsupervised models, and other fundamental concepts and techniques. Students and practitioners learn the basics of deep learning by working through programs in Tensorflow, an open-source machine learning framework. “I find I learn computer science material best by sitting down and writing programs,” the author writes, and the book reflects this approach.Each chapter includes a programming project, exercises, and references for further reading. An early chapter is devoted to Tensorflow and its interface with Python, the widely used programming language. Familiarity with linear algebra, multivariate calculus, and probability and statistics is required, as is a rudimentary knowledge of programming in Python. The book can be used in both undergraduate and graduate courses; practitioners will find it an essential reference.},
  isbn = {978-0-262-03951-2},
  langid = {english},
  pagetotal = {192}
}

@book{cholletDeep2021,
  title = {Deep {{Learning}} with {{Python}}},
  author = {Chollet, Francois},
  date = {2021-12-07},
  edition = {2},
  eprint = {mjVKEAAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Manning}},
  abstract = {Unlock the groundbreaking advances of deep learning with this extensively revised edition of the bestselling original. Learn directly from the creator of Keras and master practical Python deep learning techniques that are easy to apply in the real world.In Deep Learning with Python, Second Edition you will learn:  Deep learning from first principles Image classification \& image segmentation Timeseries forecasting Text classification and machine translation Text generation, neural style transfer, and image generation  Deep Learning with Python has taught thousands of readers how to put the full capabilities of deep learning into action. This extensively revised second edition introduces deep learning using Python and Keras, and is loaded with insights for both novice and experienced ML practitioners. You’ll learn practical techniques that are easy to apply in the real world, and important theory for perfecting neural networks.  Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications.  About the technology Recent innovations in deep learning unlock exciting new software capabilities like automated language translation, image recognition, and more. Deep learning is becoming essential knowledge for every software developer, and modern tools like Keras and TensorFlow put it within your reach, even if you have no background in mathematics or data science.   About the book Deep Learning with Python, Second Edition introduces the field of deep learning using Python and the powerful Keras library. In this new edition, Keras creator François Chollet offers insights for both novice and experienced machine learning practitioners. As you move through this book, you’ll build your understanding through intuitive explanations, crisp illustrations, and clear examples. You’ll pick up the skills to start developing deep-learning applications.  What's inside  Deep learning from first principles Image classification and image segmentation Time series forecasting Text classification and machine translation Text generation, neural style transfer, and image generation  About the reader For readers with intermediate Python skills. No previous experience with Keras, TensorFlow, or machine learning is required.  About the author François Chollet is a software engineer at Google and creator of the Keras deep-learning library.  Table of Contents 1 What is deep learning? 2 The mathematical building blocks of neural networks 3 Introduction to Keras and TensorFlow 4 Getting started with neural networks: Classification and regression 5 Fundamentals of machine learning 6 The universal workflow of machine learning 7 Working with Keras: A deep dive 8 Introduction to deep learning for computer vision 9 Advanced deep learning for computer vision 10 Deep learning for timeseries 11 Deep learning for text 12 Generative deep learning 13 Best practices for the real world 14 Conclusions},
  isbn = {978-1-63835-009-5},
  langid = {english},
  pagetotal = {502},
  keywords = {Computers / Data Science / Machine Learning,Computers / Data Science / Neural Networks,Computers / Languages / Python}
}

@article{clarkMetaAnalysis2005,
  title = {Meta-{{Analysis}}: {{Secondary Prevention Programs}} for {{Patients}} with {{Coronary Artery Disease}}},
  shorttitle = {Meta-{{Analysis}}},
  author = {Clark, Alexander M. and Hartling, Lisa and Vandermeer, Ben and McAlister, Finlay A.},
  date = {2005-11},
  journaltitle = {Annals of Internal Medicine},
  shortjournal = {Ann Intern Med},
  volume = {143},
  number = {9},
  pages = {659--672},
  publisher = {{American College of Physicians}},
  issn = {0003-4819},
  doi = {10.7326/0003-4819-143-9-200511010-00010}
}

@article{collinsNew2015,
  title = {A {{New Initiative}} on {{Precision Medicine}}},
  author = {Collins, Francis S. and Varmus, Harold},
  date = {2015-02-26},
  journaltitle = {New England Journal of Medicine},
  volume = {372},
  number = {9},
  eprint = {25635347},
  eprinttype = {pmid},
  pages = {793--795},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJMp1500523},
  file = {C:\Users\sdp490\Zotero\storage\YRKTA2QI\Collins and Varmus - 2015 - A New Initiative on Precision Medicine.pdf}
}

@article{coudrayClassification2018,
  title = {Classification and Mutation Prediction from Non–Small Cell Lung Cancer Histopathology Images Using Deep Learning},
  author = {Coudray, Nicolas and Ocampo, Paolo Santiago and Sakellaropoulos, Theodore and Narula, Navneet and Snuderl, Matija and Fenyö, David and Moreira, Andre L. and Razavian, Narges and Tsirigos, Aristotelis},
  date = {2018-10},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {24},
  number = {10},
  pages = {1559--1567},
  publisher = {{Nature Publishing Group}},
  issn = {1546-170X},
  doi = {10.1038/s41591-018-0177-5},
  abstract = {Visual inspection of histopathology slides is one of the main methods used by pathologists to assess the stage, type and subtype of lung tumors. Adenocarcinoma (LUAD) and squamous cell carcinoma (LUSC) are the most prevalent subtypes of lung cancer, and their distinction requires visual inspection by an experienced pathologist. In this study, we trained a deep convolutional neural network (inception v3) on whole-slide images obtained from The Cancer Genome Atlas to accurately and automatically classify them into LUAD, LUSC or normal lung tissue. The performance of our method is comparable to that of pathologists, with an average area under the curve (AUC) of 0.97. Our model was validated on independent datasets of frozen tissues, formalin-fixed paraffin-embedded tissues and biopsies. Furthermore, we trained the network to predict the ten most commonly mutated genes in LUAD. We found that six of them—STK11, EGFR, FAT1, SETBP1, KRAS and TP53—can be predicted from pathology images, with AUCs from 0.733 to 0.856 as measured on a held-out population. These findings suggest that deep-learning models can assist pathologists in the detection of cancer subtype or gene mutations. Our approach can be applied to any cancer type, and the code is available at https://github.com/ncoudray/DeepPATH.},
  issue = {10},
  langid = {english},
  keywords = {Machine learning},
  file = {C:\Users\sdp490\Zotero\storage\MP364ABQ\Coudray et al. - 2018 - Classification and mutation prediction from non–sm.pdf}
}

@article{coxRegression1972,
  title = {Regression {{Models}} and {{Life-Tables}}},
  author = {Cox, D. R.},
  date = {1972},
  journaltitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {34},
  number = {2},
  pages = {187--220},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {0035-9246},
  url = {https://www.jstor.org/stable/2985181},
  urldate = {2023-11-07},
  abstract = {The analysis of censored failure times is considered. It is assumed that on each individual are available values of one or more explanatory variables. The hazard function (age-specific failure rate) is taken to be a function of the explanatory variables and unknown regression coefficients multiplied by an arbitrary and unknown function of time. A conditional likelihood is obtained, leading to inferences about the unknown regression coefficients. Some generalizations are outlined.},
  file = {C:\Users\sdp490\Zotero\storage\DJEDSRA9\Cox - 1972 - Regression Models and Life-Tables.pdf}
}

@article{dainisCardiovascular2018,
  title = {Cardiovascular {{Precision Medicine}} in the {{Genomics Era}}},
  author = {Dainis, Alexandra M. and Ashley, Euan A.},
  date = {2018-04},
  journaltitle = {JACC: Basic to Translational Science},
  volume = {3},
  number = {2},
  pages = {313--326},
  publisher = {{American College of Cardiology Foundation}},
  doi = {10.1016/j.jacbts.2018.01.003},
  keywords = {genome sequencing,genomics,precision medicine,targeted therapeutics},
  file = {C:\Users\sdp490\Zotero\storage\V789XE8G\Dainis and Ashley - 2018 - Cardiovascular Precision Medicine in the Genomics .pdf}
}

@article{defauwClinically2018,
  title = {Clinically Applicable Deep Learning for Diagnosis and Referral in Retinal Disease},
  author = {De Fauw, Jeffrey and Ledsam, Joseph R. and Romera-Paredes, Bernardino and Nikolov, Stanislav and Tomasev, Nenad and Blackwell, Sam and Askham, Harry and Glorot, Xavier and O’Donoghue, Brendan and Visentin, Daniel and family=Driessche, given=George, prefix=van den, useprefix=true and Lakshminarayanan, Balaji and Meyer, Clemens and Mackinder, Faith and Bouton, Simon and Ayoub, Kareem and Chopra, Reena and King, Dominic and Karthikesalingam, Alan and Hughes, Cían O. and Raine, Rosalind and Hughes, Julian and Sim, Dawn A. and Egan, Catherine and Tufail, Adnan and Montgomery, Hugh and Hassabis, Demis and Rees, Geraint and Back, Trevor and Khaw, Peng T. and Suleyman, Mustafa and Cornebise, Julien and Keane, Pearse A. and Ronneberger, Olaf},
  date = {2018-09},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {24},
  number = {9},
  pages = {1342--1350},
  publisher = {{Nature Publishing Group}},
  issn = {1546-170X},
  doi = {10.1038/s41591-018-0107-6},
  abstract = {The volume and complexity of diagnostic imaging is increasing at a pace faster than the availability of human expertise to interpret it. Artificial intelligence has shown great promise in classifying two-dimensional photographs of some common diseases and typically relies on databases of millions of annotated images. Until now, the challenge of reaching the performance of expert clinicians in a real-world clinical pathway with three-dimensional diagnostic scans has remained unsolved. Here, we apply a novel deep learning architecture to a clinically heterogeneous set of three-dimensional optical coherence tomography scans from patients referred to a major eye hospital. We demonstrate performance in making a referral recommendation that reaches or exceeds that of experts on a range of sight-threatening retinal diseases after training on only 14,884 scans. Moreover, we demonstrate that the tissue segmentations produced by our architecture act as a device-independent representation; referral accuracy is maintained when using tissue segmentations from a different type of device. Our work removes previous barriers to wider clinical use without prohibitive training data requirements across multiple pathologies in a real-world setting.},
  issue = {9},
  langid = {english},
  keywords = {Diagnosis,Eye manifestations,Machine learning,Three-dimensional imaging},
  file = {C:\Users\sdp490\Zotero\storage\P5PXRBPB\De Fauw et al. - 2018 - Clinically applicable deep learning for diagnosis .pdf}
}

@article{dengComplexity1994,
  title = {On the {{Complexity}} of {{Cooperative Solution Concepts}}},
  author = {Deng, Xiaotie and Papadimitriou, Christos H.},
  date = {1994},
  journaltitle = {Mathematics of Operations Research},
  volume = {19},
  number = {2},
  pages = {257--266},
  publisher = {{INFORMS}},
  issn = {0364-765X},
  url = {https://www.jstor.org/stable/3690220},
  urldate = {2023-11-03},
  abstract = {We study from a complexity theoretic standpoint the various solution concepts arising in cooperative game theory. We use as a vehicle for this study a game in which the players are nodes of a graph with weights on the edges, and the value of a coalition is determined by the total weight of the edges contained in it. The Shapley value is always easy to compute. The core is easy to characterize when the game is convex, and is intractable (NP-complete) otherwise. Similar results are shown for the kernel, the nucleolus, the ε-core, and the bargaining set. As for the von Neumann-Morgenstern solution, we point out that its existence may not even be decidable. Many of these results generalize to the case in which the game is presented by a hypergraph with edges of size k {$>$} 2.},
  file = {C:\Users\sdp490\Zotero\storage\XPWZVGBI\Deng and Papadimitriou - 1994 - On the Complexity of Cooperative Solution Concepts.pdf}
}

@article{dorresteijnDevelopment2013,
  title = {Development and Validation of a Prediction Rule for Recurrent Vascular Events Based on a Cohort Study of Patients with Arterial Disease: The {{SMART}} Risk Score},
  shorttitle = {Development and Validation of a Prediction Rule for Recurrent Vascular Events Based on a Cohort Study of Patients with Arterial Disease},
  author = {Dorresteijn, Johannes A. N. and Visseren, Frank L. J. and Wassink, Annemarie M. J. and Gondrie, Martijn J. A. and Steyerberg, Ewout W. and Ridker, Paul M. and Cook, Nancy R. and family=Graaf, given=Yolanda, prefix=van der, useprefix=false and Group, on behalf of the SMART Study},
  date = {2013-06-15},
  journaltitle = {Heart},
  shortjournal = {Heart},
  volume = {99},
  number = {12},
  eprint = {23574971},
  eprinttype = {pmid},
  pages = {866--872},
  publisher = {{BMJ Publishing Group Ltd and British Cardiovascular Society}},
  issn = {1355-6037, 1468-201X},
  doi = {10.1136/heartjnl-2013-303640},
  abstract = {Objectives To enable risk stratification of patients with various types of arterial disease by the development and validation of models for prediction of recurrent vascular event risk based on vascular risk factors, imaging or both. Design Prospective cohort study. Setting University Medical Centre. Patients 5788 patients referred with various clinical manifestations of arterial disease between January 1996 and February 2010. Main outcome measures 788 recurrent vascular events (ie, myocardial infarction, stroke or vascular death) that were observed during 4.7 (IQR 2.3 to 7.7) years’ follow-up. Results Three Cox proportional hazards models for prediction of 10-year recurrent vascular event risk were developed based on age and sex in addition to clinical parameters (model A), carotid ultrasound findings (model B) or both (model C). Clinical parameters were medical history, current smoking, systolic blood pressure and laboratory biomarkers. In a separate part of the dataset, the concordance statistic of model A was 0.68 (95\% CI 0.64 to 0.71), compared to 0.64 (0.61 to 0.68) for model B and 0.68 (0.65 to 0.72) for model C. Goodness-of-fit and calibration of model A were adequate, also in separate subgroups of patients having coronary, cerebrovascular, peripheral artery or aneurysmal disease. Model A predicted {$<$}20\% risk in 59\% of patients, 20–30\% risk in 19\% and {$>$}30\% risk in 23\%. Conclusions Patients at high risk for recurrent vascular events can be identified based on readily available clinical characteristics.},
  langid = {english}
}

@article{drukerEfficacy2001,
  title = {Efficacy and Safety of a Specific Inhibitor of the {{BCR-ABL}} Tyrosine Kinase in Chronic Myeloid Leukemia},
  author = {Druker, B. J. and Talpaz, M. and Resta, D. J. and Peng, B. and Buchdunger, E. and Ford, J. M. and Lydon, N. B. and Kantarjian, H. and Capdeville, R. and Ohno-Jones, S. and Sawyers, C. L.},
  date = {2001-04-05},
  journaltitle = {The New England Journal of Medicine},
  shortjournal = {N Engl J Med},
  volume = {344},
  number = {14},
  eprint = {11287972},
  eprinttype = {pmid},
  pages = {1031--1037},
  issn = {0028-4793},
  doi = {10.1056/NEJM200104053441401},
  abstract = {BACKGROUND: BCR-ABL is a constitutively activated tyrosine kinase that causes chronic myeloid leukemia (CML). Since tyrosine kinase activity is essential to the transforming function of BCR-ABL, an inhibitor of the kinase could be an effective treatment for CML. METHODS: We conducted a phase 1, dose-escalating trial of STI571 (formerly known as CGP 57148B), a specific inhibitor of the BCR-ABL tyrosine kinase. STI571 was administered orally to 83 patients with CML in the chronic phase in whom treatment with interferon alfa had failed. Patients were successively assigned to 1 of 14 doses ranging from 25 to 1000 mg per day. RESULTS: Adverse effects of STI571 were minimal; the most common were nausea, myalgias, edema, and diarrhea. A maximal tolerated dose was not identified. Complete hematologic responses were observed in 53 of 54 patients treated with daily doses of 300 mg or more and typically occurred in the first four weeks of therapy. Of the 54 patients treated with doses of 300 mg or more, cytogenetic responses occurred in 29, including 17 (31 percent of the 54 patients who received this dose) with major responses (0 to 35 percent of cells in metaphase positive for the Philadelphia chromosome); 7 of these patients had complete cytogenetic remissions. CONCLUSIONS: STI571 is well tolerated and has significant antileukemic activity in patients with CML in whom treatment with interferon alfa had failed. Our results provide evidence of the essential role of BCR-ABL tyrosine kinase activity in CML and demonstrate the potential for the development of anticancer drugs based on the specific molecular abnormality present in a human cancer.},
  langid = {english},
  keywords = {Adult,Aged,Antineoplastic Agents,Benzamides,Blood Cell Count,{Dose-Response Relationship, Drug},Enzyme Inhibitors,Female,{Fusion Proteins, bcr-abl},Humans,Imatinib Mesylate,Interferon-alpha,{Leukemia, Myelogenous, Chronic, BCR-ABL Positive},Male,Middle Aged,Phosphorylation,Piperazines,Protein-Tyrosine Kinases,Pyrimidines,Recurrence,Remission Induction}
}

@article{estevaGuide2019,
  title = {A Guide to Deep Learning in Healthcare},
  author = {Esteva, Andre and Robicquet, Alexandre and Ramsundar, Bharath and Kuleshov, Volodymyr and DePristo, Mark and Chou, Katherine and Cui, Claire and Corrado, Greg and Thrun, Sebastian and Dean, Jeff},
  date = {2019-01},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {25},
  pages = {24--29},
  issn = {1546-170X},
  doi = {10.1038/s41591-018-0316-z},
  abstract = {Here we present deep-learning techniques for healthcare, centering our discussion on deep learning in computer vision, natural language processing, reinforcement learning, and generalized methods. We describe how these computational techniques can impact a few key areas of medicine and explore how to build end-to-end systems. Our discussion of computer vision focuses largely on medical imaging, and we describe the application of natural language processing to domains such as electronic health record data. Similarly, reinforcement learning is discussed in the context of robotic-assisted surgery, and generalized deep-learning methods for genomics are reviewed.},
  langid = {english},
  keywords = {Bioinformatics,Health care,Machine learning}
}

@article{falkPathogenesis2006,
  title = {Pathogenesis of {{Atherosclerosis}}},
  author = {Falk, Erling},
  date = {2006-04-18},
  journaltitle = {Journal of the American College of Cardiology},
  volume = {47},
  pages = {C7-C12},
  publisher = {{American College of Cardiology Foundation}},
  doi = {10.1016/j.jacc.2005.09.068},
  file = {C:\Users\sdp490\Zotero\storage\2QAQ5599\Falk - 2006 - Pathogenesis of Atherosclerosis.pdf}
}

@article{faraggiNeural1995,
  title = {A Neural Network Model for Survival Data},
  author = {Faraggi, David and Simon, Richard},
  date = {1995},
  journaltitle = {Statistics in Medicine},
  volume = {14},
  number = {1},
  pages = {73--82},
  issn = {1097-0258},
  doi = {10.1002/sim.4780140108},
  abstract = {Neural networks have received considerable attention recently, mostly by non-statisticians. They are considered by many to be very promising tools for classification and prediction. In this paper we present an approach to modelling censored survival data using the input—output relationship associated with a simple feed-forward neural network as the basis for a non-linear proportional hazards model. This approach can be extended to other models used with censored survival data. The proportional hazards neural network parameters are estimated using the method of maximum likelihood. These maximum likelihood based models can be compared, using readily available techniques such as the likelihood ratio test and the Akaike criterion. The neural network models are illustrated using data on the survival of men with prostatic carcinoma. A method of interpreting the neural network predictions based on the factorial contrasts is presented.},
  langid = {english}
}

@online{fotsoDeep2018,
  title = {Deep {{Neural Networks}} for {{Survival Analysis Based}} on a {{Multi-Task Framework}}},
  author = {Fotso, Stephane},
  date = {2018-01-16},
  eprint = {1801.05512},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1801.05512},
  urldate = {2023-11-16},
  abstract = {Survival analysis/time-to-event models are extremely useful as they can help companies predict when a customer will buy a product, churn or default on a loan, and therefore help them improve their ROI. In this paper, we introduce a new method to calculate survival functions using the Multi-Task Logistic Regression (MTLR) model as its base and a deep learning architecture as its core. Based on the Concordance index (C-index) and Brier score, this method outperforms the MTLR in all the experiments disclosed in this paper as well as the Cox Proportional Hazard (CoxPH) model when nonlinear dependencies are found.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\8HSFA2QT\\Fotso - 2018 - Deep Neural Networks for Survival Analysis Based o.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\T8RWJ7A8\\1801.html}
}

@article{foxMyth2020,
  title = {The Myth of ‘Stable’ Coronary Artery Disease},
  author = {Fox, Keith A. A. and Metra, Marco and Morais, João and Atar, Dan},
  date = {2020-01},
  journaltitle = {Nature Reviews Cardiology},
  shortjournal = {Nat Rev Cardiol},
  volume = {17},
  number = {1},
  pages = {9--21},
  publisher = {{Nature Publishing Group}},
  issn = {1759-5010},
  doi = {10.1038/s41569-019-0233-y},
  abstract = {Patients with known cardiovascular disease who have not had a recent acute event are often referred to as having stable coronary artery disease (CAD). The concept of ‘stable’ CAD is misleading for two important reasons: the continuing risks of cardiovascular events over the longer term and the diverse spectrum of powerful risk characteristics. The risks of cardiovascular events are frequently underestimated and continue to exist, despite current standards of care for secondary prevention, including lifestyle changes, optimal medical therapy, myocardial revascularization and the use of antiplatelet agents to limit thrombosis. In dispelling the myth of ‘stable’ CAD, we explore the pathophysiology of the disease and the relative contribution of plaque and systemic factors to cardiovascular events. A broader concept of the vulnerable patient, not just the vulnerable plaque, takes into account the diversity and future risks of atherothrombotic events. We also evaluate new and ongoing research into medical therapies aimed at further reducing the risks of cardiovascular events in patients with chronic — but not stable — atherothrombotic disease.},
  issue = {1},
  langid = {english},
  keywords = {Coronary artery disease and stable angina,Drug therapy,Preventive medicine,Risk factors},
  file = {C:\Users\sdp490\Zotero\storage\XWECRE2J\Fox et al. - 2020 - The myth of ‘stable’ coronary artery disease.pdf}
}

@article{frankEpidemiology2000,
  title = {Epidemiology. {{When}} an Entire Country Is a Cohort},
  author = {Frank, Lone},
  date = {2000-03-31},
  journaltitle = {Science (New York, N.Y.)},
  shortjournal = {Science},
  volume = {287},
  number = {5462},
  eprint = {10766613},
  eprinttype = {pmid},
  pages = {2398--2399},
  issn = {0036-8075},
  doi = {10.1126/science.287.5462.2398},
  langid = {english},
  keywords = {Biomedical and Behavioral Research,Cohort Studies,Confidentiality,{Databases, Factual},Denmark,Genetic Research,Humans,{Medical Records Systems, Computerized},Registries,Twin Studies as Topic}
}

@article{fusterPathogenesis1992,
  title = {The {{Pathogenesis}} of {{Coronary Artery Disease}} and the {{Acute Coronary Syndromes}}},
  author = {Fuster, Valentin and Badimon, Lina and Badimon, Juan J. and Chesebro, James H.},
  date = {1992-01-23},
  journaltitle = {New England Journal of Medicine},
  volume = {326},
  number = {4},
  eprint = {1727977},
  eprinttype = {pmid},
  pages = {242--250},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJM199201233260406},
  abstract = {IN the 19th century there were two major hypotheses to explain the pathogenesis of atherosclerosis: the "incrustation" hypothesis and the "lipid" hypothesis. The incrustation hypothesis of von Rokitansky,1 proposed in 1852 and modified by Duguid,2 suggested that intimal thickening resulted from fibrin deposition, with subsequent organization by fibroblasts and secondary lipid accumulation. The lipid hypothesis, proposed by Virchow3 in 1856, suggested that lipid in the arterial wall represented a transduction of blood lipid, which subsequently formed complexes with acid mucopolysaccharides; lipid accumulated in arterial walls because mechanisms of lipid deposition predominated over those of removal. The two hypotheses are now . . .}
}

@article{gensheimerScalable2019,
  title = {A Scalable Discrete-Time Survival Model for Neural Networks},
  author = {Gensheimer, Michael F. and Narasimhan, Balasubramanian},
  date = {2019-01-25},
  journaltitle = {PeerJ},
  volume = {7},
  pages = {e6257},
  doi = {10.7717/peerj.6257},
  abstract = {{$<$}jats:p{$>$}There is currently great interest in applying neural networks to prediction tasks in medicine. It is important for predictive models to be able to use survival data, where each patient has a known follow-up time and event/censoring indicator. This avoids information loss when training the model and enables generation of predicted survival curves. In this paper, we describe a discrete-time survival model that is designed to be used with neural networks, which we refer to as Nnet-survival. The model is trained with the maximum likelihood method using mini-batch stochastic gradient descent (SGD). The use of SGD enables rapid convergence and application to large datasets that do not fit in memory. The model is flexible, so that the baseline hazard rate and the effect of the input data on hazard probability can vary with follow-up time. It has been implemented in the Keras deep learning framework, and source code for the model and several examples is available online. We demonstrate the performance of the model on both simulated and real data and compare it to existing models Cox-nnet and Deepsurv.{$<$}/jats:p{$>$}},
  langid = {english},
  annotation = {This CSL Item was generated by Manubot v0.5.3 from its persistent identifier (standard\_id). standard\_id: doi:10.7717/peerj.6257 Loaded from an external bibliography file by Manubot. source\_bibliography: bibliography.csl.json original\_id: yunjBlQR}
}

@book{goodfellow2016deep,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016},
  publisher = {{MIT press}}
}

@article{gunningXAI2019,
  title = {{{XAI}}—{{Explainable}} Artificial Intelligence},
  author = {Gunning, David and Stefik, Mark and Choi, Jaesik and Miller, Timothy and Stumpf, Simone and Yang, Guang-Zhong},
  date = {2019-12-18},
  journaltitle = {Science Robotics},
  volume = {4},
  number = {37},
  pages = {eaay7120},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/scirobotics.aay7120},
  abstract = {Explainability is essential for users to effectively understand, trust, and manage powerful artificial intelligence applications.},
  file = {C:\Users\sdp490\Zotero\storage\Z2Q7A6C2\Gunning et al. - 2019 - XAI—Explainable artificial intelligence.pdf}
}

@article{handelmanEDoctor2018,
  title = {{{eDoctor}}: Machine Learning and the Future of Medicine},
  shorttitle = {{{eDoctor}}},
  author = {Handelman, G. S. and Kok, H. K. and Chandra, R. V. and Razavi, A. H. and Lee, M. J. and Asadi, H.},
  date = {2018-12},
  journaltitle = {Journal of Internal Medicine},
  shortjournal = {J Intern Med},
  volume = {284},
  number = {6},
  eprint = {30102808},
  eprinttype = {pmid},
  pages = {603--619},
  issn = {1365-2796},
  doi = {10.1111/joim.12822},
  abstract = {Machine learning (ML) is a burgeoning field of medicine with huge resources being applied to fuse computer science and statistics to medical problems. Proponents of ML extol its ability to deal with large, complex and disparate data, often found within medicine and feel that ML is the future for biomedical research, personalized medicine, computer-aided diagnosis to significantly advance global health care. However, the concepts of ML are unfamiliar to many medical professionals and there is untapped potential in the use of ML as a research tool. In this article, we provide an overview of the theory behind ML, explore the common ML algorithms used in medicine including their pitfalls and discuss the potential future of ML in medicine.},
  langid = {english},
  keywords = {Algorithms,artificial intelligence,{Decision Support Systems, Clinical},Forecasting,Humans,machine learning,Machine Learning,medicine,Medicine,Precision Medicine,supervised machine learning,Supervised Machine Learning,unsupervised machine learning,Unsupervised Machine Learning},
  file = {C:\Users\sdp490\Zotero\storage\Z3ZHSRG3\Handelman et al. - 2018 - eDoctor machine learning and the future of medici.pdf}
}

@article{hannunCardiologistlevel2019,
  title = {Cardiologist-Level Arrhythmia Detection and Classification in Ambulatory Electrocardiograms Using a Deep Neural Network},
  author = {Hannun, Awni Y. and Rajpurkar, Pranav and Haghpanahi, Masoumeh and Tison, Geoffrey H. and Bourn, Codie and Turakhia, Mintu P. and Ng, Andrew Y.},
  date = {2019-01},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {25},
  number = {1},
  pages = {65--69},
  publisher = {{Nature Publishing Group}},
  issn = {1546-170X},
  doi = {10.1038/s41591-018-0268-3},
  abstract = {Computerized electrocardiogram (ECG) interpretation plays a critical role in the clinical ECG workflow1. Widely available digital ECG data and the algorithmic paradigm of deep learning2 present an opportunity to substantially improve the accuracy and scalability of automated ECG analysis. However, a comprehensive evaluation of an end-to-end deep learning approach for ECG analysis across a wide variety of diagnostic classes has not been previously reported. Here, we develop a deep neural network (DNN) to classify 12 rhythm classes using 91,232 single-lead ECGs from 53,549 patients who used a single-lead ambulatory ECG monitoring device. When validated against an independent test dataset annotated by a consensus committee of board-certified practicing cardiologists, the DNN achieved an average area under the receiver operating characteristic curve (ROC) of 0.97. The average F1 score, which is the harmonic mean of the positive predictive value and sensitivity, for the DNN (0.837) exceeded that of average cardiologists (0.780). With specificity fixed at the average specificity achieved by cardiologists, the sensitivity of the DNN exceeded the average cardiologist sensitivity for all rhythm classes. These findings demonstrate that an end-to-end deep learning approach can classify a broad range of distinct arrhythmias from single-lead ECGs with high diagnostic performance similar to that of cardiologists. If confirmed in clinical settings, this approach could reduce the rate of misdiagnosed computerized ECG interpretations and improve the efficiency of expert human ECG interpretation by accurately triaging or prioritizing the most urgent conditions.},
  issue = {1},
  langid = {english},
  keywords = {Arrhythmias,Machine learning},
  file = {C:\Users\sdp490\Zotero\storage\9HYKAINU\Hannun et al. - 2019 - Cardiologist-level arrhythmia detection and classi.pdf}
}

@online{haueSubgrouping2023,
  title = {Subgrouping Multimorbid Patients with Ischemic Heart Disease by Means of Unsupervised Clustering: {{A}} Cohort Study of 72,249 Patients Defined Comprehensively by Diagnoses Prior to Presentation},
  shorttitle = {Subgrouping Multimorbid Patients with Ischemic Heart Disease by Means of Unsupervised Clustering},
  author = {Haue, Amalie D. and Holm, Peter C. and Banasik, Karina and Lundgaard, Agnete T. and Muse, Victorine P. and Röder, Timo and Westergaard, David and Chmura, Piotr J. and Christensen, Alex H. and Weeke, Peter E. and Sørensen, Erik and Pedersen, Ole B. V. and Ostrowski, Sisse R. and Iversen, Kasper K. and Køber, Lars V. and Ullum, Henrik and Bundgaard, Henning and Brunak, Søren},
  date = {2023-04-11},
  eprinttype = {medRxiv},
  pages = {2023.03.31.23288006},
  doi = {10.1101/2023.03.31.23288006},
  abstract = {Background There are no methods for classifying patients with ischemic heart disease (IHD) based on the entire spectrum of pre-existing diseases. Such methods might be clinically useful due to the marked differences in presentation and course of disease. Methods A population-based cohort study from a Danish secondary care setting of patients with IHD (2004-2016) and subjected to a coronary angiography (CAG) or coronary computed tomography angiography (CCTA). Data sources were The Danish National Patient Registry, in-hospital laboratory data, and genetic data from Copenhagen Hospital Biobank. Comorbidities included diagnoses assigned prior to presentation of IHD. Patients were clustered by means of the Markov Clustering Algorithm using the entire spectrum of registered multimorbidity. The two prespecified outcomes were: New ischemic events (including death from IHD causes) and death from non-IHD causes. Patients were followed from date of CAG/CCTA until one of the two outcomes occurred or end of follow-up, whichever came first. Biological and clinical appropriateness of clusters was assessed by comparing risks (estimated from Cox proportional hazard models) in clusters and by phenotypic and genetic enrichment analyses, respectively. Findings In a cohort of 72,249 patients with IHD (mean age 63.9 years, 63.1\% males), 31 distinct clusters (C1-31, 67,136 patients) were identified. Comparing each cluster to the 30 others, seven clusters (9,590 patients) had statistically significantly higher or lower risk of new ischemic events (five and two clusters, respectively). 18 clusters (35,982 patients) had a higher or lower risk of death from non-IHD causes (12 and six clusters, respectively). All clusters at increased risk of new ischemic events, associated with risk of death from non-IHD causes as well. Cardiovascular or inflammatory diseases were commonly enriched in clusters (13), and distributions for 24 laboratory test results differed significantly across clusters. Clusters enriched for cerebrovascular diseases were generally not at increased risk of the two outcomes. Polygenic risk scores were increased in a total of 15 clusters (48.4\%). Conclusions Clustering of patients with IHD based on pre-existing comorbidities identified subgroups of patients with significantly different clinical outcomes and presented a tool to rank pre-existing comorbidities based on their association with clinical outcomes. This novel method may support better classification of patients and thereby differentiation of treatment intensity depending on expected outcomes in subgroups.},
  langid = {english},
  pubstate = {preprint},
  file = {C:\Users\sdp490\Zotero\storage\MF36DE7K\Haue et al. - 2023 - Subgrouping multimorbid patients with ischemic hea.pdf}
}

@article{hawkinsProblem2004,
  title = {The {{Problem}} of {{Overfitting}}},
  author = {Hawkins, Douglas M.},
  date = {2004-01-01},
  journaltitle = {Journal of Chemical Information and Computer Sciences},
  shortjournal = {J. Chem. Inf. Comput. Sci.},
  volume = {44},
  number = {1},
  pages = {1--12},
  publisher = {{American Chemical Society}},
  issn = {0095-2338},
  doi = {10.1021/ci0342472}
}

@online{heDeep2015,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2015-12-10},
  eprint = {1512.03385},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1512.03385},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\NT8DMYI5\\He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\UJK7VFXY\\1512.html}
}

@article{helweg-larsenDanish2011,
  title = {The {{Danish Register}} of {{Causes}} of {{Death}}},
  author = {Helweg-Larsen, Karin},
  date = {2011-07},
  journaltitle = {Scandinavian Journal of Public Health},
  shortjournal = {Scand J Public Health},
  volume = {39},
  eprint = {21775346},
  eprinttype = {pmid},
  pages = {26--29},
  issn = {1651-1905},
  doi = {10.1177/1403494811399958},
  abstract = {INTRODUCTION: Cause-specific mortality statistics is a valuable source for the identification of risk factors for poor public health. CONTENT: Since 1875, the National Board of Health has maintained the register covering all deaths among citizens dying in Denmark, and since 1970 has computerised individual records. VALIDITY AND COVERAGE: Classification of cause(s) of deaths is done in accordance to WHO's rules, since 1994 by ICD-10 codes. A change in coding practices and a low autopsy rate might influence the continuity and validity in cause-specific mortality. CONCLUSION: The longstanding national registration of causes of death is essential for much research. The quality of the register on causes of death relies mainly upon the correctness of the physicians' notification and the coding in the National Board of Health.},
  issue = {7 Suppl},
  langid = {english},
  keywords = {Cause of Death,Clinical Coding,Death Certificates,Denmark,Humans,Registries,World Health Organization}
}

@article{hochreiterLong1997,
  title = {Long {{Short-Term Memory}}},
  author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  date = {1997-11},
  journaltitle = {Neural Computation},
  volume = {9},
  number = {8},
  pages = {1735--1780},
  issn = {0899-7667},
  doi = {10.1162/neco.1997.9.8.1735},
  abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
  eventtitle = {Neural {{Computation}}},
  file = {C:\Users\sdp490\Zotero\storage\HUCY8JJK\6795963.html}
}

@article{hokkenPrecision2020,
  title = {Precision {{Medicine}} in {{Interventional Cardiology}}},
  author = {Hokken, Thijmen W and Ribeiro, Joana M and De Jaegere, Peter P and Van Mieghem, Nicolas M},
  date = {2020-04-23},
  journaltitle = {Interventional Cardiology Review},
  shortjournal = {Interv Cardiol},
  volume = {15},
  eprint = {32382319},
  eprinttype = {pmid},
  pages = {e03},
  issn = {1756-1477},
  doi = {10.15420/icr.2019.23},
  abstract = {Precision medicine has recently become widely advocated. It revolves around the individual patient, taking into account genetic, biomarker, phenotypic or psychosocial characteristics and uses biological, mechanical and/or personal variables to optimise individual therapy. In silico testing, such as the Virtual Physiological Human project, is being promoted to predict risk and to test treatments and medical devices. It combines artificial intelligence and computational modelling to select the best therapeutic option for the individual patient.},
  pmcid = {PMC7203877},
  file = {C:\Users\sdp490\Zotero\storage\U3ZUWRVD\Hokken et al. - 2020 - Precision Medicine in Interventional Cardiology.pdf}
}

@online{holmDevelopment2023,
  title = {Development and Validation of a Neural Network-Based Survival Model for Mortality in Ischemic Heart Disease},
  author = {Holm, Peter C. and Haue, Amalie D. and Westergaard, David and Röder, Timo and Banasik, Karina and Tragante, Vinicius and Christensen, Alex H. and Thomas, Laurent and Nøst, Therese H. and Skogholt, Anne-Heidi and Iversen, Kasper K. and Pedersen, Frants and Høfsten, Dan E. and Pedersen, Ole B. and Ostrowski, Sisse Rye and Ullum, Henrik and Svendsen, Mette N. and Gjødsbøl, Iben M. and Gudnason, Thorarinn and Guðbjartsson, Daníel F. and Helgadottir, Anna and Hveem, Kristian and Køber, Lars V. and Holm, Hilma and Stefansson, Kari and Brunak, Søren and Bundgaard, Henning},
  date = {2023-06-20},
  eprinttype = {medRxiv},
  pages = {2023.06.16.23291527},
  doi = {10.1101/2023.06.16.23291527},
  abstract = {Background Current risk prediction models for ischemic heart disease (IHD) use a limited set of established risk factors and are based on classical statistical techniques. Using machine-learning techniques and including a broader panel of features from electronic health records (EHRs) may improve prognostication. Objectives Developing and externally validating a neural network-based time-to-event model (PMHnet) for prediction of all-cause mortality in IHD. Methods We included 39,746 patients (training: 34,746, test: 5,000) with IHD from the Eastern Danish Heart Registry, who underwent coronary angiography (CAG) between 2006-2016. Clinical and genetic features were extracted from national registries, EHRs, and biobanks. The feature-selection process identified 584 features, including prior diagnosis and procedure codes, laboratory test results, and clinical measurements. Model performance was evaluated using time-dependent AUC (tdAUC) and the Brier score. PMHnet was benchmarked against GRACE Risk Score 2.0 (GRACE2.0), and externally validated using data from Iceland (n=8,287). Feature importance and model explainability were assessed using SHAP analysis. Findings On the test set, the tdAUC was 0.88 (95\% CI 0.86-0.90, case count, cc=196) at six months, 0.88(0.86-0.90, cc=261) at one year, 0.84(0.82-0.86, cc=395) at three years, and 0.82(0.80-0.84, cc=763) at five years. On the same data, GRACE2.0 had a lower performance: 0.77 (0.73-0.80) at six months, 0.77(0.74-0.80) at one year, and 0.73(0.70-0.75) at three years. PMHnet showed similar performance in the Icelandic data. Conclusion PMHnet significantly improved survival prediction in patients with IHD compared to GRACE2.0. Our findings support the use of deep phenotypic data as precision medicine tools in modern healthcare systems.},
  langid = {english},
  pubstate = {preprint},
  file = {C:\Users\sdp490\Zotero\storage\HAH4YHP7\Holm et al. - 2023 - Development and validation of a neural network-bas.pdf}
}

@article{jensenIschemic2020,
  title = {Ischemic {{Heart Disease}}: {{An Update}}},
  shorttitle = {Ischemic {{Heart Disease}}},
  author = {Jensen, Rebekka Vibjerg and Hjortbak, Marie Vognstoft and Bøtker, Hans Erik},
  date = {2020-05},
  journaltitle = {Seminars in Nuclear Medicine},
  shortjournal = {Semin Nucl Med},
  volume = {50},
  number = {3},
  eprint = {32284106},
  eprinttype = {pmid},
  pages = {195--207},
  issn = {1558-4623},
  doi = {10.1053/j.semnuclmed.2020.02.007},
  abstract = {Ischemic heart disease is a dynamic process of atherosclerosis of the coronary arteries or functional alterations of coronary circulation that can be modified by lifestyle, pharmacological therapies, and revascularization. Such treatment may result in disease stabilization or regression. New terminology describes clinical presentations of Ischemic heart disease categorized as either acute coronary syndrome or chronic coronary syndrome. The reduction in prevalence of obstructive coronary artery disease in a symptomatic population causes a lower pretest probability and clinical likelihood of disease, influencing the diagnostic work-up. Noninvasive functional or anatomic imaging for myocardial ischemia is recommended as the initial test to diagnose coronary artery disease in symptomatic patients, where obstructive disease cannot be excluded by clinical assessment alone. Coronary computed tomography (CT) angiography has advanced and is first line in suitable patients, due to high rule-out power and further qualification of the diagnosis by functional assessment using noninvasive nuclear or magnetic resonance technology or CT-based fractional flow reserve (FFR-CT). Optimal medical treatment remains paramount, while FFR-guided myocardial revascularization in patients that are not responsive to antianginal treatment provides further symptom relieve as well as prognostic impact on prevention of spontaneous myocardial infarction.},
  langid = {english},
  keywords = {{Fractional Flow Reserve, Myocardial},Humans,Magnetic Resonance Imaging,Myocardial Ischemia,{Tomography, X-Ray Computed}}
}

@article{jordanMachine2015,
  title = {Machine Learning: {{Trends}}, Perspectives, and Prospects},
  shorttitle = {Machine Learning},
  author = {Jordan, M. I. and Mitchell, T. M.},
  date = {2015-07-17},
  journaltitle = {Science},
  volume = {349},
  number = {6245},
  pages = {255--260},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aaa8415},
  abstract = {Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today’s most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.}
}

@book{kalbfleischStatistical2002,
  title = {The {{Statistical Analysis}} of {{Failure Time Data}}, 2nd {{Edition}}},
  author = {Kalbfleisch},
  date = {2002-08-26},
  edition = {2nd edition},
  publisher = {{Wiley-Interscience}},
  location = {{Hoboken, N.J}},
  abstract = {* Contains additional discussion and examples on left truncation as well as material on more general censoring and truncation patterns. * Introduces the martingale and counting process formulation swil lbe in a new chapter. * Develops multivariate failure time data in a separate chapter and extends the material on Markov and semi Markov formulations. * Presents new examples and applications of data analysis.},
  isbn = {978-0-471-36357-6},
  langid = {english},
  pagetotal = {462}
}

@article{kaplan1958nonparametric,
  title = {Nonparametric Estimation from Incomplete Observations},
  author = {Kaplan, Edward L and Meier, Paul},
  date = {1958},
  journaltitle = {Journal of the American statistical association},
  volume = {53},
  number = {282},
  pages = {457--481},
  publisher = {{Taylor \& Francis}}
}

@article{katzmanDeepSurv2018a,
  title = {{{DeepSurv}}: Personalized Treatment Recommender System Using a {{Cox}} Proportional Hazards Deep Neural Network},
  shorttitle = {{{DeepSurv}}},
  author = {Katzman, Jared L. and Shaham, Uri and Cloninger, Alexander and Bates, Jonathan and Jiang, Tingting and Kluger, Yuval},
  date = {2018-02-26},
  journaltitle = {BMC Medical Research Methodology},
  shortjournal = {BMC Medical Research Methodology},
  volume = {18},
  number = {1},
  pages = {24},
  issn = {1471-2288},
  doi = {10.1186/s12874-018-0482-1},
  abstract = {Medical practitioners use survival models to explore and understand the relationships between patients’ covariates (e.g. clinical and genetic features) and the effectiveness of various treatment options. Standard survival models like the linear Cox proportional hazards model require extensive feature engineering or prior medical knowledge to model treatment interaction at an individual level. While nonlinear survival methods, such as neural networks and survival forests, can inherently model these high-level interaction terms, they have yet to be shown as effective treatment recommender systems.},
  keywords = {Deep learning,Survival analysis,Treatment recommendations},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\5VXAM8Y6\\Katzman et al. - 2018 - DeepSurv personalized treatment recommender syste.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\PL8Q6GPE\\s12874-018-0482-1.html}
}

@article{kellyKey2019,
  title = {Key Challenges for Delivering Clinical Impact with Artificial Intelligence},
  author = {Kelly, Christopher J. and Karthikesalingam, Alan and Suleyman, Mustafa and Corrado, Greg and King, Dominic},
  date = {2019-10-29},
  journaltitle = {BMC Medicine},
  shortjournal = {BMC Medicine},
  volume = {17},
  number = {1},
  pages = {195},
  issn = {1741-7015},
  doi = {10.1186/s12916-019-1426-2},
  abstract = {Artificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice.},
  keywords = {Algorithms,Artificial intelligence,Evaluation,Machine learning,Regulation,Translation},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\SKK988MN\\Kelly et al. - 2019 - Key challenges for delivering clinical impact with.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\4YG5I3MJ\\s12916-019-1426-2.html}
}

@article{kildemoesDanish2011,
  title = {The {{Danish National Prescription Registry}}},
  author = {Kildemoes, Helle Wallach and Sørensen, Henrik Toft and Hallas, Jesper},
  date = {2011-07},
  journaltitle = {Scandinavian Journal of Public Health},
  shortjournal = {Scand J Public Health},
  volume = {39},
  eprint = {21775349},
  eprinttype = {pmid},
  pages = {38--41},
  issn = {1651-1905},
  doi = {10.1177/1403494810394717},
  abstract = {INTRODUCTION: Individual-level data on all prescription drugs sold in Danish community pharmacies has since 1994 been recorded in the Register of Medicinal Products Statistics of the Danish Medicines Agency. CONTENT: The register subset, termed the Danish National Prescription Registry (DNPR), contains information on dispensed prescriptions, including variables at the level of the drug user, the prescriber, and the pharmacy. VALIDITY AND COVERAGE: Reimbursement-driven record keeping, with automated bar-code-based data entry provides data of high quality, including detailed information on the dispensed drug. CONCLUSION: The possibility of linkage with many other nationwide individual-level data sources renders the DNPR a very powerful pharmacoepidemiological tool.},
  issue = {7 Suppl},
  langid = {english},
  keywords = {Denmark,Drug Prescriptions,Humans,Pharmacoepidemiology,Registries,Research},
  file = {C:\Users\sdp490\Zotero\storage\QHRYNVCY\Kildemoes et al. - 2011 - The Danish National Prescription Registry.pdf}
}

@book{kleinbaumSurvival2011,
  title = {Survival {{Analysis}}: {{A Self-Learning Text}}, {{Third Edition}}},
  shorttitle = {Survival {{Analysis}}},
  author = {Kleinbaum, David G. and Klein, Mitchel},
  date = {2011-08-31},
  edition = {3rd edition},
  publisher = {{Springer}},
  location = {{New York, NY}},
  abstract = {An excellent introduction for all those coming to the subject for the first time.New material has been added to the second edition and the original six chapters have been modified.The previous edition sold 9500 copies world wide since its release in 1996.Based on numerous courses given by the author to students and researchers in the health sciences and is written with such readers in mind. Provides a "user-friendly" layout and includes numerous illustrations and exercises. Written in such a way so as to enable readers learn directly without the assistance of a classroom instructor. Throughout, there is an emphasis on presenting each new topic backed by real examples of a survival analysis investigation, followed up with thorough analyses of real data sets.},
  isbn = {978-1-4419-6645-2},
  langid = {english},
  pagetotal = {715}
}

@book{kleinSurvival2003,
  title = {Survival {{Analysis}}: {{Techniques}} for {{Censored}} and {{Truncated Data}}},
  shorttitle = {Survival {{Analysis}}},
  author = {Klein, John P. and Moeschberger, Melvin L.},
  date = {2003},
  series = {Statistics for {{Biology}} and {{Health}}},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/b97377},
  isbn = {978-0-387-95399-1 978-0-387-21645-4},
  langid = {english},
  keywords = {Analysis,Censoring,Statistical Method,statistics,Survival analysis,Truncated Data},
  file = {C:\Users\sdp490\Zotero\storage\UTGM86TI\Klein and Moeschberger - 2003 - Survival Analysis Techniques for Censored and Tru.pdf}
}

@article{knuuti20192020,
  title = {2019 {{ESC Guidelines}} for the Diagnosis and Management of Chronic Coronary Syndromes},
  shorttitle = {2019 {{ESC Guidelines}} for the Diagnosis and Management of Chronic Coronary Syndromes},
  author = {Knuuti, Juhani and Wijns, William and Saraste, Antti and Capodanno, Davide and Barbato, Emanuele and Funck-Brentano, Christian and Prescott, Eva and Storey, Robert F and Deaton, Christi and Cuisset, Thomas and Agewall, Stefan and Dickstein, Kenneth and Edvardsen, Thor and Escaned, Javier and Gersh, Bernard J and Svitil, Pavel and Gilard, Martine and Hasdai, David and Hatala, Robert and Mahfoud, Felix and Masip, Josep and Muneretto, Claudio and Valgimigli, Marco and Achenbach, Stephan and Bax, Jeroen J and {ESC Scientific Document Group}},
  date = {2020-01-14},
  journaltitle = {European Heart Journal},
  shortjournal = {European Heart Journal},
  volume = {41},
  number = {3},
  pages = {407--477},
  issn = {0195-668X},
  doi = {10.1093/eurheartj/ehz425},
  abstract = {For the Supplementary Data which include background information and detailed discussion of the data that have provided the basis for the Guidelines see https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehz425\#supplementary-data},
  file = {C:\Users\sdp490\Zotero\storage\FJU7CN9D\Knuuti et al. - 2020 - 2019 ESC Guidelines for the diagnosis and manageme.pdf}
}

@article{konigWhat2017,
  title = {What Is Precision Medicine?},
  author = {König, Inke R. and Fuchs, Oliver and Hansen, Gesine and Von Mutius, Erika and Kopp, Matthias V.},
  date = {2017-10},
  journaltitle = {European Respiratory Journal},
  shortjournal = {Eur Respir J},
  volume = {50},
  number = {4},
  pages = {1700391},
  issn = {0903-1936, 1399-3003},
  doi = {10.1183/13993003.00391-2017},
  abstract = {The term “precision medicine” has become very popular over recent years, fuelled by scientific as well as political perspectives. Despite its popularity, its exact meaning, and how it is different from other popular terms such as “stratified medicine”, “targeted therapy” or “deep phenotyping” remains unclear. Commonly applied definitions focus on the stratification of patients, sometimes referred to as a novel taxonomy, and this is derived using large-scale data including clinical, lifestyle, genetic and further biomarker information, thus going beyond the classical “signs-and-symptoms” approach.},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\8PRVCLXP\König et al. - 2017 - What is precision medicine.pdf}
}

@article{kosorokPrecision2019,
  title = {Precision {{Medicine}}},
  author = {Kosorok, Michael R. and Laber, Eric B.},
  date = {2019},
  journaltitle = {Annual Review of Statistics and Its Application},
  volume = {6},
  number = {1},
  pages = {263--286},
  doi = {10.1146/annurev-statistics-030718-105251},
  abstract = {Precision medicine seeks to maximize the quality of health care by individualizing the health-care process to the uniquely evolving health status of each patient. This endeavor spans a broad range of scientific areas including drug discovery, genetics/genomics, health communication, and causal inference, all in support of evidence-based, i.e., data-driven, decision making. Precision medicine is formalized as a treatment regime that comprises a sequence of decision rules, one per decision point, which map up-to-date patient information to a recommended action. The potential actions could be the selection of which drug to use, the selection of dose, the timing of administration, the recommendation of a specific diet or exercise, or other aspects of treatment or care. Statistics research in precision medicine is broadly focused on methodological development for estimation of and inference for treatment regimes that maximize some cumulative clinical outcome. In this review, we provide an overview of this vibrant area of research and present important and emerging challenges.},
  file = {C:\Users\sdp490\Zotero\storage\CWA6STI5\Kosorok and Laber - 2019 - Precision Medicine.pdf}
}

@book{kumarRobbins2014,
  title = {Robbins and {{Cotran Pathologic Basis}} of {{Disease}}},
  author = {Kumar, Vinay and Abbas, Abul K. and Fausto, Nelson and Aster, Jon C.},
  date = {2014-08-27},
  eprint = {jJllBAAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Elsevier Health Sciences}},
  abstract = {Dependable, current, and complete, Robbins and Cotran Pathologic Basis of Disease, 9th Edition is the perennially best-selling text that you’ll use long after your medical student days are behind you. A world-class author team headed by Drs. Vinay Kumar, Abul Abbas, and Jon Aster, delivers the latest, most essential pathology knowledge in a readable, interesting manner, ensuring optimal understanding of the latest basic science and clinical content. High-quality photographs and full-color illustrations highlight new information in molecular biology, disease classifications, new drugs and drug therapies, and much more.Rely on uniquely authoritative and readable coverage, ideal for USMLE or specialty board preparation, as well as for course work.Simplify your study with an outstanding full-color, highly user-friendly design.Stay up to date with the latest information in molecular and genetic testing and mechanisms of disease.Consult new Targeted Therapy boxes online that discuss drug therapy for specific diseases.Gain a new perspective in key areas thanks to contributions from new authors at the top of their fields.Consult this title on your favorite e-reader, conduct rapid searches, and adjust font sizes for optimal readability.},
  isbn = {978-0-323-29639-7},
  langid = {english},
  pagetotal = {1413},
  keywords = {Medical / Pathology}
}

@book{kumarRobbins2017,
  title = {Robbins {{Basic Pathology E-Book}}: {{Robbins Basic Pathology E-Book}}},
  shorttitle = {Robbins {{Basic Pathology}}},
  author = {Kumar, Vinay and Abbas, Abul K. and Aster, Jon C.},
  date = {2017-03-08},
  eprint = {YYZMDgAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Elsevier Health Sciences}},
  abstract = {Part of the trusted Robbins and Cotran family, Robbins Basic Pathology provides a readable, well-illustrated and concise overview of the principles of human pathology that's ideal for today's busy students. This thoroughly revised edition continues with a strong emphasis on pathogenesis and the clinical features of disease, adding new artwork and more schematic diagrams to further aid in summarizing key pathologic processes and expand the already impressive illustration program. Excellent art program boasts high-quality photomicrographs, gross photos, and radiologic images to supplement the world-class illustrations.   Bulleted summary boxes provide quick access to key information and easy review of key concepts.    Highlights pathogenesis, morphology, and pathophysiologic content throughout.   Includes increased and updated clinical topics.   New artwork and more schematic diagrams summarize key pathologic processes.    An all-star editorial team enables you to gain a rich understanding of all essential pathology concepts.    Student Consult eBook version included with purchase. This enhanced eBook experience allows you to search all of the text, figures, and images from the book on a variety of devices. You'll also access virtual microscope slides, self-assessment questions, additional images, updated pathology case studies, and Targeted Therapy boxes.},
  isbn = {978-0-323-39413-0},
  langid = {english},
  pagetotal = {955},
  keywords = {Medical / Pathology}
}

@article{kvammeContinuous2021,
  title = {Continuous and Discrete-Time Survival Prediction with Neural Networks},
  author = {Kvamme, Håvard and Borgan, Ørnulf},
  date = {2021-10-01},
  journaltitle = {Lifetime Data Analysis},
  shortjournal = {Lifetime Data Anal},
  volume = {27},
  number = {4},
  pages = {710--736},
  issn = {1572-9249},
  doi = {10.1007/s10985-021-09532-6},
  abstract = {Due to rapid developments in machine learning, and in particular neural networks, a number of new methods for time-to-event predictions have been developed in the last few years. As neural networks are parametric models, it is more straightforward to integrate parametric survival models in the neural network framework than the popular semi-parametric Cox model. In particular, discrete-time survival models, which are fully parametric, are interesting candidates to extend with neural networks. The likelihood for discrete-time survival data may be parameterized by the probability mass function (PMF) or by the discrete hazard rate, and both of these formulations have been used to develop neural network-based methods for time-to-event predictions. In this paper, we review and compare these approaches. More importantly, we show how the discrete-time methods may be adopted as approximations for continuous-time data. To this end, we introduce two discretization schemes, corresponding to equidistant times or equidistant marginal survival probabilities, and two ways of interpolating the discrete-time predictions, corresponding to piecewise constant density functions or piecewise constant hazard rates. Through simulations and study of real-world data, the methods based on the hazard rate parametrization are found to perform slightly better than the methods that use the PMF parametrization. Inspired by these investigations, we also propose a continuous-time method by assuming that the continuous-time hazard rate is piecewise constant. The method, named PC-Hazard, is found to be highly competitive with the aforementioned methods in addition to other methods for survival prediction found in the literature.},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\TX9WR7IR\Kvamme and Borgan - 2021 - Continuous and discrete-time survival prediction w.pdf}
}

@inproceedings{lecunHandwritten1989,
  title = {Handwritten {{Digit Recognition}} with a {{Back-Propagation Network}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {LeCun, Yann and Boser, Bernhard and Denker, John and Henderson, Donnie and Howard, R. and Hubbard, Wayne and Jackel, Lawrence},
  date = {1989},
  volume = {2},
  publisher = {{Morgan-Kaufmann}},
  url = {https://proceedings.neurips.cc/paper_files/paper/1989/hash/53c3bce66e43be4f209556518c2fcb54-Abstract.html},
  urldate = {2023-10-29},
  abstract = {We present an application of back-propagation networks to hand(cid:173) written digit recognition. Minimal preprocessing of the data was  required, but architecture of the network was highly constrained  and specifically designed for the task. The input of the network  consists of normalized images of isolated digits. The method has  1 \% error rate and about a 9\% reject rate on zipcode digits provided  by the U.S. Postal Service.},
  file = {C:\Users\sdp490\Zotero\storage\8TCLYNNR\LeCun et al. - 1989 - Handwritten Digit Recognition with a Back-Propagat.pdf}
}

@article{ledleyReasoning1959,
  title = {Reasoning {{Foundations}} of {{Medical Diagnosis}}},
  author = {Ledley, Robert S. and Lusted, Lee B.},
  date = {1959},
  journaltitle = {Science},
  volume = {130},
  number = {3366},
  pages = {9--21},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  url = {https://www.jstor.org/stable/1758070},
  urldate = {2023-04-08},
  file = {C:\Users\sdp490\Zotero\storage\SPY7DDBY\Ledley and Lusted - 1959 - Reasoning Foundations of Medical Diagnosis.pdf}
}

@article{leeDeepHit2018,
  title = {{{DeepHit}}: {{A Deep Learning Approach}} to {{Survival Analysis With Competing Risks}}},
  shorttitle = {{{DeepHit}}},
  author = {Lee, Changhee and Zame, William and Yoon, Jinsung and family=Schaar, given=Mihaela, prefix=van der, useprefix=false},
  date = {2018-04-26},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {32},
  number = {1},
  issn = {2374-3468},
  doi = {10.1609/aaai.v32i1.11842},
  abstract = {Survival analysis (time-to-event analysis) is widely used in economics and finance, engineering, medicine and many other areas. A fundamental problem is to understand the relationship between the covariates and the (distribution of) survival times(times-to-event). Much of the previous work has approached the problem by viewing the survival time as the first hitting time of a stochastic process, assuming a specific form for the underlying stochastic process, using available data to learn the relationship between the covariates and the parameters of the model, and then deducing the relationship between covariates and the distribution of first hitting times (the risk). However, previous models rely on strong parametric assumptions that are often violated. This paper proposes a very different approach to survival analysis, DeepHit, that uses a deep neural network to learn the distribution of survival times directly.DeepHit makes no assumptions about the underlying stochastic process and allows for the possibility that the relationship between covariates and risk(s) changes over time. Most importantly, DeepHit smoothly handles competing risks; i.e. settings in which there is more than one possible event of interest.Comparisons with previous models on the basis of real and synthetic datasets demonstrate that DeepHit achieves large and statistically significant performance improvements over previous state-of-the-art methods.},
  issue = {1},
  langid = {english},
  keywords = {first-hitting-time analysis},
  file = {C:\Users\sdp490\Zotero\storage\P2CD94KB\Lee et al. - 2018 - DeepHit A Deep Learning Approach to Survival Anal.pdf}
}

@article{lehneWhy2019,
  title = {Why Digital Medicine Depends on Interoperability},
  author = {Lehne, Moritz and Sass, Julian and Essenwanger, Andrea and Schepers, Josef and Thun, Sylvia},
  date = {2019-08-20},
  journaltitle = {npj Digital Medicine},
  shortjournal = {npj Digit. Med.},
  volume = {2},
  number = {1},
  pages = {1--5},
  publisher = {{Nature Publishing Group}},
  issn = {2398-6352},
  doi = {10.1038/s41746-019-0158-1},
  abstract = {Digital data are anticipated to transform medicine. However, most of today’s medical data lack interoperability: hidden in isolated databases, incompatible systems and proprietary software, the data are difficult to exchange, analyze, and interpret. This slows down medical progress, as technologies that rely on these data – artificial intelligence, big data or mobile applications – cannot be used to their full potential. In this article, we argue that interoperability is a prerequisite for the digital innovations envisioned for future medicine. We focus on four areas where interoperable data and IT systems are particularly important: (1) artificial intelligence and big data; (2) medical communication; (3) research; and (4) international cooperation. We discuss how interoperability can facilitate digital transformation in these areas to improve the health and well-being of patients worldwide.},
  issue = {1},
  langid = {english},
  keywords = {Health care,Health policy},
  file = {C:\Users\sdp490\Zotero\storage\UEGX5DYC\Lehne et al. - 2019 - Why digital medicine depends on interoperability.pdf}
}

@article{libbyPathophysiology2005,
  title = {Pathophysiology of {{Coronary Artery Disease}}},
  author = {Libby, Peter and Theroux, Pierre},
  date = {2005-06-28},
  journaltitle = {Circulation},
  volume = {111},
  number = {25},
  pages = {3481--3488},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIRCULATIONAHA.105.537878},
  abstract = {During the past decade, our understanding of the pathophysiology of coronary artery disease (CAD) has undergone a remarkable evolution. We review here how these advances have altered our concepts of and clinical approaches to both the chronic and acute phases of CAD. Previously considered a cholesterol storage disease, we currently view atherosclerosis as an inflammatory disorder. The appreciation of arterial remodeling (compensatory enlargement) has expanded attention beyond stenoses evident by angiography to encompass the biology of nonstenotic plaques. Revascularization effectively relieves ischemia, but we now recognize the need to attend to nonobstructive lesions as well. Aggressive management of modifiable risk factors reduces cardiovascular events and should accompany appropriate revascularization. We now recognize that disruption of plaques that may not produce critical stenoses causes many acute coronary syndromes (ACS). The disrupted plaque represents a “solid-state” stimulus to thrombosis. Alterations in circulating prothrombotic or antifibrinolytic mediators in the “fluid phase” of the blood can also predispose toward ACS. Recent results have established the multiplicity of “high-risk” plaques and the widespread nature of inflammation in patients prone to develop ACS. These findings challenge our traditional view of coronary atherosclerosis as a segmental or localized disease. Thus, treatment of ACS should involve 2 overlapping phases: first, addressing the culprit lesion, and second, aiming at rapid “stabilization” of other plaques that may produce recurrent events. The concept of “interventional cardiology” must expand beyond mechanical revascularization to embrace preventive interventions that forestall future events.},
  keywords = {acute coronary syndromes,atherogenesis,inflammation,ischemia,plaque},
  file = {C:\Users\sdp490\Zotero\storage\UWXS6D92\Libby and Theroux - 2005 - Pathophysiology of Coronary Artery Disease.pdf}
}

@online{lpr2dok,
  title = {Landspatientregisteret, {{Dokumentation}}},
  url = {https://www.esundhed.dk/Dokumentation?rid=5},
  urldate = {2023-11-25},
  organization = {{eSundhed}},
  file = {C:\Users\sdp490\Zotero\storage\759E59W2\Dokumentation.html}
}

@inproceedings{lundbergUnified2017,
  title = {A {{Unified Approach}} to {{Interpreting Model Predictions}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lundberg, Scott M and Lee, Su-In},
  date = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html},
  urldate = {2023-11-02},
  abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
  file = {C:\Users\sdp490\Zotero\storage\XWUCHGMD\Lundberg and Lee - 2017 - A Unified Approach to Interpreting Model Predictio.pdf}
}

@article{lyngeDanish2011,
  title = {The {{Danish National Patient Register}}},
  author = {Lynge, Elsebeth and Sandegaard, Jakob Lynge and Rebolj, Matejka},
  date = {2011-07-01},
  journaltitle = {Scandinavian Journal of Public Health},
  shortjournal = {Scand J Public Health},
  volume = {39},
  pages = {30--33},
  publisher = {{SAGE Publications Ltd STM}},
  issn = {1403-4948},
  doi = {10.1177/1403494811401482},
  abstract = {Introduction: The Danish National Patient Register (NPR) was established in 1977, and it is considered to be the finest of its kind internationally. Content: At the onset the register included information on inpatient in somatic wards. The content of the register has gradually been expanded, and since 2007 the register has included information on all patients in Danish hospitals. Validity and coverage: Although the NPR is overall a sound data source, both the content and the definitions of single variables have changed over time. Changes in the organisation and provision of health services may affect both the type and the completeness of registrations. Conclusion: The NPR is a unique data source. Researchers using the data should carefully consider potential fallacies in the data before drawing conclusions.},
  issue = {7\_suppl},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\D2LDI7LF\Lynge et al. - 2011 - The Danish National Patient Register.pdf}
}

@article{mirosevicskvrceCYP2C92013,
  title = {{{CYP2C9}} and {{ABCG2}} Polymorphisms as Risk Factors for Developing Adverse Drug Reactions in Renal Transplant Patients Taking Fluvastatin: A Case-Control Study},
  shorttitle = {{{CYP2C9}} and {{ABCG2}} Polymorphisms as Risk Factors for Developing Adverse Drug Reactions in Renal Transplant Patients Taking Fluvastatin},
  author = {Miroševic Skvrce, Nikica and Božina, Nada and Zibar, Lada and Barišic, Ivan and Pejnovic, Lana and Macolic Šarinic, Viola},
  date = {2013-09},
  journaltitle = {Pharmacogenomics},
  shortjournal = {Pharmacogenomics},
  volume = {14},
  number = {12},
  eprint = {24024895},
  eprinttype = {pmid},
  pages = {1419--1431},
  issn = {1744-8042},
  doi = {10.2217/pgs.13.135},
  abstract = {AIM: To investigate whether an association exists between fluvastatin-induced adverse drug reactions (ADRs) and polymorphisms in genes encoding the metabolizing enzyme CYP2C9 and the drug transporter ABCG2 in renal transplant recipients (RTRs). MATERIALS \& METHODS: Fifty-two RTRs that experienced fluvastatin ADRs and 52 controls matched for age, gender, dose of fluvastatin and immunosuppressive use were enrolled in the study. Genotyping for CYP2C9*2, *3 and ABCG2 421C{$>$}A variants was performed by real-time PCR. RESULTS: CYP2C9 homozygous and heterozygous mutant allele (*2 or *3) carriers had 2.5-times greater odds of developing adverse effects (χ² = 4.370; degrees of freedom = 1; p = 0.037; φ = 0.21, odds ratio [OR]: 2.44; 95\% CI: 1.05-5.71). Patients who were the carriers of at least one mutant CYP2C9 allele (*2 or *3) and who were receiving CYP2C9 inhibitors, had more than six-times greater odds of having adverse effects than those without the inhibitor included in their therapy (p = 0.027; OR: 6.59; 95\% CI: 1.24-35.08). Patients with ABCG2 421CA or AA (taken together) had almost four-times greater odds of developing adverse effects than those with ABCG2 421CC genotype (χ² = 6.190; degrees of freedom = 1; p = 0.013; φ = 0.24, OR: 3.81; 95\% CI: 1.27-11.45). Patients with A allele had 2.75-times (95\% CI: 1.02-7.40) greater odds of developing adverse effects than those with C allele. CONCLUSION: Our preliminary data demonstrate an association between fluvastatin-induced ADRs in RTRs and genetic variants in the CYP2C9 and ABCG2 genes.},
  langid = {english},
  keywords = {Adult,Aryl Hydrocarbon Hydroxylases,{ATP Binding Cassette Transporter, Subfamily G, Member 2},ATP-Binding Cassette Transporters,Case-Control Studies,Cytochrome P-450 CYP2C9,Drug-Related Side Effects and Adverse Reactions,{Fatty Acids, Monounsaturated},Female,Fluvastatin,Genetic Association Studies,Humans,Indoles,Kidney Transplantation,Male,Middle Aged,Neoplasm Proteins,{Polymorphism, Single Nucleotide},Risk Factors}
}

@book{mitchellMachine1997,
  title = {Machine {{Learning}}},
  author = {Mitchell, Tom M.},
  date = {1997},
  eprint = {EoYBngEACAAJ},
  eprinttype = {googlebooks},
  publisher = {{McGraw-Hill}},
  abstract = {This book covers the field of machine learning, which is the study of algorithms that allow computer programs to automatically improve through experience. The book is intended to support upper level undergraduate and introductory level graduate courses in machine learning.},
  isbn = {978-0-07-115467-3},
  langid = {english},
  pagetotal = {414}
}

@book{molnar2020interpretable,
  title = {Interpretable Machine Learning},
  author = {Molnar, Christoph},
  date = {2020},
  publisher = {{Lulu}}
}

@book{murphyMachine2012,
  title = {Machine {{Learning}}: {{A Probabilistic Perspective}}},
  shorttitle = {Machine {{Learning}}},
  author = {Murphy, Kevin P.},
  date = {2012-09-07},
  eprint = {RC43AgAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{MIT Press}},
  abstract = {A comprehensive introduction to machine learning that uses probabilistic models and inference as a unifying approach.Today's Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach.The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package—PMTK (probabilistic modeling toolkit)—that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.},
  isbn = {978-0-262-30432-0},
  langid = {english},
  pagetotal = {1102},
  keywords = {Computers / Artificial Intelligence / General}
}

@article{nabelTale2012,
  title = {A {{Tale}} of {{Coronary Artery Disease}} and {{Myocardial Infarction}}},
  author = {Nabel, Elizabeth G. and Braunwald, Eugene},
  date = {2012-01-05},
  journaltitle = {New England Journal of Medicine},
  volume = {366},
  number = {1},
  eprint = {22216842},
  eprinttype = {pmid},
  pages = {54--63},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJMra1112570},
  abstract = {The remarkable facts, that the paroxysm, or indeed the disease itself, is excited more especially upon walking up hill, and after a meal; that thus excited, it is accompanied with a sensation, which threatens instant death if the motion is persisted in; and, that on stopping, the distress immediately abates, or altogether subsides; have . . . formed a constituent part of the character of Angina Pectoris.1 “Remarks on Angina Pectoris” by John Warren, M.D., appeared in 1812 as the first article in the first issue of The New England Journal of Medicine and Surgery.1 Warren's description of angina pectoris . . .},
  file = {C:\Users\sdp490\Zotero\storage\9CE8VLJN\Nabel and Braunwald - 2012 - A Tale of Coronary Artery Disease and Myocardial I.pdf}
}

@article{nakanishiMachine2021,
  title = {Machine {{Learning Adds}} to {{Clinical}} and {{CAC Assessments}} in {{Predicting}} 10-{{Year CHD}} and {{CVD Deaths}}},
  author = {Nakanishi, Rine and Slomka, Piotr J. and Rios, Richard and Betancur, Julian and Blaha, Michael J. and Nasir, Khurram and Miedema, Michael D. and Rumberger, John A. and Gransar, Heidi and Shaw, Leslee J. and Rozanski, Alan and Budoff, Matthew J. and Berman, Daniel S.},
  date = {2021-03},
  journaltitle = {JACC. Cardiovascular imaging},
  shortjournal = {JACC Cardiovasc Imaging},
  volume = {14},
  number = {3},
  eprint = {33129741},
  eprinttype = {pmid},
  pages = {615--625},
  issn = {1876-7591},
  doi = {10.1016/j.jcmg.2020.08.024},
  abstract = {OBJECTIVES: The aim of this study was to evaluate whether machine learning (ML) of noncontrast computed tomographic (CT) and clinical variables improves the prediction of atherosclerotic cardiovascular disease (ASCVD) and coronary heart disease (CHD) deaths compared with coronary artery calcium (CAC) Agatston scoring and clinical data. BACKGROUND: The CAC score provides a measure of the global burden of coronary atherosclerosis, and its long-term prognostic utility has been consistently shown to have incremental value over clinical risk assessment. However, current approaches fail to integrate all available CT and clinical variables for comprehensive risk assessment. METHODS: The study included data from 66,636 asymptomatic subjects (mean age 54 ± 11 years, 67\% men) without established ASCVD undergoing CAC scanning and followed for cardiovascular disease (CVD) and CHD deaths at 10 years. Clinical risk assessment incorporated the ASCVD risk score. For ML, an ensemble boosting approach was used to fit a predictive classifier for outcomes, followed by automated feature selection using information gain ratio. The model-building process incorporated all available clinical and CT data, including the CAC score; the number, volume, and density of CAC plaques; and extracoronary scores; comprising a total of 77 variables. The overall proposed model (ML all) was evaluated using a 10-fold cross-validation framework on the population data and area under the curve (AUC) as metrics. The prediction performance was also compared with 2 traditional scores (ASCVD risk and CAC score) and 2 additional models that were trained using all the clinical data (ML clinical) and CT variables (ML CT). RESULTS: The AUC by ML all (0.845) for predicting CVD death was superior compared with those obtained by ASCVD risk alone (0.821), CAC score alone (0.781), and ML CT alone (0.804) (p~{$<~$}0.001 for all). Similarly, for predicting CHD death, AUC by ML all (0.860) was superior to the other analyses (0.835 for ASCVD risk, 0.816 for CAC, and 0.827 for ML CT; p~{$<~$}0.001). CONCLUSIONS: The comprehensive ML model was superior to ASCVD risk, CAC score, and an ML model fitted using CT variables alone in the prediction of both CVD and CHD death.},
  langid = {english},
  pmcid = {PMC7987201},
  keywords = {Adult,Aged,Atherosclerosis,cardiovascular disease death,Cardiovascular Diseases,coronary artery calcification,Coronary Artery Disease,coronary heart disease death,Female,Humans,machine learning,Machine Learning,Male,Middle Aged,pooled cohort equation,Predictive Value of Tests},
  file = {C:\Users\sdp490\Zotero\storage\UIHBZVDF\Nakanishi et al. - 2021 - Machine Learning Adds to Clinical and CAC Assessme.pdf}
}

@article{neumann20182019,
  title = {2018 {{ESC}}/{{EACTS Guidelines}} on Myocardial Revascularization},
  author = {Neumann, Franz-Josef and Sousa-Uva, Miguel and Ahlsson, Anders and Alfonso, Fernando and Banning, Adrian P and Benedetto, Umberto and Byrne, Robert A and Collet, Jean-Philippe and Falk, Volkmar and Head, Stuart J and Jüni, Peter and Kastrati, Adnan and Koller, Akos and Kristensen, Steen D and Niebauer, Josef and Richter, Dimitrios J and Seferović, Petar M and Sibbing, Dirk and Stefanini, Giulio G and Windecker, Stephan and Yadav, Rashmi and Zembala, Michael O and {ESC Scientific Document Group}},
  date = {2019-01-07},
  journaltitle = {European Heart Journal},
  shortjournal = {European Heart Journal},
  volume = {40},
  number = {2},
  pages = {87--165},
  issn = {0195-668X},
  doi = {10.1093/eurheartj/ehy394},
  abstract = {The Task Force on myocardial revascularization of the European Society of Cardiology (ESC) and European Association for Cardio-Thoracic Surgery (EACTS)Developed with the special contribution of the European Association for Percutaneous Cardiovascular Interventions (EAPCI)},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\9QUPCQJG\\Neumann et al. - 2019 - 2018 ESCEACTS Guidelines on myocardial revascular.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\TXP36HZK\\5079120.html}
}

@online{nielsenLPR32018,
  title = {LPR3 går snart i luften},
  author = {Nielsen, Lisbeth},
  date = {2018-12-11},
  url = {sundhedsdatastyrelsen.dk},
  langid = {danish}
}

@article{norgeotCall2019,
  title = {A Call for Deep-Learning Healthcare},
  author = {Norgeot, Beau and Glicksberg, Benjamin S. and Butte, Atul J.},
  date = {2019-01},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {25},
  number = {1},
  pages = {14--15},
  publisher = {{Nature Publishing Group}},
  issn = {1546-170X},
  doi = {10.1038/s41591-018-0320-3},
  abstract = {Here we argue that now is the time to create smarter healthcare systems in which the best treatment decisions are computationally learned from electronic health record data by deep-learning methodologies.},
  issue = {1},
  langid = {english},
  keywords = {Health care,Machine learning}
}

@online{openaiGPT42023,
  title = {{{GPT-4 Technical Report}}},
  author = {OpenAI},
  date = {2023-03-27},
  eprint = {2303.08774},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2303.08774},
  abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\R3LK7WYY\\OpenAI - 2023 - GPT-4 Technical Report.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\SJAKL688\\2303.html}
}

@article{pasanenSLCO1B12006,
  title = {{{SLCO1B1}} Polymorphism Markedly Affects the Pharmacokinetics of Simvastatin Acid},
  author = {Pasanen, Marja K. and Neuvonen, Mikko and Neuvonen, Pertti J. and Niemi, Mikko},
  date = {2006-12},
  journaltitle = {Pharmacogenetics and Genomics},
  shortjournal = {Pharmacogenet Genomics},
  volume = {16},
  number = {12},
  eprint = {17108811},
  eprinttype = {pmid},
  pages = {873--879},
  issn = {1744-6872},
  doi = {10.1097/01.fpc.0000230416.82349.90},
  abstract = {BACKGROUND AND OBJECTIVE: Organic anion transporting polypeptide 1B1 (OATP1B1) is an uptake transporter located at the sinusoidal membrane of human hepatocytes. This study aimed to investigate the effects of genetic polymorphism in the SLCO1B1 gene encoding OATP1B1 on the pharmacokinetics of simvastatin. METHODS: Four healthy volunteers with the homozygous SLCO1B1 c.521CC genotype, 12 with the heterozygous c.521TC genotype and 16 with the homozygous c.521TT genotype (controls) were recruited. Each study participant ingested a single 40-mg dose of simvastatin. Plasma concentrations of simvastatin (inactive lactone) and its active metabolite simvastatin acid were measured for 12 h. RESULTS: The AUC0-infinity of simvastatin acid was 120 and 221\% higher in participants with the SLCO1B1 c.521CC genotype than in those with the c.521TC and c.521TT (reference) genotypes, respectively (P{$<$}0.001). The Cmax of simvastatin acid was 162 and 200\% higher in participants with the c.521CC genotype than in those with the c.521TC and c.521TT genotypes (P{$<$}0.001). The Cmax of simvastatin acid occurred earlier in participants with the c.521CC and c.521TC genotypes than in those with the c.521TT genotype (P{$<$}0.05). No association existed between the SLCO1B1 genotype and the elimination half-life of simvastatin acid. Moreover, no statistically significant association was seen between the SLCO1B1 genotype and the pharmacokinetics of simvastatin lactone. CONCLUSIONS: SLCO1B1 polymorphism markedly affects the pharmacokinetics of active simvastatin acid, but has no significant effect on parent simvastatin. Raised plasma concentrations of simvastatin acid in patients carrying the SLCO1B1 c.521C variant allele may enhance the risk of systemic adverse effects during simvastatin treatment. In addition, reduced uptake of simvastatin acid by OATP1B1 into the liver in patients with the c.521C allele could reduce its cholesterol-lowering efficacy.},
  langid = {english},
  keywords = {Adult,Female,Genotype,Half-Life,Heterozygote,Homozygote,Humans,Hydroxymethylglutaryl-CoA Reductase Inhibitors,Liver-Specific Organic Anion Transporter 1,Male,Organic Anion Transporters,Pharmacogenetics,{Polymorphism, Single Nucleotide},Simvastatin}
}

@article{pedersenUnidirectional2023,
  title = {A Unidirectional Mapping of {{ICD-8}} to {{ICD-10}} Codes, for Harmonized Longitudinal Analysis of Diseases},
  author = {Pedersen, Mette Krogh and Eriksson, Robert and Reguant, Roc and Collin, Catherine and Pedersen, Helle Krogh and Sørup, Freja Karuna Hemmingsen and Simon, Christian and Birch, Anna Marie and Larsen, Michael and Nielsen, Anna Pors and Belling, Kirstine and Brunak, Søren},
  date = {2023-10},
  journaltitle = {European Journal of Epidemiology},
  shortjournal = {Eur J Epidemiol},
  volume = {38},
  number = {10},
  eprint = {37555907},
  eprinttype = {pmid},
  pages = {1043--1052},
  issn = {1573-7284},
  doi = {10.1007/s10654-023-01027-y},
  abstract = {Periodic revisions of the international classification of diseases (ICD) ensure that the classification reflects new practices and knowledge; however, this complicates retrospective research as diagnoses are coded in different versions. For longitudinal disease trajectory studies, a crosswalk is an essential tool and a comprehensive mapping between ICD-8 and ICD-10 has until now been lacking. In this study, we map all ICD-8 morbidity codes to ICD-10 in the expanded Danish ICD version. We mapped ICD-8 codes to ICD-10, using a many-to-one system inspired by general equivalence mappings such that each ICD-8 code maps to a single ICD-10 code. Each ICD-8 code was manually and unidirectionally mapped to a single ICD-10 code based on medical setting and context. Each match was assigned a score (1 of 4 levels) reflecting the quality of the match and, if applicable, a "flag" signalling choices made in the mapping. We provide the first complete mapping of the 8596 ICD-8 morbidity codes to ICD-10 codes. All Danish ICD-8 codes representing diseases were mapped and 5106 (59.4\%) achieved the highest consistency score. Only 334 (3.9\%) of the ICD-8 codes received the lowest mapping consistency score. The mapping provides a scaffold for translation of ICD-8 to ICD-10, which enable longitudinal disease studies back to and 1969 in Denmark and to 1965 internationally with further adaption.},
  langid = {english},
  pmcid = {PMC10570238},
  keywords = {Conversion table,Crosswalk,Data harmonization,Denmark,Diagnosis,Disease codes,ICD-10,ICD-8,International classification of diseases,Mapping},
  file = {C:\Users\sdp490\Zotero\storage\SSNPZJ2A\Pedersen et al. - 2023 - A unidirectional mapping of ICD-8 to ICD-10 codes,.pdf}
}

@article{pepeKaplan1993,
  title = {Kaplan—Meier, Marginal or Conditional Probability Curves in Summarizing Competing Risks Failure Time Data?},
  author = {Pepe, Margaret S. and Mori, Motomi},
  date = {1993},
  journaltitle = {Statistics in Medicine},
  volume = {12},
  number = {8},
  pages = {737--751},
  issn = {1097-0258},
  doi = {10.1002/sim.4780120803},
  abstract = {In the context of competing risks the Kaplan—Meier estimator is often unsuitable for summarizing failure time data. We discuss some alternative descriptive methods including marginal probability and conditional probability estimators. Two-sample test statistics are also presented.},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\EXBUEDV7\sim.html}
}

@book{prince2023understanding,
  title = {Understanding Deep Learning},
  author = {Prince, Simon J.D.},
  date = {2023},
  publisher = {{MIT Press}},
  url = {http://udlbook.com}
}

@online{rameshZeroShot2021,
  title = {Zero-{{Shot Text-to-Image Generation}}},
  author = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  date = {2021-02-26},
  eprint = {2102.12092},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2102.12092},
  urldate = {2023-10-24},
  abstract = {Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufficient data and scale, our approach is competitive with previous domain-specific models when evaluated in a zero-shot fashion.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\TKE2HLQJ\\Ramesh et al. - 2021 - Zero-Shot Text-to-Image Generation.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\7WDDMVVV\\2102.html}
}

@article{raoSurvival2007,
  title = {Survival {{Methods}}},
  author = {Rao, Sowmya R. and Schoenfeld, David A.},
  date = {2007-01-02},
  journaltitle = {Circulation},
  volume = {115},
  number = {1},
  pages = {109--113},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIRCULATIONAHA.106.614859},
  keywords = {Kaplan-Meiers estimate,proportional hazards models,survival},
  file = {C:\Users\sdp490\Zotero\storage\BYQ67FTC\Rao and Schoenfeld - 2007 - Survival Methods.pdf}
}

@article{rapsomanikiPrognostic2014,
  title = {Prognostic Models for Stable Coronary Artery Disease Based on Electronic Health Record Cohort of 102 023 Patients},
  author = {Rapsomaniki, Eleni and Shah, Anoop and Perel, Pablo and Denaxas, Spiros and George, Julie and Nicholas, Owen and Udumyan, Ruzan and Feder, Gene Solomon and Hingorani, Aroon D. and Timmis, Adam and Smeeth, Liam and Hemingway, Harry},
  date = {2014-04-01},
  journaltitle = {European Heart Journal},
  shortjournal = {European Heart Journal},
  volume = {35},
  number = {13},
  pages = {844--852},
  issn = {0195-668X},
  doi = {10.1093/eurheartj/eht533},
  abstract = {The population with stable coronary artery disease (SCAD) is growing but validated models to guide their clinical management are lacking. We developed and validated prognostic models for all-cause mortality and non-fatal myocardial infarction (MI) or coronary death in SCAD.Models were developed in a linked electronic health records cohort of 102 023 SCAD patients from the CALIBER programme, with mean follow-up of 4.4 (SD 2.8) years during which 20 817 deaths and 8856 coronary outcomes were observed. The Kaplan–Meier 5-year risk was 20.6\% (95\% CI, 20.3, 20.9) for mortality and 9.7\% (95\% CI, 9.4, 9.9) for non-fatal MI or coronary death. The predictors in the models were age, sex, CAD diagnosis, deprivation, smoking, hypertension, diabetes, lipids, heart failure, peripheral arterial disease, atrial fibrillation, stroke, chronic kidney disease, chronic pulmonary disease, liver disease, cancer, depression, anxiety, heart rate, creatinine, white cell count, and haemoglobin. The models had good calibration and discrimination in internal (external) validation with C-index 0.811 (0.735) for all-cause mortality and 0.778 (0.718) for non-fatal MI or coronary death. Using these models to identify patients at high risk (defined by guidelines as 3\% annual mortality) and support a management decision associated with hazard ratio 0.8 could save an additional 13–16 life years or 15–18 coronary event-free years per 1000 patients screened, compared with models with just age, sex, and deprivation.These validated prognostic models could be used in clinical practice to support risk stratification as recommended in clinical guidelines.},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\SIHPWXWZ\\Rapsomaniki et al. - 2014 - Prognostic models for stable coronary artery disea.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\5YX6T3PT\\633759.html}
}

@article{riekeFuture2020,
  title = {The Future of Digital Health with Federated Learning},
  author = {Rieke, Nicola and Hancox, Jonny and Li, Wenqi and Milletarì, Fausto and Roth, Holger R. and Albarqouni, Shadi and Bakas, Spyridon and Galtier, Mathieu N. and Landman, Bennett A. and Maier-Hein, Klaus and Ourselin, Sébastien and Sheller, Micah and Summers, Ronald M. and Trask, Andrew and Xu, Daguang and Baust, Maximilian and Cardoso, M. Jorge},
  date = {2020-09-14},
  journaltitle = {npj Digital Medicine},
  shortjournal = {npj Digit. Med.},
  volume = {3},
  number = {1},
  pages = {1--7},
  publisher = {{Nature Publishing Group}},
  issn = {2398-6352},
  doi = {10.1038/s41746-020-00323-1},
  abstract = {Data-driven machine learning (ML) has emerged as a promising approach for building accurate and robust statistical models from medical data, which is collected in huge volumes by modern healthcare systems. Existing medical data is not fully exploited by ML primarily because it sits in data silos and privacy concerns restrict access to this data. However, without access to sufficient data, ML will be prevented from reaching its full potential and, ultimately, from making the transition from research to clinical practice. This paper considers key factors contributing to this issue, explores how federated learning (FL) may provide a solution for the future of digital health and highlights the challenges and considerations that need to be addressed.},
  issue = {1},
  langid = {english},
  keywords = {Medical imaging,Medical research},
  file = {C:\Users\sdp490\Zotero\storage\7BQBVCWE\Rieke et al. - 2020 - The future of digital health with federated learni.pdf}
}

@book{russellArtificial2009,
  title = {Artificial {{Intelligence}}: {{A Modern Approach}}},
  shorttitle = {Artificial {{Intelligence}}},
  author = {Russell, Stuart and Norvig, Peter},
  date = {2009-12-01},
  edition = {3rd edition},
  publisher = {{Pearson}},
  location = {{Upper Saddle River}},
  abstract = {Artificial Intelligence: A Modern Approach, 3e offers the most comprehensive, up-to-date introduction to the theory and practice of artificial intelligence. Number one in its field, this textbook is ideal for one or two-semester, undergraduate or graduate-level courses in Artificial Intelligence.Dr. Peter Norvig, contributing Artificial Intelligence author and Professor Sebastian Thrun, a Pearson author are offering a free online course at Stanford University on artificial intelligence. According to an article in The New York Times, the course on artificial intelligence is “one of three being offered experimentally by the Stanford computer science department to extend technology knowledge and skills beyond this elite campus to the entire world.” One of the other two courses, an introduction to database software, is being taught by Pearson author Dr. Jennifer Widom.Artificial Intelligence: A Modern Approach, 3e is available to purchase as an eText for your KindleTM, NOOKTM, and the iPhone®/iPad®. To learn more about the course on artificial intelligence, visit http://www.ai-class.com. To read the full New York Times article, click here.},
  isbn = {978-0-13-604259-4},
  langid = {english},
  pagetotal = {1152}
}

@article{schmidtDanish2014,
  title = {The {{Danish Civil Registration System}} as a Tool in Epidemiology},
  author = {Schmidt, Morten and Pedersen, Lars and Sørensen, Henrik Toft},
  date = {2014-08-01},
  journaltitle = {European Journal of Epidemiology},
  shortjournal = {Eur J Epidemiol},
  volume = {29},
  number = {8},
  pages = {541--549},
  issn = {1573-7284},
  doi = {10.1007/s10654-014-9930-3},
  abstract = {The methodological advances in epidemiology have facilitated the use of the Danish Civil Registration System (CRS) in ways not previously described systematically. We reviewed the CRS and its use as a research tool in epidemiology. We obtained information from the Danish Law on Civil Registration and the Central Office of Civil Registration, and used existing literature to provide illustrative examples of its use. The CRS is an administrative register established on April 2, 1968. It contains individual-level information on all persons residing in Denmark (and Greenland as of May 1, 1972). By January 2014, the CRS had cumulatively registered 9.5 million individuals and more than 400 million person-years of follow-up. A unique ten-digit Civil Personal Register number assigned to all persons in the CRS allows for technically easy, cost-effective, and unambiguous individual-level record linkage of Danish registers. Daily updated information on migration and vital status allows for nationwide cohort studies with virtually complete long-term follow-up on emigration and death. The CRS facilitates sampling of general population comparison cohorts, controls in case–control studies, family cohorts, and target groups in population surveys. The data in the CRS are virtually complete, have high accuracy, and can be retrieved for research purposes while protecting the anonymity of Danish residents. In conclusion, the CRS is a key tool for epidemiological research in Denmark.},
  langid = {english},
  keywords = {Data linkage,Database,Epidemiological methods,Epidemiology,Follow-up,Registers},
  file = {C:\Users\sdp490\Zotero\storage\5D2DT99A\Schmidt et al. - 2014 - The Danish Civil Registration System as a tool in .pdf}
}

@article{schmidtDanish2015,
  title = {The {{Danish National Patient Registry}}: A Review of Content, Data Quality, and Research Potential},
  shorttitle = {The {{Danish National Patient Registry}}},
  author = {Schmidt, Morten and Schmidt, Sigrun Alba Johannesdottir and Sandegaard, Jakob Lynge and Ehrenstein, Vera and Pedersen, Lars and Sørensen, Henrik Toft},
  date = {2015-11-17},
  journaltitle = {Clinical Epidemiology},
  shortjournal = {Clin Epidemiol},
  volume = {7},
  eprint = {26604824},
  eprinttype = {pmid},
  pages = {449--490},
  issn = {1179-1349},
  doi = {10.2147/CLEP.S91125},
  abstract = {Background The Danish National Patient Registry (DNPR) is one of the world’s oldest nationwide hospital registries and is used extensively for research. Many studies have validated algorithms for identifying health events in the DNPR, but the reports are fragmented and no overview exists. Objectives To review the content, data quality, and research potential of the DNPR. Methods We examined the setting, history, aims, content, and classification systems of the DNPR. We searched PubMed and the Danish Medical Journal to create a bibliography of validation studies. We included also studies that were referenced in retrieved papers or known to us beforehand. Methodological considerations related to DNPR data were reviewed. Results During 1977–2012, the DNPR registered 8,085,603 persons, accounting for 7,268,857 inpatient, 5,953,405 outpatient, and 5,097,300 emergency department contacts. The DNPR provides nationwide longitudinal registration of detailed administrative and clinical data. It has recorded information on all patients discharged from Danish nonpsychiatric hospitals since 1977 and on psychiatric inpatients and emergency department and outpatient specialty clinic contacts since 1995. For each patient contact, one primary and optional secondary diagnoses are recorded according to the International Classification of Diseases. The DNPR provides a data source to identify diseases, examinations, certain in-hospital medical treatments, and surgical procedures. Long-term temporal trends in hospitalization and treatment rates can be studied. The positive predictive values of diseases and treatments vary widely ({$<$}15\%–100\%). The DNPR data are linkable at the patient level with data from other Danish administrative registries, clinical registries, randomized controlled trials, population surveys, and epidemiologic field studies – enabling researchers to reconstruct individual life and health trajectories for an entire population. Conclusion The DNPR is a valuable tool for epidemiological research. However, both its strengths and limitations must be considered when interpreting research results, and continuous validation of its clinical data is essential.},
  pmcid = {PMC4655913},
  file = {C:\Users\sdp490\Zotero\storage\RZPCWP2J\Schmidt et al. - 2015 - The Danish National Patient Registry a review of .pdf}
}

@article{schmidtDanish2019,
  title = {The {{Danish}} Health Care System and Epidemiological Research: From Health Care Contacts to Database Records},
  shorttitle = {{$<$}p{$>$}{{The Danish}} Health Care System and Epidemiological Research},
  author = {Schmidt, Morten and Schmidt, Sigrun Alba Johannesdottir and Adelborg, Kasper and Sundbøll, Jens and Laugesen, Kristina and Ehrenstein, Vera and Sørensen, Henrik Toft},
  date = {2019-07-12},
  journaltitle = {Clinical Epidemiology},
  shortjournal = {CLEP},
  volume = {11},
  pages = {563--591},
  publisher = {{Dove Press}},
  doi = {10.2147/CLEP.S179083},
  abstract = {The Danish health care system and epidemiological research: from health care contacts to database records},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\2UCG7AYL\Schmidt et al. - 2019 - The Danish health care system and epidemiologic.pdf}
}

@article{searchcollaborativegroupSLCO1B12008,
  title = {{{SLCO1B1}} Variants and Statin-Induced Myopathy--a Genomewide Study},
  author = {{SEARCH Collaborative Group} and Link, E. and Parish, S. and Armitage, J. and Bowman, L. and Heath, S. and Matsuda, F. and Gut, I. and Lathrop, M. and Collins, R.},
  date = {2008-08-21},
  journaltitle = {The New England Journal of Medicine},
  shortjournal = {N Engl J Med},
  volume = {359},
  number = {8},
  eprint = {18650507},
  eprinttype = {pmid},
  pages = {789--799},
  issn = {1533-4406},
  doi = {10.1056/NEJMoa0801936},
  abstract = {BACKGROUND: Lowering low-density lipoprotein cholesterol with statin therapy results in substantial reductions in cardiovascular events, and larger reductions in cholesterol may produce larger benefits. In rare cases, myopathy occurs in association with statin therapy, especially when the statins are administered at higher doses and with certain other medications. METHODS: We carried out a genomewide association study using approximately 300,000 markers (and additional fine-mapping) in 85 subjects with definite or incipient myopathy and 90 controls, all of whom were taking 80 mg of simvastatin daily as part of a trial involving 12,000 participants. Replication was tested in a trial of 40 mg of simvastatin daily involving 20,000 participants. RESULTS: The genomewide scan yielded a single strong association of myopathy with the rs4363657 single-nucleotide polymorphism (SNP) located within SLCO1B1 on chromosome 12 (P=4x10(-9)). SLCO1B1 encodes the organic anion-transporting polypeptide OATP1B1, which has been shown to regulate the hepatic uptake of statins. The noncoding rs4363657 SNP was in nearly complete linkage disequilibrium with the nonsynonymous rs4149056 SNP (r(2)=0.97), which has been linked to statin metabolism. The prevalence of the rs4149056 C allele in the population was 15\%. The odds ratio for myopathy was 4.5 (95\% confidence interval [CI], 2.6 to 7.7) per copy of the C allele, and 16.9 (95\% CI, 4.7 to 61.1) in CC as compared with TT homozygotes. More than 60\% of these myopathy cases could be attributed to the C variant. The association of rs4149056 with myopathy was replicated in the trial of 40 mg of simvastatin daily, which also showed an association between rs4149056 and the cholesterol-lowering effects of simvastatin. No SNPs in any other region were clearly associated with myopathy. CONCLUSIONS: We have identified common variants in SLCO1B1 that are strongly associated with an increased risk of statin-induced myopathy. Genotyping these variants may help to achieve the benefits of statin therapy more safely and effectively. (Current Controlled Trials number, ISRCTN74348595.)},
  langid = {english},
  keywords = {Aged,Arterial Occlusive Diseases,{Chromosomes, Human, Pair 12},Diabetes Mellitus,Female,Genetic Markers,Genotype,Humans,Hydroxymethylglutaryl-CoA Reductase Inhibitors,Liver-Specific Organic Anion Transporter 1,Male,Middle Aged,Muscular Diseases,Myocardial Infarction,Organic Anion Transporters,{Polymorphism, Single Nucleotide},Risk,Simvastatin},
  file = {C:\Users\sdp490\Zotero\storage\LR5YC8DP\SEARCH Collaborative Group et al. - 2008 - SLCO1B1 variants and statin-induced myopathy--a ge.pdf}
}

@book{seifterConcepts2005,
  title = {Concepts in {{Medical Physiology}}},
  author = {Seifter, Julian and Sloane, David and Ratner, Austin},
  date = {2005},
  eprint = {A8H_9S4E0I4C},
  eprinttype = {googlebooks},
  publisher = {{Lippincott Williams \& Wilkins}},
  abstract = {Written through a collaboration of expert faculty and medical students from Harvard Medical School, this innovative text delivers a straightforward and clear overview of the major principles, agents, and processes governing human physiology. Emphasis is on understanding the higher-order processes in each organ system. Concepts in Medical Physiology avoids long lists of unprioritized information and undefined jargon by presenting fresh concept diagrams and figures alongside clear explanations of quantitative concepts. It can function equally well as a primary resource or as a review. Eight major sections, comprising a total of 36 chapters, cover general principles, muscle and bone, blood and the immune system, cardiovascular physiology, pulmonary physiology, renal physiology, gastrointestinal physiology, and endocrine physiology. Many useful features simplify mastery of difficult concepts:  Case studies for each major section present detailed cases with signs and symptoms, history, and laboratory data. Questions at the conclusion of each case reinforce important clinical concepts. Reviews of cell biology, basic science, and biochemistry refresh students on the foundations of physiological knowledge. Clinical Application boxes draw the connection between physiology to practical issues students face and help with preparation for the USMLE. Pathophysiology sections are featured in every chapter. Review questions with answers in each chapter aid in preparation for the examination. Integrative Physiology inserts highlight how specific systems, organs, and tissues work together. More than 350 illustrations aid with visual learning, including original schematic diagrams, photos, and tables. Concept-focused summaries conclude each chapter for more effective learning and review. Suggested readings in every chapter provide a valuable resource for further investigation in physiological and clinical ideas.},
  isbn = {978-0-7817-4489-8},
  langid = {english},
  pagetotal = {694},
  keywords = {Medical / Physiology}
}

@article{shapley1953value,
  title = {A Value for N-Person Games},
  author = {Shapley, Lloyd S and others},
  date = {1953},
  publisher = {{Princeton University Press Princeton}}
}

@article{srivastava2014dropout,
  title = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  date = {2014},
  journaltitle = {The journal of machine learning research},
  volume = {15},
  number = {1},
  pages = {1929--1958},
  publisher = {{JMLR. org}}
}

@manual{survival-package,
  type = {manual},
  title = {A Package for Survival Analysis in {{R}}},
  author = {Therneau, Terry M},
  date = {2023},
  url = {https://CRAN.R-project.org/package=survival}
}

@inreference{Survival2023,
  title = {Survival Analysis},
  booktitle = {Wikipedia},
  date = {2023-10-12T12:14:30Z},
  url = {https://en.wikipedia.org/w/index.php?title=Survival_analysis&oldid=1179784738},
  urldate = {2023-11-09},
  abstract = {Survival analysis is a branch of statistics for analyzing the expected duration of time until one event occurs, such as death in biological organisms and failure in mechanical systems. This topic is called reliability theory or reliability analysis in engineering, duration analysis or duration modelling in economics, and event history analysis in sociology. Survival analysis attempts to answer certain questions, such as what is the proportion of a population which will survive past a certain time? Of those that survive, at what rate will they die or fail? Can multiple causes of death or failure be taken into account? How do particular circumstances or characteristics increase or decrease the probability of survival? To answer such questions, it is necessary to define "lifetime". In the case of biological survival, death is unambiguous, but for mechanical reliability, failure may not be well-defined, for there may well be mechanical systems in which failure is partial, a matter of degree, or not otherwise localized in time. Even in biological problems, some events (for example, heart attack or other organ failure) may have the same ambiguity. The theory outlined below assumes well-defined events at specific times; other cases may be better treated by models which explicitly account for ambiguous events. More generally, survival analysis involves the modelling of time to event data; in this context, death or failure is considered an "event" in the survival analysis literature – traditionally only a single event occurs for each subject, after which the organism or mechanism is dead or broken. Recurring event or repeated event models relax that assumption. The study of recurring events is relevant in systems reliability, and in many areas of social sciences and medical research.},
  langid = {english},
  annotation = {Page Version ID: 1179784738},
  file = {C:\Users\sdp490\Zotero\storage\UPE9J2K2\Survival_analysis.html}
}

@article{taylorStatins2013,
  title = {Statins for the Primary Prevention of Cardiovascular Disease},
  author = {Taylor, Fiona and Huffman, Mark D. and Macedo, Ana Filipa and Moore, Theresa HM and Burke, Margaret and Smith, George Davey and Ward, Kirsten and Ebrahim, Shah and Gay, Hawkins C.},
  date = {2013},
  journaltitle = {Cochrane Database of Systematic Reviews},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {1465-1858},
  doi = {10.1002/14651858.CD004816.pub5},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\9DEK7WBN\Taylor et al. - 2013 - Statins for the primary prevention of cardiovascul.pdf}
}

@article{thanMachine2019,
  title = {Machine {{Learning}} to {{Predict}} the {{Likelihood}} of {{Acute Myocardial Infarction}}},
  author = {Than, Martin P. and Pickering, John W. and Sandoval, Yader and Shah, Anoop S.V. and Tsanas, Athanasios and Apple, Fred S. and Blankenberg, Stefan and Cullen, Louise and Mueller, Christian and Neumann, Johannes T. and Twerenbold, Raphael and Westermann, Dirk and Beshiri, Agim and Mills, Nicholas L. and {null}, null and George, Peter M and Richards, A Mark and Troughton, Richard W and Aldous, Sally J and Chapman, Andrew R and Anand, Atul and Greenslade, Jaimi and Parsonage, William and Boeddinghaus, Jasper and Wildi, Karin and Nestelberger, Thomas and Badertscher, Patrick and Du, Shaoqing and Huang, Janel and Smith, Stephen W and Sörensen, Nils A and Ojeda, Francisco},
  date = {2019-09-10},
  journaltitle = {Circulation},
  volume = {140},
  number = {11},
  pages = {899--909},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIRCULATIONAHA.119.041980},
  abstract = {Background: Variations in cardiac troponin concentrations by age, sex, and time between samples in patients with suspected myocardial infarction are not currently accounted for in diagnostic approaches. We aimed to combine these variables through machine learning to improve the assessment of risk for individual patients. Methods: A machine learning algorithm (myocardial-ischemic-injury-index [MI3]) incorporating age, sex, and paired high-sensitivity cardiac troponin I concentrations, was trained on 3013 patients and tested on 7998 patients with suspected myocardial infarction. MI3 uses gradient boosting to compute a value (0–100) reflecting an individual’s likelihood of a diagnosis of type 1 myocardial infarction and estimates the sensitivity, negative predictive value, specificity and positive predictive value for that individual. Assessment was by calibration and area under the receiver operating characteristic curve. Secondary analysis evaluated example MI3 thresholds from the training set that identified patients as low risk (99\% sensitivity) and high risk (75\% positive predictive value), and performance at these thresholds was compared in the test set to the 99th percentile and European Society of Cardiology rule-out pathways. Results: Myocardial infarction occurred in 404 (13.4\%) patients in the training set and 849 (10.6\%) patients in the test set. MI3 was well calibrated with a very high area under the receiver operating characteristic curve of 0.963 [0.956–0.971] in the test set and similar performance in early and late presenters. Example MI3 thresholds identifying low- and high-risk patients in the training set were 1.6 and 49.7, respectively. In the test set, MI3 values were {$<$}1.6 in 69.5\% with a negative predictive value of 99.7\% (99.5–99.8\%) and sensitivity of 97.8\% (96.7–98.7\%), and were ≥49.7 in 10.6\% with a positive predictive value of 71.8\% (68.9–75.0\%) and specificity of 96.7\% (96.3–97.1\%). Using these thresholds, MI3 performed better than the European Society of Cardiology 0/3-hour pathway (sensitivity, 82.5\% [74.5–88.8\%]; specificity, 92.2\% [90.7–93.5\%]) and the 99th percentile at any time point (sensitivity, 89.6\% [87.4–91.6\%]); specificity, 89.3\% [88.6–90.0\%]). Conclusions: Using machine learning, MI3 provides an individualized and objective assessment of the likelihood of myocardial infarction, which can be used to identify low- and high-risk patients who may benefit from earlier clinical decisions. Clinical Trial Registration: URL: https://www.anzctr.org.au. Unique identifier: ACTRN12616001441404.},
  keywords = {acute coronary syndrome,machine learning,myocardial infarction,troponin},
  file = {C:\Users\sdp490\Zotero\storage\4F8YPMCT\Than et al. - 2019 - Machine Learning to Predict the Likelihood of Acut.pdf}
}

@article{thompsonStatinAssociated2003,
  title = {Statin-{{Associated Myopathy}}},
  author = {Thompson, Paul D. and Clarkson, Priscilla and Karas, Richard H.},
  date = {2003-04-02},
  journaltitle = {JAMA},
  shortjournal = {JAMA},
  volume = {289},
  number = {13},
  pages = {1681--1690},
  issn = {0098-7484},
  doi = {10.1001/jama.289.13.1681},
  abstract = {Statins (3-hydroxy-3-methylglutaryl coenzyme A reductase inhibitors) are associated with skeletal muscle complaints, including clinically important myositis and rhabdomyolysis, mild serum creatine kinase (CK) elevations, myalgia with and without elevated CK levels, muscle weakness, muscle cramps, and persistent myalgia and CK elevations after statin withdrawal. We performed a literature review to provide a clinical summary of statin-associated myopathy and discuss possible mediating mechanisms. We also update the US Food and Drug Administration (FDA) reports on statin-associated rhabdomyolysis. Articles on statin myopathy were identified via a PubMed search through November 2002 and articles on statin clinical trials, case series, and review articles were identified via a PubMed search through January 2003. Adverse event reports of statin-associated rhabdomyolysis were also collected from the FDA MEDWATCH database. The literature review found that reports of muscle problems during statin clinical trials are extremely rare. The FDA MEDWATCH Reporting System lists 3339 cases of statin-associated rhabdomyolysis reported between January 1, 1990, and March 31, 2002. Cerivastatin was the most commonly implicated statin. Few data are available regarding the frequency of less-serious events such as muscle pain and weakness, which may affect 1\% to 5\% of patients. The risk of rhabdomyolysis and other adverse effects with statin use can be exacerbated by several factors, including compromised hepatic and renal function, hypothyroidism, diabetes, and concomitant medications. Medications such as the fibrate gemfibrozil alter statin metabolism and increase statin plasma concentration. How statins injure skeletal muscle is not clear, although recent evidence suggests that statins reduce the production of small regulatory proteins that are important for myocyte maintenance.},
  file = {C:\Users\sdp490\Zotero\storage\TQIDEU82\196305.html}
}

@incollection{thornPharmGKB2013,
  title = {{{PharmGKB}}: {{The Pharmacogenomics Knowledge Base}}},
  shorttitle = {{{PharmGKB}}},
  booktitle = {Pharmacogenomics: {{Methods}} and {{Protocols}}},
  author = {Thorn, Caroline F. and Klein, Teri E. and Altman, Russ B.},
  editor = {Innocenti, Federico and family=Schaik, given=Ron H.N., prefix=van, useprefix=true},
  date = {2013},
  series = {Methods in {{Molecular Biology}}},
  pages = {311--320},
  publisher = {{Humana Press}},
  location = {{Totowa, NJ}},
  doi = {10.1007/978-1-62703-435-7_20},
  abstract = {The Pharmacogenomics Knowledge Base, PharmGKB, is an interactive tool for researchers investigating how genetic variation affects drug response. The PharmGKB Web site, http://www.pharmgkb.org, displays genotype, molecular, and clinical knowledge integrated into pathway representations and Very Important Pharmacogene (VIP) summaries with links to additional external resources. Users can search and browse the knowledgebase by genes, variants, drugs, diseases, and pathways. Registration is free to the entire research community, but subject to agreement to use for research purposes only and not to redistribute. Registered users can access and download data to aid in the design of future pharmacogenetics and pharmacogenomics studies.},
  isbn = {978-1-62703-435-7},
  langid = {english},
  keywords = {Database,Genotype,Pathways,Pharmacogenes,Pharmacogenetics,Pharmacogenomics,PharmGKB,Phenotype,VIP genes},
  file = {C:\Users\sdp490\Zotero\storage\5EIWWJ3I\Thorn et al. - 2013 - PharmGKB The Pharmacogenomics Knowledge Base.pdf}
}

@article{thygesenFourth2019,
  title = {Fourth Universal Definition of Myocardial Infarction (2018)},
  author = {Thygesen, Kristian and Alpert, Joseph S and Jaffe, Allan S and Chaitman, Bernard R and Bax, Jeroen J and Morrow, David A and White, Harvey D and {ESC Scientific Document Group}},
  date = {2019-01-14},
  journaltitle = {European Heart Journal},
  shortjournal = {European Heart Journal},
  volume = {40},
  number = {3},
  pages = {237--269},
  issn = {0195-668X},
  doi = {10.1093/eurheartj/ehy462},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\HKHWV4QB\\Thygesen et al. - 2019 - Fourth universal definition of myocardial infarcti.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\8J353BTK\\5079081.html}
}

@article{tomasevClinically2019,
  title = {A Clinically Applicable Approach to Continuous Prediction of Future Acute Kidney Injury},
  author = {Tomašev, Nenad and Glorot, Xavier and Rae, Jack W. and Zielinski, Michal and Askham, Harry and Saraiva, Andre and Mottram, Anne and Meyer, Clemens and Ravuri, Suman and Protsyuk, Ivan and Connell, Alistair and Hughes, Cían O. and Karthikesalingam, Alan and Cornebise, Julien and Montgomery, Hugh and Rees, Geraint and Laing, Chris and Baker, Clifton R. and Peterson, Kelly and Reeves, Ruth and Hassabis, Demis and King, Dominic and Suleyman, Mustafa and Back, Trevor and Nielson, Christopher and Ledsam, Joseph R. and Mohamed, Shakir},
  date = {2019-08},
  journaltitle = {Nature},
  volume = {572},
  number = {7767},
  pages = {116--119},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1390-1},
  abstract = {The early prediction of deterioration could have an important role in supporting healthcare professionals, as an estimated 11\% of deaths in hospital follow a failure to promptly recognize and treat deteriorating patients1. To achieve this goal requires predictions of patient risk that are continuously updated and accurate, and delivered at an individual level with sufficient context and enough time to act. Here we develop a deep learning approach for the continuous risk prediction of future deterioration in patients, building on recent work that models adverse events from electronic health records2–17 and using acute kidney injury—a common and potentially life-threatening condition18—as an exemplar. Our model was developed on a large, longitudinal dataset of electronic health records that cover diverse clinical environments, comprising 703,782~adult patients across 172~inpatient and 1,062~outpatient sites. Our model predicts 55.8\% of all inpatient episodes of acute kidney injury, and 90.2\% of all acute kidney injuries that required subsequent administration of dialysis, with a lead time of up to 48~h and a ratio of 2~false alerts for every true alert. In addition to predicting future acute kidney injury, our model provides confidence assessments and a list of the clinical features that are most salient to each prediction, alongside predicted future trajectories for clinically relevant blood tests9. Although the recognition and prompt treatment of acute kidney injury is known to be challenging, our approach may offer opportunities for identifying patients at risk within a time window that enables early treatment.},
  issue = {7767},
  langid = {english},
  keywords = {Predictive markers,Preventive medicine,Translational research},
  file = {C:\Users\sdp490\Zotero\storage\BD2KEQDL\Tomašev et al. - 2019 - A clinically applicable approach to continuous pre.pdf}
}

@article{tomasevUse2021,
  title = {Use of Deep Learning to Develop Continuous-Risk Models for Adverse Event Prediction from Electronic Health Records},
  author = {Tomašev, Nenad and Harris, Natalie and Baur, Sebastien and Mottram, Anne and Glorot, Xavier and Rae, Jack W. and Zielinski, Michal and Askham, Harry and Saraiva, Andre and Magliulo, Valerio and Meyer, Clemens and Ravuri, Suman and Protsyuk, Ivan and Connell, Alistair and Hughes, Cían O. and Karthikesalingam, Alan and Cornebise, Julien and Montgomery, Hugh and Rees, Geraint and Laing, Chris and Baker, Clifton R. and Osborne, Thomas F. and Reeves, Ruth and Hassabis, Demis and King, Dominic and Suleyman, Mustafa and Back, Trevor and Nielson, Christopher and Seneviratne, Martin G. and Ledsam, Joseph R. and Mohamed, Shakir},
  date = {2021-06},
  journaltitle = {Nature Protocols},
  shortjournal = {Nat Protoc},
  volume = {16},
  number = {6},
  pages = {2765--2787},
  publisher = {{Nature Publishing Group}},
  issn = {1750-2799},
  doi = {10.1038/s41596-021-00513-5},
  abstract = {Early prediction of patient outcomes is important for targeting preventive care. This protocol describes a practical workflow for developing deep-learning risk models that can predict various clinical and operational outcomes from structured electronic health record (EHR) data. The protocol comprises five main stages: formal problem definition, data pre-processing, architecture selection, calibration and uncertainty, and generalizability evaluation. We have applied the workflow to four endpoints (acute kidney injury, mortality, length of stay and 30-day hospital readmission). The workflow can enable continuous (e.g., triggered every 6 h) and static (e.g., triggered at 24 h after admission) predictions. We also provide an open-source codebase that illustrates some key principles in EHR modeling. This protocol can be used by interdisciplinary teams with programming and clinical expertise to build deep-learning prediction models with alternate data sources and prediction tasks.},
  issue = {6},
  langid = {english},
  keywords = {Machine learning,Predictive markers,Software,Translational research},
  file = {C:\Users\sdp490\Zotero\storage\ICC3UGDA\Tomašev et al. - 2021 - Use of deep learning to develop continuous-risk mo.pdf}
}

@article{topolHighperformance2019,
  title = {High-Performance Medicine: The Convergence of Human and Artificial Intelligence},
  shorttitle = {High-Performance Medicine},
  author = {Topol, Eric J.},
  date = {2019-01},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {25},
  number = {1},
  pages = {44--56},
  publisher = {{Nature Publishing Group}},
  doi = {10.1038/s41591-018-0300-7},
  abstract = {The use of artificial intelligence, and the deep-learning subtype in particular, has been enabled by the use of labeled big data, along with markedly enhanced computing power and cloud storage, across all sectors. In medicine, this is beginning to have an impact at three levels: for clinicians, predominantly via rapid, accurate image interpretation; for health systems, by improving workflow and the potential for reducing medical errors; and for patients, by enabling them to process their own data to promote health. The current limitations, including bias, privacy and security, and lack of transparency, along with the future directions of these applications will be discussed in this article. Over time, marked improvements in accuracy, productivity, and workflow will likely be actualized, but whether that will be used to improve the patient–doctor relationship or facilitate its erosion remains to be seen.},
  issue = {1},
  langid = {english},
  keywords = {Health care,Machine learning}
}

@book{tutzModeling2016,
  title = {Modeling {{Discrete Time-to-Event Data}}},
  author = {Tutz, Gerhard and Schmid, Matthias},
  date = {2016-06-22},
  edition = {1st ed. 2016 edition},
  publisher = {{Springer}},
  location = {{New York, NY}},
  abstract = {This book focuses on statistical methods for the analysis of discrete failure times. Failure time analysis is one of the most important fields in statistical research, with applications affecting a wide range of disciplines, in particular, demography, econometrics, epidemiology and clinical research. Although there are a large variety of statistical methods for failure time analysis, many techniques are designed for failure times that are measured on a continuous scale. In empirical studies, however, failure times are often discrete, either because they have been measured in intervals (e.g., quarterly or yearly) or because they have been rounded or grouped. The book covers well-established methods like life-table analysis and discrete hazard regression models, but also introduces state-of-the art techniques for model evaluation, nonparametric estimation and variable selection. Throughout, the methods are illustrated by real life applications, and relationships to survival analysis in continuous time are explained. Each section includes a set of exercises on the respective topics. Various functions and tools for the analysis of discrete survival data are collected in the R package discSurv that accompanies the book.},
  isbn = {978-3-319-28156-8},
  langid = {english},
  pagetotal = {257}
}

@article{vanderveldenExplainable2022,
  title = {Explainable Artificial Intelligence ({{XAI}}) in Deep Learning-Based Medical Image Analysis},
  author = {family=Velden, given=Bas H. M., prefix=van der, useprefix=true and Kuijf, Hugo J. and Gilhuijs, Kenneth G. A. and Viergever, Max A.},
  date = {2022-07-01},
  journaltitle = {Medical Image Analysis},
  shortjournal = {Medical Image Analysis},
  volume = {79},
  pages = {102470},
  issn = {1361-8415},
  doi = {10.1016/j.media.2022.102470},
  abstract = {With an increase in deep learning-based methods, the call for explainability of such methods grows, especially in high-stakes decision making areas such as medical image analysis. This survey presents an overview of explainable artificial intelligence (XAI) used in deep learning-based medical image analysis. A framework of XAI criteria is introduced to classify deep learning-based medical image analysis methods. Papers on XAI techniques in medical image analysis are then surveyed and categorized according to the framework and according to anatomical location. The paper concludes with an outlook of future opportunities for XAI in medical image analysis.},
  langid = {english},
  keywords = {Deep learning,Explainable artificial intelligence,Interpretable deep learning,Medical image analysis,Survey},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\VBMTIC9N\\van der Velden et al. - 2022 - Explainable artificial intelligence (XAI) in deep .pdf;C\:\\Users\\sdp490\\Zotero\\storage\\ZZ4VXBJK\\S1361841522001177.html}
}

@article{visseren20212021,
  title = {2021 {{ESC Guidelines}} on Cardiovascular Disease Prevention in Clinical Practice},
  shorttitle = {2021 {{ESC Guidelines}} on Cardiovascular Disease Prevention in Clinical Practice},
  author = {Visseren, Frank L J and Mach, François and Smulders, Yvo M and Carballo, David and Koskinas, Konstantinos C and Bäck, Maria and Benetos, Athanase and Biffi, Alessandro and Boavida, José-Manuel and Capodanno, Davide and Cosyns, Bernard and Crawford, Carolyn and Davos, Constantinos H and Desormais, Ileana and Di Angelantonio, Emanuele and Franco, Oscar H and Halvorsen, Sigrun and Hobbs, F D Richard and Hollander, Monika and Jankowska, Ewa A and Michal, Matthias and Sacco, Simona and Sattar, Naveed and Tokgozoglu, Lale and Tonstad, Serena and Tsioufis, Konstantinos P and family=Dis, given=Ineke, prefix=van, useprefix=true and family=Gelder, given=Isabelle C, prefix=van, useprefix=true and Wanner, Christoph and Williams, Bryan and {ESC Scientific Document Group}},
  date = {2021-09-07},
  journaltitle = {European Heart Journal},
  shortjournal = {European Heart Journal},
  volume = {42},
  number = {34},
  pages = {3227--3337},
  issn = {0195-668X},
  doi = {10.1093/eurheartj/ehab484},
  abstract = {All experts involved in the development of these guidelines have submitted declarations of interest. These have been compiled in a report and published in a supplementary document simultaneously to the guidelines. The report is also available on the ESC website www.escardio.org/guidelines},
  file = {C:\Users\sdp490\Zotero\storage\DAKXS85B\Visseren et al. - 2021 - 2021 ESC Guidelines on cardiovascular disease prev.pdf}
}

@online{wiegrebeDeep2023,
  title = {Deep {{Learning}} for {{Survival Analysis}}: {{A Review}}},
  shorttitle = {Deep {{Learning}} for {{Survival Analysis}}},
  author = {Wiegrebe, Simon and Kopper, Philipp and Sonabend, Raphael and Bischl, Bernd and Bender, Andreas},
  date = {2023-07-12},
  eprint = {2305.14961},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2305.14961},
  urldate = {2023-09-14},
  abstract = {The influx of deep learning (DL) techniques into the field of survival analysis in recent years has led to substantial methodological progress; for instance, learning from unstructured or high-dimensional data such as images, text or omics data. In this work, we conduct a comprehensive systematic review of DL-based methods for time-to-event analysis, characterizing them according to both survival- and DL-related attributes. In summary, the reviewed methods often address only a small subset of tasks relevant to time-to-event data - e.g., single-risk right-censored data - and neglect to incorporate more complex settings. Our findings are summarized in an editable, open-source, interactive table: https://survival-org.github.io/DL4Survival. As this research area is advancing rapidly, we encourage community contribution in order to keep this database up to date.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\GDXYM2Q3\\Wiegrebe et al. - 2023 - Deep Learning for Survival Analysis A Review.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\URAKYSQW\\2305.html}
}

@online{wiegrebeDeep2023a,
  title = {Deep {{Learning}} for {{Survival Analysis}}: {{A Review}}},
  shorttitle = {Deep {{Learning}} for {{Survival Analysis}}},
  author = {Wiegrebe, Simon and Kopper, Philipp and Sonabend, Raphael and Bischl, Bernd and Bender, Andreas},
  date = {2023-07-12},
  eprint = {2305.14961},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2305.14961},
  urldate = {2023-11-17},
  abstract = {The influx of deep learning (DL) techniques into the field of survival analysis in recent years has led to substantial methodological progress; for instance, learning from unstructured or high-dimensional data such as images, text or omics data. In this work, we conduct a comprehensive systematic review of DL-based methods for time-to-event analysis, characterizing them according to both survival- and DL-related attributes. In summary, the reviewed methods often address only a small subset of tasks relevant to time-to-event data - e.g., single-risk right-censored data - and neglect to incorporate more complex settings. Our findings are summarized in an editable, open-source, interactive table: https://survival-org.github.io/DL4Survival. As this research area is advancing rapidly, we encourage community contribution in order to keep this database up to date.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\CAWUSTWG\\Wiegrebe et al. - 2023 - Deep Learning for Survival Analysis A Review.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\TCP2Z7AM\\2305.html}
}

@article{yangHyperparameter2020,
  title = {On Hyperparameter Optimization of Machine Learning Algorithms: {{Theory}} and Practice},
  shorttitle = {On Hyperparameter Optimization of Machine Learning Algorithms},
  author = {Yang, Li and Shami, Abdallah},
  date = {2020-11-20},
  journaltitle = {Neurocomputing},
  shortjournal = {Neurocomputing},
  volume = {415},
  pages = {295--316},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2020.07.061},
  abstract = {Machine learning algorithms have been used widely in various applications and areas. To fit a machine learning model into different problems, its hyper-parameters must be tuned. Selecting the best hyper-parameter configuration for machine learning models has a direct impact on the model’s performance. It often requires deep knowledge of machine learning algorithms and appropriate hyper-parameter optimization techniques. Although several automatic optimization techniques exist, they have different strengths and drawbacks when applied to different types of problems. In this paper, optimizing the hyper-parameters of common machine learning models is studied. We introduce several state-of-the-art optimization techniques and discuss how to apply them to machine learning algorithms. Many available libraries and frameworks developed for hyper-parameter optimization problems are provided, and some open challenges of hyper-parameter optimization research are also discussed in this paper. Moreover, experiments are conducted on benchmark datasets to compare the performance of different optimization methods and provide practical examples of hyper-parameter optimization. This survey paper will help industrial users, data analysts, and researchers to better develop machine learning models by identifying the proper hyper-parameter configurations effectively.},
  keywords = {Bayesian optimization,Genetic algorithm,Grid search,Hyper-parameter optimization,Machine learning,Particle swarm optimization},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\AP99QZRH\\Yang and Shami - 2020 - On hyperparameter optimization of machine learning.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\FP3WMAC9\\S0925231220311693.html}
}

@inproceedings{yuLearning2011,
  title = {Learning {{Patient-Specific Cancer Survival Distributions}} as a {{Sequence}} of {{Dependent Regressors}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Yu, Chun-Nam and Greiner, Russell and Lin, Hsiu-Chin and Baracos, Vickie},
  date = {2011},
  volume = {24},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2011/hash/1019c8091693ef5c5f55970346633f92-Abstract.html},
  urldate = {2023-11-16},
  abstract = {An accurate model of patient survival time can help in the treatment and care of cancer patients. The common practice of providing survival time estimates based only on population averages for the site and stage of cancer ignores many important individual differences among patients. In this paper, we propose a local regression method for learning patient-specific survival time distribution based on patient attributes such as blood tests and clinical assessments. When tested on a cohort of more than 2000 cancer patients, our method gives survival time predictions that are much more accurate than popular survival analysis models such as the Cox and Aalen regression models. Our results also show that using patient-specific attributes can reduce the prediction error on survival time by as much as 20\% when compared to using cancer site and stage only.},
  file = {C:\Users\sdp490\Zotero\storage\U8YRFLDE\Yu et al. - 2011 - Learning Patient-Specific Cancer Survival Distribu.pdf}
}

@article{zhaoDeep2020,
  title = {Deep {{Neural Networks}} for {{Survival Analysis Using Pseudo Values}}},
  author = {Zhao, Lili and Feng, Dai},
  date = {2020-11},
  journaltitle = {IEEE Journal of Biomedical and Health Informatics},
  volume = {24},
  number = {11},
  pages = {3308--3314},
  issn = {2168-2208},
  doi = {10.1109/JBHI.2020.2980204},
  abstract = {There has been increasing interest in modelling survival data using deep learning methods in medical research. Current approaches have focused on designing special cost functions to handle censored survival data. We propose a very different method with two simple steps. In the first step, we transform each subject's survival time into a series of jackknife pseudo conditional survival probabilities and then use these pseudo probabilities as a quantitative response variable in the deep neural network model. By using the pseudo values, we reduce a complex survival analysis to a standard regression problem, which greatly simplifies the neural network construction. Our two-step approach is simple, yet very flexible in making risk predictions for survival data, which is very appealing from the practice point of view. The source code is freely available at http://github.com/lilizhaoUM/DNNSurv.},
  eventtitle = {{{IEEE Journal}} of {{Biomedical}} and {{Health Informatics}}},
  keywords = {Adaptation models,Analytical models,Biological system modeling,Data models,Deep learning,Hazards,Informatics,IPCW,neural network,Neural networks,pseudo probability,risk prediction,survival outcome},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\UBZ94MHZ\\Zhao and Feng - 2020 - Deep Neural Networks for Survival Analysis Using P.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\AD7MIKBS\\9034100.html}
}
