@article{aalenEmpirical1978,
  title = {An {{Empirical Transition Matrix}} for {{Non-Homogeneous Markov Chains Based}} on {{Censored Observations}}},
  author = {Aalen, Odd O. and Johansen, Søren},
  date = {1978},
  journaltitle = {Scandinavian Journal of Statistics},
  volume = {5},
  number = {3},
  pages = {141--150},
  publisher = {{[Board of the Foundation of the Scandinavian Journal of Statistics, Wiley]}},
  issn = {0303-6898},
  url = {https://www.jstor.org/stable/4615704},
  urldate = {2023-11-08},
  abstract = {A product limit estimator is suggested for the transition probabilities of a non-homogeneous Markov chain with finitely many states. The estimator is expressed as a product integral and its properties are studied by means of the theory of square integrable martingales.},
  file = {C:\Users\sdp490\Zotero\storage\JYVEQ5DP\Aalen and Johansen - 1978 - An Empirical Transition Matrix for Non-Homogeneous.pdf}
}

@online{aasExplaining2020,
  title = {Explaining Individual Predictions When Features Are Dependent: {{More}} Accurate Approximations to {{Shapley}} Values},
  shorttitle = {Explaining Individual Predictions When Features Are Dependent},
  author = {Aas, Kjersti and Jullum, Martin and Løland, Anders},
  date = {2020-02-06},
  eprint = {1903.10464},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1903.10464},
  urldate = {2023-11-03},
  abstract = {Explaining complex or seemingly simple machine learning models is an important practical problem. We want to explain individual predictions from a complex machine learning model by learning simple, interpretable explanations. Shapley values is a game theoretic concept that can be used for this purpose. The Shapley value framework has a series of desirable theoretical properties, and can in principle handle any predictive model. Kernel SHAP is a computationally efficient approximation to Shapley values in higher dimensions. Like several other existing methods, this approach assumes that the features are independent, which may give very wrong explanations. This is the case even if a simple linear model is used for predictions. In this paper, we extend the Kernel SHAP method to handle dependent features. We provide several examples of linear and non-linear models with various degrees of feature dependence, where our method gives more accurate approximations to the true Shapley values. We also propose a method for aggregating individual Shapley values, such that the prediction can be explained by groups of dependent variables.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\X7FN6KBX\\Aas et al. - 2020 - Explaining individual predictions when features ar.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\5PIJGP9D\\1903.html}
}

@article{adesCardiac2001,
  title = {Cardiac {{Rehabilitation}} and {{Secondary Prevention}} of {{Coronary Heart Disease}}},
  author = {Ades, Philip A.},
  date = {2001-09-20},
  journaltitle = {New England Journal of Medicine},
  volume = {345},
  number = {12},
  eprint = {11565523},
  eprinttype = {pmid},
  pages = {892--902},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJMra001529},
  url = {https://doi.org/10.1056/NEJMra001529},
  urldate = {2023-10-09},
  abstract = {Coronary heart disease is the leading cause of death in the United States among men and women.1 It is also a major cause of physical disability, particularly in the rapidly growing population of elderly persons.2,3 In 1997, acute myocardial infarction was diagnosed in 1.1 million Americans, and 800,000 patients underwent coronary revascularization.1 The prevention of subsequent coronary events and the maintenance of physical functioning in such patients are major challenges in preventive care. Cardiac-rehabilitation programs were first developed in the 1960s,4–6 once the benefits of ambulation during prolonged hospitalization for coronary events had been recognized.7 After discharge from . . .}
}

@inproceedings{akibaOptuna2019,
  title = {Optuna: {{A Next-generation Hyperparameter Optimization Framework}}},
  shorttitle = {Optuna},
  author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
  date = {2019-07-25},
  pages = {2623--2631},
  publisher = {{ACM}},
  location = {{Anchorage AK USA}},
  doi = {10.1145/3292500.3330701},
  url = {https://dl.acm.org/doi/10.1145/3292500.3330701},
  urldate = {2023-11-01},
  eventtitle = {{{KDD}} '19: {{The}} 25th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  isbn = {978-1-4503-6201-6},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\G3FVXQ8S\Akiba et al. - 2019 - Optuna A Next-generation Hyperparameter Optimizat.pdf}
}

@article{anderson20122013,
  title = {2012 {{Update}} of the {{Canadian Cardiovascular Society Guidelines}} for the {{Diagnosis}} and {{Treatment}} of {{Dyslipidemia}} for the {{Prevention}} of {{Cardiovascular Disease}} in the {{Adult}}},
  author = {Anderson, Todd J. and Grégoire, Jean and Hegele, Robert A. and Couture, Patrick and Mancini, G. B. John and McPherson, Ruth and Francis, Gordon A. and Poirier, Paul and Lau, David C. and Grover, Steven and Genest, Jacques and Carpentier, André C. and Dufour, Robert and Gupta, Milan and Ward, Richard and Leiter, Lawrence A. and Lonn, Eva and Ng, Dominic S. and Pearson, Glen J. and Yates, Gillian M. and Stone, James A. and Ur, Ehud},
  date = {2013-02-01},
  journaltitle = {Canadian Journal of Cardiology},
  shortjournal = {Canadian Journal of Cardiology},
  volume = {29},
  number = {2},
  pages = {151--167},
  issn = {0828-282X},
  doi = {10.1016/j.cjca.2012.11.032},
  url = {https://www.sciencedirect.com/science/article/pii/S0828282X12015103},
  urldate = {2023-11-28},
  abstract = {Many developments have occurred since the publication of the widely-used 2009 Canadian Cardiovascular Society (CCS) Dyslipidemia guidelines. Here, we present an updated version of the guidelines, incorporating new recommendations based on recent findings and harmonizing CCS guidelines with those from other Societies. The Grading of Recommendations Assessment, Development and Evaluation (GRADE) system was used, per present standards of the CCS. The total cardiovascular disease Framingham Risk Score (FRS), modified for a family history of premature coronary disease, is recommended for risk assessment. Low-density lipoprotein cholesterol remains the primary target of therapy. However, non-high density lipoprotein cholesterol has been added to apolipoprotein B as an alternate target. There is an increased emphasis on treatment of higher risk patients, including those with chronic kidney disease and high risk hypertension. The primary panel has recommended a judicious use of secondary testing for subjects in whom the need for statin therapy is unclear. Expanded information on health behaviours is presented and is the backbone of risk reduction in all subjects. Finally, a systematic approach to statin intolerance is advocated to maximize appropriate use of lipid-lowering therapy. This document presents the recommendations and principal conclusions of this process. Along with associated Supplementary Material that can be accessed online, this document will be part of a program of knowledge translation. The goal is to increase the appropriate use of evidence-based cardiovascular disease event risk assessment in the management of dyslipidemia as a fundamental means of reducing global risk in the Canadian population. Résumé De nombreux développements sont survenus depuis la publication communément utilisée des Lignes directrices 2009 de la Société canadienne de cardiologie (SCC) sur la dyslipidémie. Nous présentons ici une version mise à jour des lignes directrices, qui inclut des nouvelles recommandations fondées sur des résultats récents qui harmonisent les lignes directrices de la SCC à celles d'autres sociétés. La méthode GRADE (Grading of Recommendations Assessment, Development and Evaluation) a été utilisée selon les normes actuelles de la SCC. Le score de risque cardiovasculaire global de Framingham (SRF) total sur les maladies cardiovasculaires modifié pour tenir compte des antécédents familiaux de coronaropathie prématurée est recommandé pour l'évaluation du risque. Le cholestérol à lipoprotéines de faible densité demeure la cible principale du traitement. Cependant, le cholestérol non à lipoprotéines de haute densité a été ajouté à l'apolipoprotéine B comme autre cible. L'accent est davantage mis sur le traitement des patients exposés à un risque élevé, incluant ceux ayant une maladie rénale chronique et une hypertension à risque élevé. Le panel principal a recommandé une utilisation judicieuse d'examens secondaires des sujets chez qui la nécessité d'un traitement par des statines est incertaine. De plus en plus de renseignements sur les comportements en matière de santé sont présentés et sont les bases de la réduction du risque chez tous les sujets. Finalement, une approche systématique sur l'intolérance aux statines est recommandée pour optimiser l'utilisation de traitements hypolipidémiants. Ce document présente les recommandations et les conclusions principales de ce processus. Par les contenus complémentaires associés qui peuvent être consultés en ligne, ce document fera partie d'un programme d'application des connaissances. Le but est d'accroître l'utilisation appropriée de l'évaluation des risques d'événements cardiovasculaires fondée sur les preuves dans la prise en charge de la dyslipidémie en tant que moyen fondamental pour réduire le risque global dans la population canadienne.},
  file = {C:\Users\sdp490\Zotero\storage\Z478LM4V\S0828282X12015103.html}
}

@article{arendtExisting2020,
  title = {Existing {{Data Sources}} in {{Clinical Epidemiology}}: {{Laboratory Information System Databases}} in {{Denmark}}},
  shorttitle = {Existing {{Data Sources}} in {{Clinical Epidemiology}}},
  author = {Arendt, Johan Frederik Håkonsen and Hansen, Anette Tarp and Ladefoged, Søren Andreas and Sørensen, Henrik Toft and Pedersen, Lars and Adelborg, Kasper},
  date = {2020-05-18},
  journaltitle = {Clinical Epidemiology},
  volume = {12},
  eprint = {32547238},
  eprinttype = {pmid},
  pages = {469--475},
  publisher = {{Dove Medical Press}},
  issn = {null},
  doi = {10.2147/CLEP.S245060},
  url = {https://www.tandfonline.com/doi/abs/10.2147/CLEP.S245060},
  urldate = {2023-11-29},
  abstract = {Routine biomarker results from hospital laboratory information systems, covering hospitals and general practitioners, in Denmark are available to researchers through access to the regional Clinical Laboratory Information System Research Database at Aarhus University and the nationwide Register of Laboratory Results for Research. This review describes these two data sources. The laboratory databases have different geographical and temporal coverage. They both include individual-level biomarker results that are electronically transferred from laboratory information systems. The biomarker results can be linked to all other Danish registries at the individual level, using the unique identifier, the CPR number. The databases include variables such as the CPR number, date and time (hour and minute) of sampling, NPU code, and name of the biomarker, identification code for the laboratory and the requisitioner, the test result with the corresponding unit, and the lower and upper reference limits. Access to the two databases differs since they are hosted by two different institutions. Data cannot be transferred outside Denmark, and direct access is provided only to Danish institutions. It is concluded that access to data on routine biomarkers expands the detailed biological and clinical information available on patients in the Danish healthcare system. The full potential is enabled through linkage to other Danish healthcare registries.},
  keywords = {biomarkers,data resource,database,laboratory information systems},
  file = {C:\Users\sdp490\Zotero\storage\SAIAN5BD\Arendt et al. - 2020 - Existing Data Sources in Clinical Epidemiology La.pdf}
}

@article{austinIntroduction2016,
  title = {Introduction to the {{Analysis}} of {{Survival Data}} in the {{Presence}} of {{Competing Risks}}},
  author = {Austin, Peter C. and Lee, Douglas S. and Fine, Jason P.},
  date = {2016-02-09},
  journaltitle = {Circulation},
  volume = {133},
  number = {6},
  pages = {601--609},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIRCULATIONAHA.115.017719},
  url = {https://www.ahajournals.org/doi/full/10.1161/CIRCULATIONAHA.115.017719},
  urldate = {2023-11-08},
  abstract = {Competing risks occur frequently in the analysis of survival data. A competing risk is an event whose occurrence precludes the occurrence of the primary event of interest. In a study examining time to death attributable to cardiovascular causes, death attributable to noncardiovascular causes is a competing risk. When estimating the crude incidence of outcomes, analysts should use the cumulative incidence function, rather than the complement of the Kaplan-Meier survival function. The use of the Kaplan-Meier survival function results in estimates of incidence that are biased upward, regardless of whether the competing events are independent of one another. When fitting regression models in the presence of competing risks, researchers can choose from 2 different families of models: modeling the effect of covariates on the cause-specific hazard of the outcome or modeling the effect of covariates on the cumulative incidence function. The former allows one to estimate the effect of the covariates on the rate of occurrence of the outcome in those subjects who are currently event free. The latter allows one to estimate the effect of covariates on the absolute risk of the outcome over time. The former family of models may be better suited for addressing etiologic questions, whereas the latter model may be better suited for estimating a patient’s clinical prognosis. We illustrate the application of these methods by examining cause-specific mortality in patients hospitalized with heart failure. Statistical software code in both R and SAS is provided.},
  keywords = {cumulative incidence function,{data interpretation, statistical},incidence,{models, statistical},proportional hazards models,risk assessment,survival analysis},
  file = {C:\Users\sdp490\Zotero\storage\YEFHQGIS\Austin et al. - 2016 - Introduction to the Analysis of Survival Data in t.pdf}
}

@article{babcockCHRONIC1909,
  title = {{{CHRONIC CHOLECYSTITIS AS A CAUSE OF MYOCARDIAL INCOMPETENCE}}: {{REPORT OF THIRTEEN CASES}}},
  shorttitle = {{{CHRONIC CHOLECYSTITIS AS A CAUSE OF MYOCARDIAL INCOMPETENCE}}},
  author = {BABCOCK, ROBERT H.},
  date = {1909-06-12},
  journaltitle = {Journal of the American Medical Association},
  shortjournal = {Journal of the American Medical Association},
  volume = {LII},
  number = {24},
  pages = {1904--1911},
  issn = {0002-9955},
  doi = {10.1001/jama.1909.25420500006002},
  url = {https://doi.org/10.1001/jama.1909.25420500006002},
  urldate = {2023-12-06},
  abstract = {It is said that one out of every ten adults has disease of the gall bladder and that one out of every thirteen has gallstones. If these figures are only approximately correct, there is certainly a remarkable discrepancy between the frequency of the occurrence and of the clinical recognition of chronic cholecystitis. This discrepancy is due partly to the ignorance of general practitioners concerning its frequency and partly to the obscurity of its symptoms. Yet when one's attention has been once directed to the subject, one is able to recognize certain symptoms which are very suggestive if not actually convincing.Prominent among these is indigestion or stomach trouble, with or without more or less epigastric distress, distention or uneasiness coming on several hours after a meal and accompanied or relieved by eructations of gas. Not uncommonly these symptoms of indigestion occur at night, often waking the individual from sleep toward},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\MY4MUY4I\\BABCOCK - 1909 - CHRONIC CHOLECYSTITIS AS A CAUSE OF MYOCARDIAL INC.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\Z3W8HS54\\429777.html}
}

@article{bergstraRandom2012,
  title = {Random {{Search}} for {{Hyper-Parameter Optimization}}},
  author = {Bergstra, James and Bengio, Yoshua},
  date = {2012},
  journaltitle = {Journal of Machine Learning Research},
  volume = {13},
  number = {10},
  pages = {281--305},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v13/bergstra12a.html},
  urldate = {2023-10-29},
  abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent "High Throughput" methods achieve surprising success−they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
  file = {C:\Users\sdp490\Zotero\storage\KZ2DG8CS\Bergstra and Bengio - 2012 - Random Search for Hyper-Parameter Optimization.pdf}
}

@article{biganzoliFeed1998,
  title = {Feed Forward Neural Networks for the Analysis of Censored Survival Data: A Partial Logistic Regression Approach},
  shorttitle = {Feed Forward Neural Networks for the Analysis of Censored Survival Data},
  author = {Biganzoli, Elia and Boracchi, Patrizia and Mariani, Luigi and Marubini, Ettore},
  date = {1998},
  journaltitle = {Statistics in Medicine},
  volume = {17},
  number = {10},
  pages = {1169--1186},
  issn = {1097-0258},
  doi = {10.1002/(SICI)1097-0258(19980530)17:10<1169::AID-SIM796>3.0.CO;2-D},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0258%2819980530%2917%3A10%3C1169%3A%3AAID-SIM796%3E3.0.CO%3B2-D},
  urldate = {2023-06-23},
  abstract = {Flexible modelling in survival analysis can be useful both for exploratory and predictive purposes. Feed forward neural networks were recently considered for flexible non-linear modelling of censored survival data through the generalization of both discrete and continuous time models. We show that by treating the time interval as an input variable in a standard feed forward network with logistic activation and entropy error function, it is possible to estimate smoothed discrete hazards as conditional probabilities of failure. We considered an easily implementable approach with a fast selection criteria of the best configurations. Examples on data sets from two clinical trials are provided. The proposed artificial neural network (ANN) approach can be applied for the estimation of the functional relationships between covariates and time in survival data to improve model predictivity in the presence of complex prognostic relationships. © 1998 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\QA8QP2FL\(SICI)1097-0258(19980530)17101169AID-SIM7963.0.html}
}

@book{bishopNeural1995,
  title = {Neural {{Networks}} for {{Pattern Recognition}}},
  author = {Bishop, Christopher M.},
  date = {1995-11-23},
  eprint = {T0S0BgAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Clarendon Press}},
  abstract = {This book provides the first comprehensive treatment of feed-forward neural networks from the perspective of statistical pattern recognition. After introducing the basic concepts of pattern recognition, the book describes techniques for modelling probability density functions, and discusses the properties and relative merits of the multi-layer perceptron and radial basis function network models. It also motivates the use of various forms of error functions, and reviews the principal algorithms for error function minimization. As well as providing a detailed discussion of learning and generalization in neural networks, the book also covers the important topics of data processing, feature extraction, and prior knowledge. The book concludes with an extensive treatment of Bayesian techniques and their applications to neural networks.},
  isbn = {978-0-19-853864-6},
  langid = {english},
  pagetotal = {501},
  keywords = {Computers / Artificial Intelligence / General,Computers / Data Science / Neural Networks,Computers / Optical Data Processing,Mathematics / Probability \& Statistics / General}
}

@article{blancheCindex2019,
  title = {The C-Index Is Not Proper for the Evaluation of t-Year Predicted Risks},
  author = {Blanche, Paul and Kattan, Michael W. and Gerds, Thomas A.},
  date = {2019-04-01},
  journaltitle = {Biostatistics (Oxford, England)},
  shortjournal = {Biostatistics},
  volume = {20},
  number = {2},
  eprint = {29462286},
  eprinttype = {pmid},
  pages = {347--357},
  issn = {1468-4357},
  doi = {10.1093/biostatistics/kxy006},
  abstract = {We show that the widely used concordance index for time to event outcome is not proper when interest is in predicting a \$t\$-year risk of an event, for example 10-year mortality. In the situation with a fixed prediction horizon, the concordance index can be higher for a misspecified model than for a correctly specified model. Impropriety happens because the concordance index assesses the order of the event times and not the order of the event status at the prediction horizon. The time-dependent area under the receiver operating characteristic curve does not have this problem and is proper in this context.},
  langid = {english},
  keywords = {Area Under Curve,Biostatistics,Concordance index,Cox regression,Discrimination ability,Humans,Model comparison,{Models, Statistical},Prognosis,Risk Assessment,ROC Curve,Survival prediction,Time Factors},
  file = {C:\Users\sdp490\Zotero\storage\AN928ELV\Blanche et al. - 2019 - The c-index is not proper for the evaluation of $t.pdf}
}

@article{brownUse1997,
  title = {On the Use of Artificial Neural Networks for the Analysis of Survival Data},
  author = {Brown, S.F. and Branford, A.J. and Moran, W.},
  date = {1997-09},
  journaltitle = {IEEE Transactions on Neural Networks},
  volume = {8},
  number = {5},
  pages = {1071--1077},
  issn = {1941-0093},
  doi = {10.1109/72.623209},
  abstract = {Artificial neural networks are a powerful tool for analyzing data sets where there are complicated nonlinear interactions between the measured inputs and the quantity to be predicted. We show that the results obtained when neural networks are applied to survival data depend critically on the treatment of censoring in the data. When the censoring is modeled correctly, neural networks are a robust model independent technique for the analysis of very large sets of survival data.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}}},
  keywords = {Artificial neural networks,Data analysis,Diseases,Independent component analysis,Neural networks,Particle measurements,Robustness,Statistical analysis,Statistics,Time measurement},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\F5XAYN5M\\Brown et al. - 1997 - On the use of artificial neural networks for the a.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\E48Q87MT\\623209.html}
}

@report{bundgaardClinical2023,
  type = {Clinical trial registration},
  title = {Clinical {{Implementation}} of a {{Novel Decision Support Tool}} in {{Patients With Ischemic Heart Disease}}},
  author = {Bundgaard, Henning},
  editora = {{Rigshospitalet, Denmark} and {Region Capital Denmark} and {Region Zealand}},
  editoratype = {collaborator},
  date = {2023-09-04},
  number = {NCT06033014},
  institution = {{clinicaltrials.gov}},
  url = {https://clinicaltrials.gov/study/NCT06033014},
  urldate = {2023-01-01},
  abstract = {The PM-Heart algorithm (PMHeartIHD) is an in-house developed software that predict the survival prognosis for the individual patient hospitalized with ischemic heart disease (IHD) after a coronary arteriography has been performed. The software is intended to be used as a clinical decision support system i.e. the calculated survival prognosis is expected to enhance the quality of the treating physician's therapeutic considerations concerning (minor) adjustments to the patients treatment and follow-up - all within the framework of the current medical guidelines. Thus, the algorithm does not "show the physician specifically what to do", but rather ensures a better knowledgebase for the overall interpretation and choice of management of the patient.}
}

@article{byrne20232023,
  title = {2023 {{ESC Guidelines}} for the Management of Acute Coronary Syndromes},
  shorttitle = {2023 {{ESC Guidelines}} for the Management of Acute Coronary Syndromes},
  author = {Byrne, Robert A and Rossello, Xavier and Coughlan, J J and Barbato, Emanuele and Berry, Colin and Chieffo, Alaide and Claeys, Marc J and Dan, Gheorghe-Andrei and Dweck, Marc R and Galbraith, Mary and Gilard, Martine and Hinterbuchner, Lynne and Jankowska, Ewa A and Jüni, Peter and Kimura, Takeshi and Kunadian, Vijay and Leosdottir, Margret and Lorusso, Roberto and Pedretti, Roberto F E and Rigopoulos, Angelos G and Rubini Gimenez, Maria and Thiele, Holger and Vranckx, Pascal and Wassmann, Sven and Wenger, Nanette Kass and Ibanez, Borja and {ESC Scientific Document Group}},
  date = {2023-08-25},
  journaltitle = {European Heart Journal},
  shortjournal = {European Heart Journal},
  pages = {ehad191},
  issn = {0195-668X},
  doi = {10.1093/eurheartj/ehad191},
  url = {https://doi.org/10.1093/eurheartj/ehad191},
  urldate = {2023-10-06},
  file = {C:\Users\sdp490\Zotero\storage\QRTH4DEH\Byrne et al. - 2023 - 2023 ESC Guidelines for the management of acute co.pdf}
}

@book{charniakIntroduction2019,
  title = {Introduction to {{Deep Learning}}},
  author = {Charniak, Eugene},
  date = {2019-01-29},
  edition = {Illustrated},
  publisher = {{The MIT Press}},
  location = {{Cambridge, Massachusetts}},
  abstract = {A project-based guide to the basics of deep learning.This concise, project-driven guide to deep learning takes readers through a series of program-writing tasks that introduce them to the use of deep learning in such areas of artificial intelligence as computer vision, natural-language processing, and reinforcement learning. The author, a longtime artificial intelligence researcher specializing in natural-language processing, covers feed-forward neural nets, convolutional neural nets, word embeddings, recurrent neural nets, sequence-to-sequence learning, deep reinforcement learning, unsupervised models, and other fundamental concepts and techniques. Students and practitioners learn the basics of deep learning by working through programs in Tensorflow, an open-source machine learning framework. “I find I learn computer science material best by sitting down and writing programs,” the author writes, and the book reflects this approach.Each chapter includes a programming project, exercises, and references for further reading. An early chapter is devoted to Tensorflow and its interface with Python, the widely used programming language. Familiarity with linear algebra, multivariate calculus, and probability and statistics is required, as is a rudimentary knowledge of programming in Python. The book can be used in both undergraduate and graduate courses; practitioners will find it an essential reference.},
  isbn = {978-0-262-03951-2},
  langid = {english},
  pagetotal = {192}
}

@book{cholletDeep2021,
  title = {Deep {{Learning}} with {{Python}}},
  author = {Chollet, Francois},
  date = {2021-12-07},
  edition = {2},
  eprint = {mjVKEAAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Manning}},
  abstract = {Unlock the groundbreaking advances of deep learning with this extensively revised edition of the bestselling original. Learn directly from the creator of Keras and master practical Python deep learning techniques that are easy to apply in the real world.In Deep Learning with Python, Second Edition you will learn:  Deep learning from first principles Image classification \& image segmentation Timeseries forecasting Text classification and machine translation Text generation, neural style transfer, and image generation  Deep Learning with Python has taught thousands of readers how to put the full capabilities of deep learning into action. This extensively revised second edition introduces deep learning using Python and Keras, and is loaded with insights for both novice and experienced ML practitioners. You’ll learn practical techniques that are easy to apply in the real world, and important theory for perfecting neural networks.  Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications.  About the technology Recent innovations in deep learning unlock exciting new software capabilities like automated language translation, image recognition, and more. Deep learning is becoming essential knowledge for every software developer, and modern tools like Keras and TensorFlow put it within your reach, even if you have no background in mathematics or data science.   About the book Deep Learning with Python, Second Edition introduces the field of deep learning using Python and the powerful Keras library. In this new edition, Keras creator François Chollet offers insights for both novice and experienced machine learning practitioners. As you move through this book, you’ll build your understanding through intuitive explanations, crisp illustrations, and clear examples. You’ll pick up the skills to start developing deep-learning applications.  What's inside  Deep learning from first principles Image classification and image segmentation Time series forecasting Text classification and machine translation Text generation, neural style transfer, and image generation  About the reader For readers with intermediate Python skills. No previous experience with Keras, TensorFlow, or machine learning is required.  About the author François Chollet is a software engineer at Google and creator of the Keras deep-learning library.  Table of Contents 1 What is deep learning? 2 The mathematical building blocks of neural networks 3 Introduction to Keras and TensorFlow 4 Getting started with neural networks: Classification and regression 5 Fundamentals of machine learning 6 The universal workflow of machine learning 7 Working with Keras: A deep dive 8 Introduction to deep learning for computer vision 9 Advanced deep learning for computer vision 10 Deep learning for timeseries 11 Deep learning for text 12 Generative deep learning 13 Best practices for the real world 14 Conclusions},
  isbn = {978-1-63835-009-5},
  langid = {english},
  pagetotal = {502},
  keywords = {Computers / Data Science / Machine Learning,Computers / Data Science / Neural Networks,Computers / Languages / Python}
}

@article{clarkMetaAnalysis2005,
  title = {Meta-{{Analysis}}: {{Secondary Prevention Programs}} for {{Patients}} with {{Coronary Artery Disease}}},
  shorttitle = {Meta-{{Analysis}}},
  author = {Clark, Alexander M. and Hartling, Lisa and Vandermeer, Ben and McAlister, Finlay A.},
  date = {2005-11},
  journaltitle = {Annals of Internal Medicine},
  shortjournal = {Ann Intern Med},
  volume = {143},
  number = {9},
  pages = {659--672},
  publisher = {{American College of Physicians}},
  issn = {0003-4819},
  doi = {10.7326/0003-4819-143-9-200511010-00010},
  url = {https://www.acpjournals.org/doi/full/10.7326/0003-4819-143-9-200511010-00010},
  urldate = {2023-10-09}
}

@article{collet20202021,
  title = {2020 {{ESC Guidelines}} for the Management of Acute Coronary Syndromes in Patients Presenting without Persistent {{ST-segment}} Elevation},
  shorttitle = {2020 {{ESC Guidelines}} for the Management of Acute Coronary Syndromes in Patients Presenting without Persistent {{ST-segment}} Elevation},
  author = {Collet, Jean-Philippe and Thiele, Holger and Barbato, Emanuele and Barthélémy, Olivier and Bauersachs, Johann and Bhatt, Deepak L and Dendale, Paul and Dorobantu, Maria and Edvardsen, Thor and Folliguet, Thierry and Gale, Chris P and Gilard, Martine and Jobs, Alexander and Jüni, Peter and Lambrinou, Ekaterini and Lewis, Basil S and Mehilli, Julinda and Meliga, Emanuele and Merkely, Béla and Mueller, Christian and Roffi, Marco and Rutten, Frans H and Sibbing, Dirk and Siontis, George C M and Chettibi, Mohammed and Hayrapetyan, Hamlet G and Metzler, Bernhard and Najafov, Ruslan and Stelmashok, Valeriy I and Claeys, Marc and Kušljugić, Zumreta and Gatzov, Plamen Marinov and Skoric, Bosko and Panayi, Georgios and Mates, Martin and Sorensen, Rikke and Shokry, Khaled and Marandi, Toomas and Kajander, Olli A and Commeau, Philippe and Aladashvili, Alexander and Massberg, Steffen and Nikas, Dimitrios and Becker, Dávid and Guðmundsdóttir, Ingibjörg J and Peace, Aaron J and Beigel, Roy and Indolfi, Ciro and Aidargaliyeva, Nazipa and Elezi, Shpend and Beishenkulov, Medet and Maca, Aija and Gustiene, Olivija and Degrell, Philippe and Cassar Maempel, Andrew and Ivanov, Victoria and Damman, Peter and Kedev, Sasko and Steigen, Terje K and Legutko, Jacek and Morais, João and Vinereanu, Dragos and Duplyakov, Dmitry and Zavatta, Marco and Pavlović, Milan and Orban, Marek and Bunc, Matjaž and Ibañez, Borja and Hofmann, Robin and Gaemperli, Oliver and Marjeh, Yassin Bani and Addad, Faouzi and Tutar, Eralp and Parkhomenko, Alexander and Karia, Nina and {ESC Scientific Document Group}},
  date = {2021-04-07},
  journaltitle = {European Heart Journal},
  shortjournal = {European Heart Journal},
  volume = {42},
  number = {14},
  pages = {1289--1367},
  issn = {0195-668X},
  doi = {10.1093/eurheartj/ehaa575},
  url = {https://doi.org/10.1093/eurheartj/ehaa575},
  urldate = {2022-02-15},
  abstract = {For the Supplementary Data which include background information and detailed discussion of the data that have provided the basis for the Guidelines see European Heart Journal online.},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\NNAT9ZEY\\Collet et al. - 2021 - 2020 ESC Guidelines for the management of acute co.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\AY7C4GES\\5898842.html}
}

@article{collinsNew2015,
  title = {A {{New Initiative}} on {{Precision Medicine}}},
  author = {Collins, Francis S. and Varmus, Harold},
  date = {2015-02-26},
  journaltitle = {New England Journal of Medicine},
  volume = {372},
  number = {9},
  eprint = {25635347},
  eprinttype = {pmid},
  pages = {793--795},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJMp1500523},
  url = {https://doi.org/10.1056/NEJMp1500523},
  urldate = {2023-05-11},
  file = {C:\Users\sdp490\Zotero\storage\YRKTA2QI\Collins and Varmus - 2015 - A New Initiative on Precision Medicine.pdf}
}

@article{coudrayClassification2018,
  title = {Classification and Mutation Prediction from Non–Small Cell Lung Cancer Histopathology Images Using Deep Learning},
  author = {Coudray, Nicolas and Ocampo, Paolo Santiago and Sakellaropoulos, Theodore and Narula, Navneet and Snuderl, Matija and Fenyö, David and Moreira, Andre L. and Razavian, Narges and Tsirigos, Aristotelis},
  date = {2018-10},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {24},
  number = {10},
  pages = {1559--1567},
  publisher = {{Nature Publishing Group}},
  issn = {1546-170X},
  doi = {10.1038/s41591-018-0177-5},
  url = {https://www.nature.com/articles/s41591-018-0177-5},
  urldate = {2023-05-09},
  abstract = {Visual inspection of histopathology slides is one of the main methods used by pathologists to assess the stage, type and subtype of lung tumors. Adenocarcinoma (LUAD) and squamous cell carcinoma (LUSC) are the most prevalent subtypes of lung cancer, and their distinction requires visual inspection by an experienced pathologist. In this study, we trained a deep convolutional neural network (inception v3) on whole-slide images obtained from The Cancer Genome Atlas to accurately and automatically classify them into LUAD, LUSC or normal lung tissue. The performance of our method is comparable to that of pathologists, with an average area under the curve (AUC) of 0.97. Our model was validated on independent datasets of frozen tissues, formalin-fixed paraffin-embedded tissues and biopsies. Furthermore, we trained the network to predict the ten most commonly mutated genes in LUAD. We found that six of them—STK11, EGFR, FAT1, SETBP1, KRAS and TP53—can be predicted from pathology images, with AUCs from 0.733 to 0.856 as measured on a held-out population. These findings suggest that deep-learning models can assist pathologists in the detection of cancer subtype or gene mutations. Our approach can be applied to any cancer type, and the code is available at https://github.com/ncoudray/DeepPATH.},
  issue = {10},
  langid = {english},
  keywords = {Machine learning},
  file = {C:\Users\sdp490\Zotero\storage\MP364ABQ\Coudray et al. - 2018 - Classification and mutation prediction from non–sm.pdf}
}

@article{coxRegression1972,
  title = {Regression {{Models}} and {{Life-Tables}}},
  author = {Cox, D. R.},
  date = {1972},
  journaltitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {34},
  number = {2},
  pages = {187--220},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {0035-9246},
  url = {https://www.jstor.org/stable/2985181},
  urldate = {2023-11-07},
  abstract = {The analysis of censored failure times is considered. It is assumed that on each individual are available values of one or more explanatory variables. The hazard function (age-specific failure rate) is taken to be a function of the explanatory variables and unknown regression coefficients multiplied by an arbitrary and unknown function of time. A conditional likelihood is obtained, leading to inferences about the unknown regression coefficients. Some generalizations are outlined.},
  file = {C:\Users\sdp490\Zotero\storage\DJEDSRA9\Cox - 1972 - Regression Models and Life-Tables.pdf}
}

@article{croweComorbidity2020,
  title = {Comorbidity Phenotypes and Risk of Mortality in Patients with Ischaemic Heart Disease in the {{UK}}},
  author = {Crowe, Francesca and Zemedikun, Dawit T. and Okoth, Kelvin and Adderley, Nicola Jaime and Rudge, Gavin and Sheldon, Mark and Nirantharakumar, Krishnarajah and Marshall, Tom},
  date = {2020-06-01},
  journaltitle = {Heart},
  shortjournal = {Heart},
  volume = {106},
  number = {11},
  eprint = {32273305},
  eprinttype = {pmid},
  pages = {810--816},
  publisher = {{BMJ Publishing Group Ltd and British Cardiovascular Society}},
  issn = {1355-6037, 1468-201X},
  doi = {10.1136/heartjnl-2019-316091},
  url = {https://heart.bmj.com/content/106/11/810},
  urldate = {2023-12-18},
  abstract = {Objectives The objective of this study is to use latent class analysis of up to 20 comorbidities in patients with a diagnosis of ischaemic heart disease (IHD) to identify clusters of comorbidities and to examine the associations between these clusters and mortality. Methods Longitudinal analysis of electronic health records in the health improvement network (THIN), a UK primary care database including 92 186 men and women aged ≥18 years with IHD and a median of 2 (IQR 1–3) comorbidities. Results Latent class analysis revealed five clusters with half categorised as a low-burden comorbidity group. After a median follow-up of 3.2 (IQR 1.4–5.8) years, 17 645 patients died. Compared with the low-burden comorbidity group, two groups of patients with a high-burden of comorbidities had the highest adjusted HR for mortality: those with vascular and musculoskeletal conditions, HR 2.38 (95\% CI 2.28 to 2.49) and those with respiratory and musculoskeletal conditions, HR 2.62 (95\% CI 2.45 to 2.79). Hazards of mortality in two other groups of patients characterised by cardiometabolic and mental health comorbidities were also higher than the low-burden comorbidity group; HR 1.46 (95\% CI 1.39 to 1.52) and 1.55 (95\% CI 1.46 to 1.64), respectively. Conclusions This analysis has identified five distinct comorbidity clusters in patients with IHD that were differentially associated with risk of mortality. These analyses should be replicated in other large datasets, and this may help shape the development of future interventions or health services that take into account the impact of these comorbidity clusters.},
  langid = {english},
  keywords = {comorbidity,ischaemic heart disease,latent class analysis,mortality,the health improvement network},
  file = {C:\Users\sdp490\Zotero\storage\V3S93Y7I\Crowe et al. - 2020 - Comorbidity phenotypes and risk of mortality in pa.pdf}
}

@article{dafniLandmark2011,
  title = {Landmark {{Analysis}} at the 25-{{Year Landmark Point}}},
  author = {Dafni, Urania},
  date = {2011-05},
  journaltitle = {Circulation: Cardiovascular Quality and Outcomes},
  volume = {4},
  number = {3},
  pages = {363--371},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIRCOUTCOMES.110.957951},
  url = {https://www.ahajournals.org/doi/10.1161/CIRCOUTCOMES.110.957951},
  urldate = {2023-12-31},
  abstract = {This statistical primer presents the landmark analysis method, exploring its appropriate use and interpretation while recognizing its limitations. This observational method is used for comparing time-to-event outcome between groups determined during study follow-up. The goal of the landmark method is to estimate in an unbiased way the time-to-event probabilities in each group conditional on the group membership of patients at a specific time point, the landmark time. The need that led to its development, the impact of the method, and its pros and cons, along with available alternative approaches, are presented. Simulations explore its performance, using realistic parameters from a recent cardiovascular study. As long as the limitations of the method are recognized and the interpretation of its results clearly reflect their “conditional” nature, landmark analysis, 25 years from its introduction, can still be of value.},
  keywords = {clinical trials,observational studies,prognostic factors,time-to-event outcome,time-varying covariate},
  file = {C:\Users\sdp490\Zotero\storage\U7G255JG\Dafni - 2011 - Landmark Analysis at the 25-Year Landmark Point.pdf}
}

@article{dainisCardiovascular2018,
  title = {Cardiovascular {{Precision Medicine}} in the {{Genomics Era}}},
  author = {Dainis, Alexandra M. and Ashley, Euan A.},
  date = {2018-04},
  journaltitle = {JACC: Basic to Translational Science},
  volume = {3},
  number = {2},
  pages = {313--326},
  publisher = {{American College of Cardiology Foundation}},
  doi = {10.1016/j.jacbts.2018.01.003},
  url = {https://www.jacc.org/doi/abs/10.1016/j.jacbts.2018.01.003},
  urldate = {2023-10-12},
  keywords = {genome sequencing,genomics,precision medicine,targeted therapeutics},
  file = {C:\Users\sdp490\Zotero\storage\V789XE8G\Dainis and Ashley - 2018 - Cardiovascular Precision Medicine in the Genomics .pdf}
}

@article{dalipartyCholecystitis2021,
  title = {Cholecystitis {{Masquerading}} as {{Cardiac Chest Pain}}: {{A Case Report}}},
  shorttitle = {Cholecystitis {{Masquerading}} as {{Cardiac Chest Pain}}},
  author = {Daliparty, Vasudev Malik and Amoozgar, Behzad and Razzeto, Alejandra and Ehsanullah, Syed Usman Mohsin and Rehman, Faseeha},
  date = {2021-09-22},
  journaltitle = {The American Journal of Case Reports},
  shortjournal = {Am J Case Rep},
  volume = {22},
  eprint = {34548467},
  eprinttype = {pmid},
  pages = {e932078-1-e932078-5},
  issn = {1941-5923},
  doi = {10.12659/AJCR.932078},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8477983/},
  urldate = {2023-12-06},
  abstract = {Patient: Male, 46-year-old ,  Final Diagnosis: Cholecystitis ,  Symptoms: Chest pain ,  Medication: — ,  Clinical Procedure: — ,  Specialty: General and Internal Medicine},
  pmcid = {PMC8477983},
  file = {C:\Users\sdp490\Zotero\storage\WVBJ5MM9\Daliparty et al. - 2021 - Cholecystitis Masquerading as Cardiac Chest Pain .pdf}
}

@online{Danish,
  title = {The Danish Clinical Quality Program (RKKP)},
  url = {https://www.rkkp.dk/in-english/},
  urldate = {2023-11-28},
  abstract = {Introduction to RKKP The Danish Clinical Quality Program\&ndash; National Clinical Registries\&nbsp; (RKKP) constitutes the infrastructure of the Danish clinica...},
  langid = {danish},
  file = {C:\Users\sdp490\Zotero\storage\MLF9IIKG\in-english.html}
}

@article{darbyRisk2013,
  title = {Risk of {{Ischemic Heart Disease}} in {{Women}} after {{Radiotherapy}} for {{Breast Cancer}}},
  author = {Darby, Sarah C. and Ewertz, Marianne and McGale, Paul and Bennet, Anna M. and Blom-Goldman, Ulla and Brønnum, Dorthe and Correa, Candace and Cutter, David and Gagliardi, Giovanna and Gigante, Bruna and Jensen, Maj-Britt and Nisbet, Andrew and Peto, Richard and Rahimi, Kazem and Taylor, Carolyn and Hall, Per},
  date = {2013-03-14},
  journaltitle = {New England Journal of Medicine},
  volume = {368},
  number = {11},
  eprint = {23484825},
  eprinttype = {pmid},
  pages = {987--998},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJMoa1209825},
  url = {https://doi.org/10.1056/NEJMoa1209825},
  urldate = {2023-12-06},
  abstract = {Randomized trials have shown that radiotherapy for early-stage breast cancer can reduce the rates of recurrence and of death from breast cancer.1,2 However, long-term follow-up in some trials has shown that radiotherapy can also increase the risk of ischemic heart disease, presumably through incidental irradiation of the heart.1,3 Radiotherapy regimens for breast cancer have changed since the women in these trials were irradiated, and the doses of radiation to which the heart is exposed are now generally lower.4 Nevertheless, in most women, the heart still receives doses of 1 to 5 Gy.5–11 Several studies have suggested that . . .},
  file = {C:\Users\sdp490\Zotero\storage\QJHTUJVH\Darby et al. - 2013 - Risk of Ischemic Heart Disease in Women after Radi.pdf}
}

@article{defauwClinically2018,
  title = {Clinically Applicable Deep Learning for Diagnosis and Referral in Retinal Disease},
  author = {De Fauw, Jeffrey and Ledsam, Joseph R. and Romera-Paredes, Bernardino and Nikolov, Stanislav and Tomasev, Nenad and Blackwell, Sam and Askham, Harry and Glorot, Xavier and O’Donoghue, Brendan and Visentin, Daniel and family=Driessche, given=George, prefix=van den, useprefix=true and Lakshminarayanan, Balaji and Meyer, Clemens and Mackinder, Faith and Bouton, Simon and Ayoub, Kareem and Chopra, Reena and King, Dominic and Karthikesalingam, Alan and Hughes, Cían O. and Raine, Rosalind and Hughes, Julian and Sim, Dawn A. and Egan, Catherine and Tufail, Adnan and Montgomery, Hugh and Hassabis, Demis and Rees, Geraint and Back, Trevor and Khaw, Peng T. and Suleyman, Mustafa and Cornebise, Julien and Keane, Pearse A. and Ronneberger, Olaf},
  date = {2018-09},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {24},
  number = {9},
  pages = {1342--1350},
  publisher = {{Nature Publishing Group}},
  issn = {1546-170X},
  doi = {10.1038/s41591-018-0107-6},
  url = {https://www.nature.com/articles/s41591-018-0107-6},
  urldate = {2023-05-09},
  abstract = {The volume and complexity of diagnostic imaging is increasing at a pace faster than the availability of human expertise to interpret it. Artificial intelligence has shown great promise in classifying two-dimensional photographs of some common diseases and typically relies on databases of millions of annotated images. Until now, the challenge of reaching the performance of expert clinicians in a real-world clinical pathway with three-dimensional diagnostic scans has remained unsolved. Here, we apply a novel deep learning architecture to a clinically heterogeneous set of three-dimensional optical coherence tomography scans from patients referred to a major eye hospital. We demonstrate performance in making a referral recommendation that reaches or exceeds that of experts on a range of sight-threatening retinal diseases after training on only 14,884 scans. Moreover, we demonstrate that the tissue segmentations produced by our architecture act as a device-independent representation; referral accuracy is maintained when using tissue segmentations from a different type of device. Our work removes previous barriers to wider clinical use without prohibitive training data requirements across multiple pathologies in a real-world setting.},
  issue = {9},
  langid = {english},
  keywords = {Diagnosis,Eye manifestations,Machine learning,Three-dimensional imaging},
  file = {C:\Users\sdp490\Zotero\storage\P5PXRBPB\De Fauw et al. - 2018 - Clinically applicable deep learning for diagnosis .pdf}
}

@article{delongComparing1988,
  title = {Comparing the Areas under Two or More Correlated Receiver Operating Characteristic Curves: A Nonparametric Approach},
  shorttitle = {Comparing the Areas under Two or More Correlated Receiver Operating Characteristic Curves},
  author = {DeLong, E. R. and DeLong, D. M. and Clarke-Pearson, D. L.},
  date = {1988-09},
  journaltitle = {Biometrics},
  shortjournal = {Biometrics},
  volume = {44},
  number = {3},
  eprint = {3203132},
  eprinttype = {pmid},
  pages = {837--845},
  issn = {0006-341X},
  abstract = {Methods of evaluating and comparing the performance of diagnostic tests are of increasing importance as new tests are developed and marketed. When a test is based on an observed variable that lies on a continuous or graded scale, an assessment of the overall value of the test can be made through the use of a receiver operating characteristic (ROC) curve. The curve is constructed by varying the cutpoint used to determine which values of the observed variable will be considered abnormal and then plotting the resulting sensitivities against the corresponding false positive rates. When two or more empirical curves are constructed based on tests performed on the same individuals, statistical analysis on differences between curves must take into account the correlated nature of the data. This paper presents a nonparametric approach to the analysis of areas under correlated ROC curves, by using the theory on generalized U-statistics to generate an estimated covariance matrix.},
  langid = {english},
  keywords = {Algorithms,Analysis of Variance,Female,Humans,Intestinal Obstruction,{Models, Statistical},Ovarian Neoplasms,Predictive Value of Tests,ROC Curve}
}

@article{dengComplexity1994,
  title = {On the {{Complexity}} of {{Cooperative Solution Concepts}}},
  author = {Deng, Xiaotie and Papadimitriou, Christos H.},
  date = {1994},
  journaltitle = {Mathematics of Operations Research},
  volume = {19},
  number = {2},
  pages = {257--266},
  publisher = {{INFORMS}},
  issn = {0364-765X},
  url = {https://www.jstor.org/stable/3690220},
  urldate = {2023-11-03},
  abstract = {We study from a complexity theoretic standpoint the various solution concepts arising in cooperative game theory. We use as a vehicle for this study a game in which the players are nodes of a graph with weights on the edges, and the value of a coalition is determined by the total weight of the edges contained in it. The Shapley value is always easy to compute. The core is easy to characterize when the game is convex, and is intractable (NP-complete) otherwise. Similar results are shown for the kernel, the nucleolus, the ε-core, and the bargaining set. As for the von Neumann-Morgenstern solution, we point out that its existence may not even be decidable. Many of these results generalize to the case in which the game is presented by a hypergraph with edges of size k {$>$} 2.},
  file = {C:\Users\sdp490\Zotero\storage\XPWZVGBI\Deng and Papadimitriou - 1994 - On the Complexity of Cooperative Solution Concepts.pdf}
}

@article{dorresteijnDevelopment2013,
  title = {Development and Validation of a Prediction Rule for Recurrent Vascular Events Based on a Cohort Study of Patients with Arterial Disease: The {{SMART}} Risk Score},
  shorttitle = {Development and Validation of a Prediction Rule for Recurrent Vascular Events Based on a Cohort Study of Patients with Arterial Disease},
  author = {Dorresteijn, Johannes A. N. and Visseren, Frank L. J. and Wassink, Annemarie M. J. and Gondrie, Martijn J. A. and Steyerberg, Ewout W. and Ridker, Paul M. and Cook, Nancy R. and family=Graaf, given=Yolanda, prefix=van der, useprefix=false and Group, on behalf of the SMART Study},
  date = {2013-06-15},
  journaltitle = {Heart},
  shortjournal = {Heart},
  volume = {99},
  number = {12},
  eprint = {23574971},
  eprinttype = {pmid},
  pages = {866--872},
  publisher = {{BMJ Publishing Group Ltd and British Cardiovascular Society}},
  issn = {1355-6037, 1468-201X},
  doi = {10.1136/heartjnl-2013-303640},
  url = {https://heart.bmj.com/content/99/12/866},
  urldate = {2023-10-09},
  abstract = {Objectives To enable risk stratification of patients with various types of arterial disease by the development and validation of models for prediction of recurrent vascular event risk based on vascular risk factors, imaging or both. Design Prospective cohort study. Setting University Medical Centre. Patients 5788 patients referred with various clinical manifestations of arterial disease between January 1996 and February 2010. Main outcome measures 788 recurrent vascular events (ie, myocardial infarction, stroke or vascular death) that were observed during 4.7 (IQR 2.3 to 7.7) years’ follow-up. Results Three Cox proportional hazards models for prediction of 10-year recurrent vascular event risk were developed based on age and sex in addition to clinical parameters (model A), carotid ultrasound findings (model B) or both (model C). Clinical parameters were medical history, current smoking, systolic blood pressure and laboratory biomarkers. In a separate part of the dataset, the concordance statistic of model A was 0.68 (95\% CI 0.64 to 0.71), compared to 0.64 (0.61 to 0.68) for model B and 0.68 (0.65 to 0.72) for model C. Goodness-of-fit and calibration of model A were adequate, also in separate subgroups of patients having coronary, cerebrovascular, peripheral artery or aneurysmal disease. Model A predicted {$<$}20\% risk in 59\% of patients, 20–30\% risk in 19\% and {$>$}30\% risk in 23\%. Conclusions Patients at high risk for recurrent vascular events can be identified based on readily available clinical characteristics.},
  langid = {english}
}

@article{drukerEfficacy2001,
  title = {Efficacy and Safety of a Specific Inhibitor of the {{BCR-ABL}} Tyrosine Kinase in Chronic Myeloid Leukemia},
  author = {Druker, B. J. and Talpaz, M. and Resta, D. J. and Peng, B. and Buchdunger, E. and Ford, J. M. and Lydon, N. B. and Kantarjian, H. and Capdeville, R. and Ohno-Jones, S. and Sawyers, C. L.},
  date = {2001-04-05},
  journaltitle = {The New England Journal of Medicine},
  shortjournal = {N Engl J Med},
  volume = {344},
  number = {14},
  eprint = {11287972},
  eprinttype = {pmid},
  pages = {1031--1037},
  issn = {0028-4793},
  doi = {10.1056/NEJM200104053441401},
  abstract = {BACKGROUND: BCR-ABL is a constitutively activated tyrosine kinase that causes chronic myeloid leukemia (CML). Since tyrosine kinase activity is essential to the transforming function of BCR-ABL, an inhibitor of the kinase could be an effective treatment for CML. METHODS: We conducted a phase 1, dose-escalating trial of STI571 (formerly known as CGP 57148B), a specific inhibitor of the BCR-ABL tyrosine kinase. STI571 was administered orally to 83 patients with CML in the chronic phase in whom treatment with interferon alfa had failed. Patients were successively assigned to 1 of 14 doses ranging from 25 to 1000 mg per day. RESULTS: Adverse effects of STI571 were minimal; the most common were nausea, myalgias, edema, and diarrhea. A maximal tolerated dose was not identified. Complete hematologic responses were observed in 53 of 54 patients treated with daily doses of 300 mg or more and typically occurred in the first four weeks of therapy. Of the 54 patients treated with doses of 300 mg or more, cytogenetic responses occurred in 29, including 17 (31 percent of the 54 patients who received this dose) with major responses (0 to 35 percent of cells in metaphase positive for the Philadelphia chromosome); 7 of these patients had complete cytogenetic remissions. CONCLUSIONS: STI571 is well tolerated and has significant antileukemic activity in patients with CML in whom treatment with interferon alfa had failed. Our results provide evidence of the essential role of BCR-ABL tyrosine kinase activity in CML and demonstrate the potential for the development of anticancer drugs based on the specific molecular abnormality present in a human cancer.},
  langid = {english},
  keywords = {Adult,Aged,Antineoplastic Agents,Benzamides,Blood Cell Count,{Dose-Response Relationship, Drug},Enzyme Inhibitors,Female,{Fusion Proteins, bcr-abl},Humans,Imatinib Mesylate,Interferon-alpha,{Leukemia, Myelogenous, Chronic, BCR-ABL Positive},Male,Middle Aged,Phosphorylation,Piperazines,Protein-Tyrosine Kinases,Pyrimidines,Recurrence,Remission Induction}
}

@article{dunlayMultimorbidity2016,
  title = {Multimorbidity in {{Older Patients}} with {{Cardiovascular Disease}}},
  author = {Dunlay, Shannon M. and Chamberlain, Alanna M.},
  date = {2016-01},
  journaltitle = {Current cardiovascular risk reports},
  shortjournal = {Curr Cardiovasc Risk Rep},
  volume = {10},
  eprint = {27274775},
  eprinttype = {pmid},
  pages = {3},
  issn = {1932-9520},
  doi = {10.1007/s12170-016-0491-8},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4889124/},
  urldate = {2023-12-06},
  abstract = {Multimorbidity affects more than two thirds of older individuals and the vast majority of patients with chronic cardiovascular disease. Patients with multimorbidity have high resource utilization, poor mobility, and poor health status and are at an increased risk for death. The presence of multimorbidity imposes numerous management challenges in caring for patients with chronic cardiovascular disease. It complicates decision-making, promotes fragmented care, and imposes an immense burden on the patient and their social support system. Novel models of care, such as the cardiovascular patient-centered medical home, are needed to provide high-quality, efficient, effective care to this growing population.},
  pmcid = {PMC4889124},
  file = {C:\Users\sdp490\Zotero\storage\Z3VCFC7E\Dunlay and Chamberlain - 2016 - Multimorbidity in Older Patients with Cardiovascul.pdf}
}

@online{elfwingSigmoidWeighted2017,
  title = {Sigmoid-{{Weighted Linear Units}} for {{Neural Network Function Approximation}} in {{Reinforcement Learning}}},
  author = {Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  date = {2017-11-01},
  eprint = {1702.03118},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1702.03118},
  url = {http://arxiv.org/abs/1702.03118},
  urldate = {2023-12-27},
  abstract = {In recent years, neural networks have enjoyed a renaissance as function approximators in reinforcement learning. Two decades after Tesauro's TD-Gammon achieved near top-level human performance in backgammon, the deep reinforcement learning algorithm DQN achieved human-level performance in many Atari 2600 games. The purpose of this study is twofold. First, we propose two activation functions for neural network function approximation in reinforcement learning: the sigmoid-weighted linear unit (SiLU) and its derivative function (dSiLU). The activation of the SiLU is computed by the sigmoid function multiplied by its input. Second, we suggest that the more traditional approach of using on-policy learning with eligibility traces, instead of experience replay, and softmax action selection with simple annealing can be competitive with DQN, without the need for a separate target network. We validate our proposed approach by, first, achieving new state-of-the-art results in both stochastic SZ-Tetris and Tetris with a small 10\$\textbackslash times\$10 board, using TD(\$\textbackslash lambda\$) learning and shallow dSiLU network agents, and, then, by outperforming DQN in the Atari 2600 domain by using a deep Sarsa(\$\textbackslash lambda\$) agent with SiLU and dSiLU hidden units.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\CUZ6LM3Z\\Elfwing et al. - 2017 - Sigmoid-Weighted Linear Units for Neural Network F.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\63QRB8WW\\1702.html}
}

@article{estevaGuide2019,
  title = {A Guide to Deep Learning in Healthcare},
  author = {Esteva, Andre and Robicquet, Alexandre and Ramsundar, Bharath and Kuleshov, Volodymyr and DePristo, Mark and Chou, Katherine and Cui, Claire and Corrado, Greg and Thrun, Sebastian and Dean, Jeff},
  date = {2019-01},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {25},
  pages = {24--29},
  issn = {1546-170X},
  doi = {10.1038/s41591-018-0316-z},
  url = {https://www.nature.com/articles/s41591-018-0316-z},
  urldate = {2023-05-03},
  abstract = {Here we present deep-learning techniques for healthcare, centering our discussion on deep learning in computer vision, natural language processing, reinforcement learning, and generalized methods. We describe how these computational techniques can impact a few key areas of medicine and explore how to build end-to-end systems. Our discussion of computer vision focuses largely on medical imaging, and we describe the application of natural language processing to domains such as electronic health record data. Similarly, reinforcement learning is discussed in the context of robotic-assisted surgery, and generalized deep-learning methods for genomics are reviewed.},
  langid = {english},
  keywords = {Bioinformatics,Health care,Machine learning}
}

@article{falkPathogenesis2006,
  title = {Pathogenesis of {{Atherosclerosis}}},
  author = {Falk, Erling},
  date = {2006-04-18},
  journaltitle = {Journal of the American College of Cardiology},
  volume = {47},
  pages = {C7-C12},
  publisher = {{American College of Cardiology Foundation}},
  doi = {10.1016/j.jacc.2005.09.068},
  url = {https://www.jacc.org/doi/abs/10.1016/j.jacc.2005.09.068},
  urldate = {2023-10-05},
  file = {C:\Users\sdp490\Zotero\storage\2QAQ5599\Falk - 2006 - Pathogenesis of Atherosclerosis.pdf}
}

@article{faraggiNeural1995,
  title = {A Neural Network Model for Survival Data},
  author = {Faraggi, David and Simon, Richard},
  date = {1995},
  journaltitle = {Statistics in Medicine},
  volume = {14},
  number = {1},
  pages = {73--82},
  issn = {1097-0258},
  doi = {10.1002/sim.4780140108},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4780140108},
  urldate = {2023-10-31},
  abstract = {Neural networks have received considerable attention recently, mostly by non-statisticians. They are considered by many to be very promising tools for classification and prediction. In this paper we present an approach to modelling censored survival data using the input—output relationship associated with a simple feed-forward neural network as the basis for a non-linear proportional hazards model. This approach can be extended to other models used with censored survival data. The proportional hazards neural network parameters are estimated using the method of maximum likelihood. These maximum likelihood based models can be compared, using readily available techniques such as the likelihood ratio test and the Akaike criterion. The neural network models are illustrated using data on the survival of men with prostatic carcinoma. A method of interpreting the neural network predictions based on the factorial contrasts is presented.},
  langid = {english}
}

@article{finleyWhat2018,
  title = {What Are the Most Common Conditions in Primary Care?},
  author = {Finley, Caitlin R. and Chan, Derek S. and Garrison, Scott and Korownyk, Christina and Kolber, Michael R. and Campbell, Sandra and Eurich, Dean T. and Lindblad, Adrienne J. and Vandermeer, Ben and Allan, G. Michael},
  date = {2018-11},
  journaltitle = {Canadian Family Physician},
  shortjournal = {Can Fam Physician},
  volume = {64},
  number = {11},
  eprint = {30429181},
  eprinttype = {pmid},
  pages = {832--840},
  issn = {0008-350X},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6234945/},
  urldate = {2023-11-30},
  abstract = {Objective To identify the most commonly presenting conditions in primary care globally, and to compare common reasons for visits (RFVs) as reported by clinicians and patients, as well as among countries of different economic classifications. Data sources Twelve scientific databases were searched up to January 2016, and a dual independent review was performed to select primary care studies. Study selection Studies were included if they contained 20 000 visits or more (or equivalent volume by patient-clinician interactions) and listed 10 or more RFVs. Dual independent data extraction of study characteristics and RFV rankings was performed. Data analysis was descriptive, with pooled rankings of RFVs across studies. Synthesis Eighteen studies met inclusion criteria (median 250 000 patients or 83 161 visits). Data were from 12 countries across 5 continents. The 10 most common clinician-reported RFVs were upper respiratory tract infection, hypertension, routine health maintenance, arthritis, diabetes, depression or anxiety, pneumonia, acute otitis media, back pain, and dermatitis. The 10 most common patient-reported RFVs were symptomatic conditions including cough, back pain, abdominal symptoms, pharyngitis, dermatitis, fever, headache, leg symptoms, unspecified respiratory concerns, and fatigue. Globally, upper respiratory tract infection and hypertension were the most common clinician-reported RFVs. In developed countries the next most common RFVs were depression or anxiety and back pain, and in developing countries they were pneumonia and tuberculosis. There was a paucity of available data, particularly from developing countries. Conclusion There are differences between clinician-reported and patient-reported RFVs to primary care, as well as between developed and developing countries. The results of our review are useful for the development of primary care guidelines, the allocation of resources, and the design of training programs and curricula.},
  pmcid = {PMC6234945},
  file = {C:\Users\sdp490\Zotero\storage\RCTF8SS4\Finley et al. - 2018 - What are the most common conditions in primary car.pdf}
}

@article{formanMultimorbidity2018,
  title = {Multimorbidity in {{Older Adults With Cardiovascular Disease}}},
  author = {Forman, Daniel E. and Maurer, Mathew S. and Boyd, Cynthia and Brindis, Ralph and Salive, Marcel E. and Horne, Frances McFarland and Bell, Susan P. and Fulmer, Terry and Reuben, David B. and Zieman, Susan and Rich, Michael W.},
  date = {2018-05-15},
  journaltitle = {Journal of the American College of Cardiology},
  shortjournal = {Journal of the American College of Cardiology},
  volume = {71},
  number = {19},
  pages = {2149--2161},
  issn = {0735-1097},
  doi = {10.1016/j.jacc.2018.03.022},
  url = {https://www.sciencedirect.com/science/article/pii/S073510971833626X},
  urldate = {2023-11-30},
  abstract = {Multimorbidity occurs in adults of all ages, but the number and complexity of comorbid conditions commonly increase with advancing age such that cardiovascular disease (CVD) in older adults typically occurs in a context of multimorbidity. Current clinical practice and research mainly target single disease-specific care that does not embrace the complexities imposed by concurrent conditions. In this paper, emerging concepts regarding CVD in combination with multimorbidity are reviewed, including recommendations for incorporating multimorbidity into clinical decision making, critical knowledge gaps, and research priorities to optimize care of complex older patients.},
  keywords = {aging,frailty,multimorbidity,polypharmacy,quality of life},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\USSZTWTL\\Forman et al. - 2018 - Multimorbidity in Older Adults With Cardiovascular.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\GRJ5ISME\\S073510971833626X.html}
}

@online{fotsoDeep2018,
  title = {Deep {{Neural Networks}} for {{Survival Analysis Based}} on a {{Multi-Task Framework}}},
  author = {Fotso, Stephane},
  date = {2018-01-16},
  eprint = {1801.05512},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1801.05512},
  urldate = {2023-11-16},
  abstract = {Survival analysis/time-to-event models are extremely useful as they can help companies predict when a customer will buy a product, churn or default on a loan, and therefore help them improve their ROI. In this paper, we introduce a new method to calculate survival functions using the Multi-Task Logistic Regression (MTLR) model as its base and a deep learning architecture as its core. Based on the Concordance index (C-index) and Brier score, this method outperforms the MTLR in all the experiments disclosed in this paper as well as the Cox Proportional Hazard (CoxPH) model when nonlinear dependencies are found.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\8HSFA2QT\\Fotso - 2018 - Deep Neural Networks for Survival Analysis Based o.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\T8RWJ7A8\\1801.html}
}

@article{foxMyth2020,
  title = {The Myth of ‘Stable’ Coronary Artery Disease},
  author = {Fox, Keith A. A. and Metra, Marco and Morais, João and Atar, Dan},
  date = {2020-01},
  journaltitle = {Nature Reviews Cardiology},
  shortjournal = {Nat Rev Cardiol},
  volume = {17},
  number = {1},
  pages = {9--21},
  publisher = {{Nature Publishing Group}},
  issn = {1759-5010},
  doi = {10.1038/s41569-019-0233-y},
  url = {https://www.nature.com/articles/s41569-019-0233-y},
  urldate = {2023-10-09},
  abstract = {Patients with known cardiovascular disease who have not had a recent acute event are often referred to as having stable coronary artery disease (CAD). The concept of ‘stable’ CAD is misleading for two important reasons: the continuing risks of cardiovascular events over the longer term and the diverse spectrum of powerful risk characteristics. The risks of cardiovascular events are frequently underestimated and continue to exist, despite current standards of care for secondary prevention, including lifestyle changes, optimal medical therapy, myocardial revascularization and the use of antiplatelet agents to limit thrombosis. In dispelling the myth of ‘stable’ CAD, we explore the pathophysiology of the disease and the relative contribution of plaque and systemic factors to cardiovascular events. A broader concept of the vulnerable patient, not just the vulnerable plaque, takes into account the diversity and future risks of atherothrombotic events. We also evaluate new and ongoing research into medical therapies aimed at further reducing the risks of cardiovascular events in patients with chronic — but not stable — atherothrombotic disease.},
  issue = {1},
  langid = {english},
  keywords = {Coronary artery disease and stable angina,Drug therapy,Preventive medicine,Risk factors},
  file = {C:\Users\sdp490\Zotero\storage\XWECRE2J\Fox et al. - 2020 - The myth of ‘stable’ coronary artery disease.pdf}
}

@article{foxShould2014,
  title = {Should Patients with Acute Coronary Disease Be Stratified for Management According to Their Risk? {{Derivation}}, External Validation and Outcomes Using the Updated {{GRACE}} Risk Score},
  shorttitle = {Should Patients with Acute Coronary Disease Be Stratified for Management According to Their Risk?},
  author = {Fox, Keith A. A. and FitzGerald, Gordon and Puymirat, Etienne and Huang, Wei and Carruthers, Kathryn and Simon, Tabassome and Coste, Pierre and Monsegu, Jacques and Steg, Philippe Gabriel and Danchin, Nicolas and Anderson, Fred},
  date = {2014-02-01},
  journaltitle = {BMJ Open},
  volume = {4},
  number = {2},
  eprint = {24561498},
  eprinttype = {pmid},
  pages = {e004425},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {2044-6055, 2044-6055},
  doi = {10.1136/bmjopen-2013-004425},
  url = {http://bmjopen.bmj.com/content/4/2/e004425},
  urldate = {2022-02-16},
  abstract = {Objectives Risk scores are recommended in guidelines to facilitate the management of patients who present with acute coronary syndromes (ACS). Internationally, such scores are not systematically used because they are not easy to apply and some risk indicators are not available at first presentation. We aimed to derive and externally validate a more accurate version of the Global Registry of Acute Coronary Events (GRACE) risk score for predicting the risk of death or death/myocardial infarction (MI) both acutely and over the longer term. The risk score was designed to be suitable for acute and emergency clinical settings and usable in electronic devices. Design and setting The GRACE risk score (2.0) was derived in 32 037 patients from the GRACE registry (14 countries, 94 hospitals) and validated externally in the French registry of Acute ST-elevation and non-ST-elevation MI (FAST-MI) 2005. Participants Patients presenting with ST-elevation and non-ST elevation ACS and with long-term outcomes. Outcome measures The GRACE Score (2.0) predicts the risk of short-term and long-term mortality, and death/MI, overall and in hospital survivors. Results For key independent risk predictors of death (1 year), non-linear associations (vs linear) were found for age (p{$<$}0.0005), systolic blood pressure (p{$<$}0.0001), pulse (p{$<$}0.0001) and creatinine (p{$<$}0.0001). By employing non-linear algorithms, there was improved model discrimination, validated externally. Using the FAST-MI 2005 cohort, the c indices for death exceeded 0.82 for the overall population at 1 year and also at 3 years. Discrimination for death or MI was slightly lower than for death alone (c=0.78). Similar results were obtained for hospital survivors, and with substitutions for creatinine and Killip class, the model performed nearly as well. Conclusions The updated GRACE risk score has better discrimination and is easier to use than the previous score based on linear associations. GRACE Risk (2.0) performed equally well acutely and over the longer term and can be used in a variety of clinical settings to aid management decisions.},
  langid = {english},
  keywords = {ACCIDENT \& EMERGENCY MEDICINE},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\8WMPX5RM\\Fox et al. - 2014 - Should patients with acute coronary disease be str.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\BHAKPG8Q\\e004425.html}
}

@article{frankEpidemiology2000,
  title = {Epidemiology. {{When}} an Entire Country Is a Cohort},
  author = {Frank, Lone},
  date = {2000-03-31},
  journaltitle = {Science (New York, N.Y.)},
  shortjournal = {Science},
  volume = {287},
  number = {5462},
  eprint = {10766613},
  eprinttype = {pmid},
  pages = {2398--2399},
  issn = {0036-8075},
  doi = {10.1126/science.287.5462.2398},
  langid = {english},
  keywords = {Biomedical and Behavioral Research,Cohort Studies,Confidentiality,{Databases, Factual},Denmark,Genetic Research,Humans,{Medical Records Systems, Computerized},Registries,Twin Studies as Topic}
}

@article{fusterPathogenesis1992,
  title = {The {{Pathogenesis}} of {{Coronary Artery Disease}} and the {{Acute Coronary Syndromes}}},
  author = {Fuster, Valentin and Badimon, Lina and Badimon, Juan J. and Chesebro, James H.},
  date = {1992-01-23},
  journaltitle = {New England Journal of Medicine},
  volume = {326},
  number = {4},
  eprint = {1727977},
  eprinttype = {pmid},
  pages = {242--250},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJM199201233260406},
  url = {https://doi.org/10.1056/NEJM199201233260406},
  urldate = {2023-10-05},
  abstract = {IN the 19th century there were two major hypotheses to explain the pathogenesis of atherosclerosis: the "incrustation" hypothesis and the "lipid" hypothesis. The incrustation hypothesis of von Rokitansky,1 proposed in 1852 and modified by Duguid,2 suggested that intimal thickening resulted from fibrin deposition, with subsequent organization by fibroblasts and secondary lipid accumulation. The lipid hypothesis, proposed by Virchow3 in 1856, suggested that lipid in the arterial wall represented a transduction of blood lipid, which subsequently formed complexes with acid mucopolysaccharides; lipid accumulated in arterial walls because mechanisms of lipid deposition predominated over those of removal. The two hypotheses are now . . .}
}

@article{gensheimerScalable2019,
  title = {A Scalable Discrete-Time Survival Model for Neural Networks},
  author = {Gensheimer, Michael F. and Narasimhan, Balasubramanian},
  date = {2019-01-25},
  journaltitle = {PeerJ},
  volume = {7},
  pages = {e6257},
  doi = {10.7717/peerj.6257},
  url = {https://doi.org/gktmcp},
  abstract = {{$<$}jats:p{$>$}There is currently great interest in applying neural networks to prediction tasks in medicine. It is important for predictive models to be able to use survival data, where each patient has a known follow-up time and event/censoring indicator. This avoids information loss when training the model and enables generation of predicted survival curves. In this paper, we describe a discrete-time survival model that is designed to be used with neural networks, which we refer to as Nnet-survival. The model is trained with the maximum likelihood method using mini-batch stochastic gradient descent (SGD). The use of SGD enables rapid convergence and application to large datasets that do not fit in memory. The model is flexible, so that the baseline hazard rate and the effect of the input data on hazard probability can vary with follow-up time. It has been implemented in the Keras deep learning framework, and source code for the model and several examples is available online. We demonstrate the performance of the model on both simulated and real data and compare it to existing models Cox-nnet and Deepsurv.{$<$}/jats:p{$>$}},
  langid = {english},
  annotation = {This CSL Item was generated by Manubot v0.5.3 from its persistent identifier (standard\_id). standard\_id: doi:10.7717/peerj.6257 Loaded from an external bibliography file by Manubot. source\_bibliography: bibliography.csl.json original\_id: yunjBlQR}
}

@book{gerdsMedical2021,
  title = {Medical {{Risk Prediction Models}}: {{With Ties}} to {{Machine Learning}}},
  shorttitle = {Medical {{Risk Prediction Models}}},
  author = {Gerds, Thomas A. and Kattan, Michael W.},
  date = {2021-02-01},
  publisher = {{Chapman and Hall/CRC}},
  location = {{New York}},
  doi = {10.1201/9781138384484},
  abstract = {Medical Risk Prediction Models: With Ties to Machine Learning is a hands-on book for clinicians, epidemiologists, and professional statisticians who need to make or evaluate a statistical prediction model based on data. The subject of the book is the patient’s individualized probability of a medical event within a given time horizon. Gerds and Kattan describe the mathematical details of making and evaluating a statistical prediction model in a highly pedagogical manner while avoiding mathematical notation. Read this book when you are in doubt about whether a Cox regression model predicts better than a random survival forest. Features: All you need to know to correctly make an online risk calculator from scratch Discrimination, calibration, and predictive performance with censored data and competing risks R-code and illustrative examples Interpretation of prediction performance via benchmarks Comparison and combination of rival modeling strategies via cross-validation Thomas A. Gerds is a professor at the Biostatistics Unit at the University of Copenhagen and is affiliated with the Danish Heart Foundation. He is the author of several R-packages on CRAN and has taught statistics courses to non-statisticians for many years. Michael W. Kattan is a highly cited author and Chair of the Department of Quantitative Health Sciences at Cleveland Clinic. He is a Fellow of the American Statistical Association and has received two awards from the Society for Medical Decision Making: the Eugene L. Saenger Award for Distinguished Service, and the John M. Eisenberg Award for Practical Application of Medical Decision-Making Research.},
  isbn = {978-1-138-38448-4},
  pagetotal = {312}
}

@software{gerdsRiskRegression2023,
  title = {{{riskRegression}}: {{Risk Regression Models}} and {{Prediction Scores}} for {{Survival Analysis}} with {{Competing Risks}}},
  shorttitle = {{{riskRegression}}},
  author = {Gerds, Thomas Alexander and Ohlendorff, Johan Sebastian and Blanche, Paul and Mortensen, Rikke and Wright, Marvin and Tollenaar, Nikolaj and Muschelli, John and Mogensen, Ulla Brasch and Ozenne, Brice},
  date = {2023-12-19},
  url = {https://cran.r-project.org/web/packages/riskRegression/index.html},
  urldate = {2023-12-29},
  abstract = {Implementation of the following methods for event history analysis. Risk regression models for survival endpoints also in the presence of competing risks are fitted using binomial regression based on a time sequence of binary event status variables. A formula interface for the Fine-Gray regression model and an interface for the combination of cause-specific Cox regression models. A toolbox for assessing and comparing performance of risk predictions (risk markers and risk prediction models). Prediction performance is measured by the Brier score and the area under the ROC curve for binary possibly time-dependent outcome. Inverse probability of censoring weighting and pseudo values are used to deal with right censored data. Lists of risk markers and lists of risk models are assessed simultaneously. Cross-validation repeatedly splits the data, trains the risk prediction models on one part of each split and then summarizes and compares the performance across splits.},
  version = {2023.12.21},
  keywords = {CausalInference,Survival}
}

@incollection{golubSingular1971,
  title = {Singular {{Value Decomposition}} and {{Least Squares Solutions}}},
  booktitle = {Handbook for {{Automatic Computation}}: {{Volume II}}: {{Linear Algebra}}},
  author = {Golub, G. H. and Reinsch, C.},
  editor = {Wilkinson, J. H. and Reinsch, C. and Bauer, F. L. and Householder, A. S. and Olver, F. W. J. and Rutishauser, H. and Samelson, K. and Stiefel, E.},
  date = {1971},
  series = {Die {{Grundlehren}} Der Mathematischen {{Wissenschaften}}},
  pages = {134--151},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-86940-2_10},
  url = {https://doi.org/10.1007/978-3-642-86940-2_10},
  urldate = {2023-12-03},
  abstract = {Let A be a real m×n matrix with m≧n. It is well known (cf. [4]) that(1)\$\$A = U\textbackslash sum \{V\^T\}\$\$where\$\$\{U\^T\}U = \{V\^T\}V = V\{V\^T\} = \{I\_n\}\{\textbackslash text\{ and \}\}\textbackslash sum \{\textbackslash text\{ = diag(\}\}\{\textbackslash sigma \_\{\textbackslash text\{1\}\}\}\{\textbackslash text\{,\}\} \textbackslash ldots \{\textbackslash text\{,\}\}\{\textbackslash sigma \_n\}\{\textbackslash text\{)\}\}\{\textbackslash text\{.\}\}\$\$The matrix U consists of n orthonormalized eigenvectors associated with the n largest eigenvalues of AAT, and the matrix V consists of the orthonormalized eigenvectors of ATA. The diagonal elements of ∑ are the non-negative square roots of the eigenvalues of ATA; they are called singular values. We shall assume that\$\$\{\textbackslash sigma \_1\} \textbackslash geqq \{\textbackslash sigma \_2\} \textbackslash geqq \textbackslash cdots \textbackslash geqq \{\textbackslash sigma \_n\} \textbackslash geqq 0.\$\$Thus if rank(A)=r, σr+1 = σr+2=⋯=σn= 0. The decomposition (1) is called the singular value decomposition (SVD).},
  isbn = {978-3-642-86940-2},
  langid = {english},
  keywords = {Bell Telephone Laboratory,Householder Transformation,Linear Algebra,Machine Precision,Matrix Versus}
}

@book{goodfellow2016deep,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016},
  publisher = {{MIT press}}
}

@online{gorishniyRevisiting2023,
  title = {Revisiting {{Deep Learning Models}} for {{Tabular Data}}},
  author = {Gorishniy, Yury and Rubachev, Ivan and Khrulkov, Valentin and Babenko, Artem},
  date = {2023-07-26},
  eprint = {2106.11959},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2106.11959},
  urldate = {2023-09-14},
  abstract = {The existing literature on deep learning for tabular data proposes a wide range of novel architectures and reports competitive results on various datasets. However, the proposed models are usually not properly compared to each other and existing works often use different benchmarks and experiment protocols. As a result, it is unclear for both researchers and practitioners what models perform best. Additionally, the field still lacks effective baselines, that is, the easy-to-use models that provide competitive performance across different problems. In this work, we perform an overview of the main families of DL architectures for tabular data and raise the bar of baselines in tabular DL by identifying two simple and powerful deep architectures. The first one is a ResNet-like architecture which turns out to be a strong baseline that is often missing in prior works. The second model is our simple adaptation of the Transformer architecture for tabular data, which outperforms other solutions on most tasks. Both models are compared to many existing architectures on a diverse set of tasks under the same training and tuning protocols. We also compare the best DL models with Gradient Boosted Decision Trees and conclude that there is still no universally superior solution.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\4J8B55NU\\Gorishniy et al. - 2023 - Revisiting Deep Learning Models for Tabular Data.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\NP2BMUDR\\2106.html}
}

@online{GRACE,
  title = {{{GRACE Risk Score}} 2.0},
  url = {https://www.outcomes-umassmed.org/grace/acs_risk2/index.html},
  urldate = {2023-12-12},
  file = {C:\Users\sdp490\Zotero\storage\MQWNR7JJ\index.html}
}

@article{grafAssessment1999,
  title = {Assessment and Comparison of Prognostic Classification Schemes for Survival Data},
  author = {Graf, Erika and Schmoor, Claudia and Sauerbrei, Willi and Schumacher, Martin},
  date = {1999},
  journaltitle = {Statistics in Medicine},
  volume = {18},
  number = {17-18},
  pages = {2529--2545},
  issn = {1097-0258},
  doi = {10.1002/(SICI)1097-0258(19990915/30)18:17/18<2529::AID-SIM274>3.0.CO;2-5},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0258%2819990915/30%2918%3A17/18%3C2529%3A%3AAID-SIM274%3E3.0.CO%3B2-5},
  urldate = {2023-11-30},
  abstract = {Prognostic classification schemes have often been used in medical applications, but rarely subjected to a rigorous examination of their adequacy. For survival data, the statistical methodology to assess such schemes consists mainly of a range of ad hoc approaches, and there is an alarming lack of commonly accepted standards in this field. We review these methods and develop measures of inaccuracy which may be calculated in a validation study in order to assess the usefulness of estimated patient-specific survival probabilities associated with a prognostic classification scheme. These measures are meaningful even when the estimated probabilities are misspecified, and asymptotically they are not affected by random censorship. In addition, they can be used to derive R2-type measures of explained residual variation. A breast cancer study will serve for illustration throughout the paper. Copyright © 1999 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\HXBLLWET\\Graf et al. - 1999 - Assessment and comparison of prognostic classifica.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\3IJ6NMA4\\182529AID-SIM2743.0.html}
}

@article{grannExisting2011,
  title = {Existing Data Sources for Clinical Epidemiology: {{The}} Clinical Laboratory Information System ({{LABKA}}) Research Database at {{Aarhus University}}, {{Denmark}}},
  shorttitle = {Existing Data Sources for Clinical Epidemiology},
  author = {Grann, Anne Fia and Erichsen, Rune and Nielsen, Anders Gunnar and Frøslev, Trine and Thomsen, Reimar W.},
  date = {2011-04-01},
  journaltitle = {Clinical Epidemiology},
  shortjournal = {Clin Epidemiol},
  volume = {3},
  eprint = {21487452},
  eprinttype = {pmid},
  pages = {133--138},
  issn = {1179-1349},
  doi = {10.2147/CLEP.S17901},
  abstract = {This paper provides an introduction to the clinical laboratory information system (LABKA) research database in Northern and Central Denmark. The database contains millions of stored laboratory test results for patients living in the two Danish regions, encompassing 1.8 million residents, or one-third of the country's population. More than 1700 different types of blood test analyses are available. Therefore, the LABKA research database represents an incredible source for studies involving blood test analyses. By record linkage of different Danish registries with the LABKA research database, it is possible to examine a large number of biomarkers as predictors of disease risk and prognosis and as markers of disease severity, and to evaluate medical treatments regarding effectiveness and possible side effects. Large epidemiological studies using routinely stored blood test results for individual patients can be performed because it is possible to link the laboratory data to high-quality individual clinical patient data in Denmark.},
  langid = {english},
  pmcid = {PMC3072155},
  keywords = {biochemistry,diagnosis,epidemiological methods,laboratory procedures,registries,therapeutic drug monitoring},
  file = {C:\Users\sdp490\Zotero\storage\6BHTAVUD\Grann et al. - 2011 - Existing data sources for clinical epidemiology T.pdf}
}

@article{gunningXAI2019,
  title = {{{XAI}}—{{Explainable}} Artificial Intelligence},
  author = {Gunning, David and Stefik, Mark and Choi, Jaesik and Miller, Timothy and Stumpf, Simone and Yang, Guang-Zhong},
  date = {2019-12-18},
  journaltitle = {Science Robotics},
  volume = {4},
  number = {37},
  pages = {eaay7120},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/scirobotics.aay7120},
  url = {https://www.science.org/doi/abs/10.1126/scirobotics.aay7120},
  urldate = {2023-04-11},
  abstract = {Explainability is essential for users to effectively understand, trust, and manage powerful artificial intelligence applications.},
  file = {C:\Users\sdp490\Zotero\storage\Z2Q7A6C2\Gunning et al. - 2019 - XAI—Explainable artificial intelligence.pdf}
}

@article{hallMultimorbidity2018,
  title = {Multimorbidity and Survival for Patients with Acute Myocardial Infarction in {{England}} and {{Wales}}: {{Latent}} Class Analysis of a Nationwide Population-Based Cohort},
  shorttitle = {Multimorbidity and Survival for Patients with Acute Myocardial Infarction in {{England}} and {{Wales}}},
  author = {Hall, Marlous and Dondo, Tatendashe B. and Yan, Andrew T. and Mamas, Mamas A. and Timmis, Adam D. and Deanfield, John E. and Jernberg, Tomas and Hemingway, Harry and Fox, Keith A. A. and Gale, Chris P.},
  date = {2018-03-06},
  journaltitle = {PLOS Medicine},
  shortjournal = {PLOS Medicine},
  volume = {15},
  number = {3},
  pages = {e1002501},
  publisher = {{Public Library of Science}},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.1002501},
  url = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002501},
  urldate = {2023-12-18},
  abstract = {Background There is limited knowledge of the scale and impact of multimorbidity for patients who have had an acute myocardial infarction (AMI). Therefore, this study aimed to determine the extent to which multimorbidity is associated with long-term survival following AMI. Methods and findings This national observational study included 693,388 patients (median age 70.7 years, 452,896 [65.5\%] male) from the Myocardial Ischaemia National Audit Project (England and Wales) who were admitted with AMI between 1 January 2003 and 30 June 2013. There were 412,809 (59.5\%) patients with multimorbidity at the time of admission with AMI, i.e., having at least 1 of the following long-term health conditions: diabetes, chronic obstructive pulmonary disease or asthma, heart failure, renal failure, cerebrovascular disease, peripheral vascular disease, or hypertension. Those with heart failure, renal failure, or cerebrovascular disease had the worst outcomes (39.5 [95\% CI 39.0–40.0], 38.2 [27.7–26.8], and 26.6 [25.2–26.4] deaths per 100 person-years, respectively). Latent class analysis revealed 3 multimorbidity phenotype clusters: (1) a high multimorbidity class, with concomitant heart failure, peripheral vascular disease, and hypertension, (2) a medium multimorbidity class, with peripheral vascular disease and hypertension, and (3) a low multimorbidity class. Patients in class 1 were less likely to receive pharmacological therapies compared with class 2 and 3 patients (including aspirin, 83.8\% versus 87.3\% and 87.2\%, respectively; β-blockers, 74.0\% versus 80.9\% and 81.4\%; and statins, 80.6\% versus 85.9\% and 85.2\%). Flexible parametric survival modelling indicated that patients in class 1 and class 2 had a 2.4-fold (95\% CI 2.3–2.5) and 1.5-fold (95\% CI 1.4–1.5) increased risk of death and a loss in life expectancy of 2.89 and 1.52 years, respectively, compared with those in class 3 over the 8.4-year follow-up period. The study was limited to all-cause mortality due to the lack of available cause-specific mortality data. However, we isolated the disease-specific association with mortality by providing the loss in life expectancy following AMI according to multimorbidity phenotype cluster compared with the general age-, sex-, and year-matched population. Conclusions Multimorbidity among patients with AMI was common, and conferred an accumulative increased risk of death. Three multimorbidity phenotype clusters that were significantly associated with loss in life expectancy were identified and should be a concomitant treatment target to improve cardiovascular outcomes. Trial registration ClinicalTrials.gov NCT03037255.},
  langid = {english},
  keywords = {Chronic obstructive pulmonary disease,Coronary artery bypass grafting,Coronary heart disease,Heart failure,Hypertension,Life expectancy,Myocardial infarction,Peripheral vascular disease},
  file = {C:\Users\sdp490\Zotero\storage\UE79H4JD\Hall et al. - 2018 - Multimorbidity and survival for patients with acut.pdf}
}

@article{handelmanEDoctor2018,
  title = {{{eDoctor}}: Machine Learning and the Future of Medicine},
  shorttitle = {{{eDoctor}}},
  author = {Handelman, G. S. and Kok, H. K. and Chandra, R. V. and Razavi, A. H. and Lee, M. J. and Asadi, H.},
  date = {2018-12},
  journaltitle = {Journal of Internal Medicine},
  shortjournal = {J Intern Med},
  volume = {284},
  number = {6},
  eprint = {30102808},
  eprinttype = {pmid},
  pages = {603--619},
  issn = {1365-2796},
  doi = {10.1111/joim.12822},
  abstract = {Machine learning (ML) is a burgeoning field of medicine with huge resources being applied to fuse computer science and statistics to medical problems. Proponents of ML extol its ability to deal with large, complex and disparate data, often found within medicine and feel that ML is the future for biomedical research, personalized medicine, computer-aided diagnosis to significantly advance global health care. However, the concepts of ML are unfamiliar to many medical professionals and there is untapped potential in the use of ML as a research tool. In this article, we provide an overview of the theory behind ML, explore the common ML algorithms used in medicine including their pitfalls and discuss the potential future of ML in medicine.},
  langid = {english},
  keywords = {Algorithms,artificial intelligence,{Decision Support Systems, Clinical},Forecasting,Humans,machine learning,Machine Learning,medicine,Medicine,Precision Medicine,supervised machine learning,Supervised Machine Learning,unsupervised machine learning,Unsupervised Machine Learning},
  file = {C:\Users\sdp490\Zotero\storage\Z3ZHSRG3\Handelman et al. - 2018 - eDoctor machine learning and the future of medici.pdf}
}

@article{hannunCardiologistlevel2019,
  title = {Cardiologist-Level Arrhythmia Detection and Classification in Ambulatory Electrocardiograms Using a Deep Neural Network},
  author = {Hannun, Awni Y. and Rajpurkar, Pranav and Haghpanahi, Masoumeh and Tison, Geoffrey H. and Bourn, Codie and Turakhia, Mintu P. and Ng, Andrew Y.},
  date = {2019-01},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {25},
  number = {1},
  pages = {65--69},
  publisher = {{Nature Publishing Group}},
  issn = {1546-170X},
  doi = {10.1038/s41591-018-0268-3},
  url = {https://www.nature.com/articles/s41591-018-0268-3},
  urldate = {2023-05-08},
  abstract = {Computerized electrocardiogram (ECG) interpretation plays a critical role in the clinical ECG workflow1. Widely available digital ECG data and the algorithmic paradigm of deep learning2 present an opportunity to substantially improve the accuracy and scalability of automated ECG analysis. However, a comprehensive evaluation of an end-to-end deep learning approach for ECG analysis across a wide variety of diagnostic classes has not been previously reported. Here, we develop a deep neural network (DNN) to classify 12 rhythm classes using 91,232 single-lead ECGs from 53,549 patients who used a single-lead ambulatory ECG monitoring device. When validated against an independent test dataset annotated by a consensus committee of board-certified practicing cardiologists, the DNN achieved an average area under the receiver operating characteristic curve (ROC) of 0.97. The average F1 score, which is the harmonic mean of the positive predictive value and sensitivity, for the DNN (0.837) exceeded that of average cardiologists (0.780). With specificity fixed at the average specificity achieved by cardiologists, the sensitivity of the DNN exceeded the average cardiologist sensitivity for all rhythm classes. These findings demonstrate that an end-to-end deep learning approach can classify a broad range of distinct arrhythmias from single-lead ECGs with high diagnostic performance similar to that of cardiologists. If confirmed in clinical settings, this approach could reduce the rate of misdiagnosed computerized ECG interpretations and improve the efficiency of expert human ECG interpretation by accurately triaging or prioritizing the most urgent conditions.},
  issue = {1},
  langid = {english},
  keywords = {Arrhythmias,Machine learning},
  file = {C:\Users\sdp490\Zotero\storage\9HYKAINU\Hannun et al. - 2019 - Cardiologist-level arrhythmia detection and classi.pdf}
}

@online{haueSubgrouping2023,
  title = {Subgrouping Multimorbid Patients with Ischemic Heart Disease by Means of Unsupervised Clustering: {{A}} Cohort Study of 72,249 Patients Defined Comprehensively by Diagnoses Prior to Presentation},
  shorttitle = {Subgrouping Multimorbid Patients with Ischemic Heart Disease by Means of Unsupervised Clustering},
  author = {Haue, Amalie D. and Holm, Peter C. and Banasik, Karina and Lundgaard, Agnete T. and Muse, Victorine P. and Röder, Timo and Westergaard, David and Chmura, Piotr J. and Christensen, Alex H. and Weeke, Peter E. and Sørensen, Erik and Pedersen, Ole B. V. and Ostrowski, Sisse R. and Iversen, Kasper K. and Køber, Lars V. and Ullum, Henrik and Bundgaard, Henning and Brunak, Søren},
  date = {2023-04-11},
  eprinttype = {medRxiv},
  pages = {2023.03.31.23288006},
  doi = {10.1101/2023.03.31.23288006},
  url = {https://www.medrxiv.org/content/10.1101/2023.03.31.23288006v2},
  urldate = {2023-10-03},
  abstract = {Background There are no methods for classifying patients with ischemic heart disease (IHD) based on the entire spectrum of pre-existing diseases. Such methods might be clinically useful due to the marked differences in presentation and course of disease. Methods A population-based cohort study from a Danish secondary care setting of patients with IHD (2004-2016) and subjected to a coronary angiography (CAG) or coronary computed tomography angiography (CCTA). Data sources were The Danish National Patient Registry, in-hospital laboratory data, and genetic data from Copenhagen Hospital Biobank. Comorbidities included diagnoses assigned prior to presentation of IHD. Patients were clustered by means of the Markov Clustering Algorithm using the entire spectrum of registered multimorbidity. The two prespecified outcomes were: New ischemic events (including death from IHD causes) and death from non-IHD causes. Patients were followed from date of CAG/CCTA until one of the two outcomes occurred or end of follow-up, whichever came first. Biological and clinical appropriateness of clusters was assessed by comparing risks (estimated from Cox proportional hazard models) in clusters and by phenotypic and genetic enrichment analyses, respectively. Findings In a cohort of 72,249 patients with IHD (mean age 63.9 years, 63.1\% males), 31 distinct clusters (C1-31, 67,136 patients) were identified. Comparing each cluster to the 30 others, seven clusters (9,590 patients) had statistically significantly higher or lower risk of new ischemic events (five and two clusters, respectively). 18 clusters (35,982 patients) had a higher or lower risk of death from non-IHD causes (12 and six clusters, respectively). All clusters at increased risk of new ischemic events, associated with risk of death from non-IHD causes as well. Cardiovascular or inflammatory diseases were commonly enriched in clusters (13), and distributions for 24 laboratory test results differed significantly across clusters. Clusters enriched for cerebrovascular diseases were generally not at increased risk of the two outcomes. Polygenic risk scores were increased in a total of 15 clusters (48.4\%). Conclusions Clustering of patients with IHD based on pre-existing comorbidities identified subgroups of patients with significantly different clinical outcomes and presented a tool to rank pre-existing comorbidities based on their association with clinical outcomes. This novel method may support better classification of patients and thereby differentiation of treatment intensity depending on expected outcomes in subgroups.},
  langid = {english},
  pubstate = {preprint},
  file = {C:\Users\sdp490\Zotero\storage\MF36DE7K\Haue et al. - 2023 - Subgrouping multimorbid patients with ischemic hea.pdf}
}

@article{hawkinsProblem2004,
  title = {The {{Problem}} of {{Overfitting}}},
  author = {Hawkins, Douglas M.},
  date = {2004-01-01},
  journaltitle = {Journal of Chemical Information and Computer Sciences},
  shortjournal = {J. Chem. Inf. Comput. Sci.},
  volume = {44},
  number = {1},
  pages = {1--12},
  publisher = {{American Chemical Society}},
  issn = {0095-2338},
  doi = {10.1021/ci0342472},
  url = {https://doi.org/10.1021/ci0342472},
  urldate = {2023-10-26}
}

@online{heDeep2015,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2015-12-10},
  eprint = {1512.03385},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1512.03385},
  url = {http://arxiv.org/abs/1512.03385},
  urldate = {2023-11-01},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\NT8DMYI5\\He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\UJK7VFXY\\1512.html}
}

@article{helweg-larsenDanish2011,
  title = {The {{Danish Register}} of {{Causes}} of {{Death}}},
  author = {Helweg-Larsen, Karin},
  date = {2011-07},
  journaltitle = {Scandinavian Journal of Public Health},
  shortjournal = {Scand J Public Health},
  volume = {39},
  eprint = {21775346},
  eprinttype = {pmid},
  pages = {26--29},
  issn = {1651-1905},
  doi = {10.1177/1403494811399958},
  abstract = {INTRODUCTION: Cause-specific mortality statistics is a valuable source for the identification of risk factors for poor public health. CONTENT: Since 1875, the National Board of Health has maintained the register covering all deaths among citizens dying in Denmark, and since 1970 has computerised individual records. VALIDITY AND COVERAGE: Classification of cause(s) of deaths is done in accordance to WHO's rules, since 1994 by ICD-10 codes. A change in coding practices and a low autopsy rate might influence the continuity and validity in cause-specific mortality. CONCLUSION: The longstanding national registration of causes of death is essential for much research. The quality of the register on causes of death relies mainly upon the correctness of the physicians' notification and the coding in the National Board of Health.},
  issue = {7 Suppl},
  langid = {english},
  keywords = {Cause of Death,Clinical Coding,Death Certificates,Denmark,Humans,Registries,World Health Organization}
}

@article{hjaltelinPancreatic2023,
  title = {Pancreatic Cancer Symptom Trajectories from {{Danish}} Registry Data and Free Text in Electronic Health Records},
  author = {Hjaltelin, Jessica Xin and Novitski, Sif Ingibergsdóttir and Jørgensen, Isabella Friis and Siggaard, Troels and Vulpius, Siri Amalie and Westergaard, David and Johansen, Julia Sidenius and Chen, Inna M and Juhl Jensen, Lars and Brunak, Søren},
  editor = {Schlecht, Nicolas and Franco, Eduardo L},
  date = {2023-11-21},
  journaltitle = {eLife},
  volume = {12},
  pages = {e84919},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.84919},
  url = {https://doi.org/10.7554/eLife.84919},
  urldate = {2023-11-28},
  abstract = {Pancreatic cancer is one of the deadliest cancer types with poor treatment options. Better detection of early symptoms and relevant disease correlations could improve pancreatic cancer prognosis. In this retrospective study, we used symptom and disease codes (ICD-10) from the Danish National Patient Registry (NPR) encompassing 6.9 million patients from 1994 to 2018,, of whom 23,592 were diagnosed with pancreatic cancer. The Danish cancer registry included 18,523 of these patients. To complement and compare the registry diagnosis codes with deeper clinical data, we used a text mining approach to extract symptoms from free text clinical notes in electronic health records (3078 pancreatic cancer patients and 30,780 controls). We used both data sources to generate and compare symptom disease trajectories to uncover temporal patterns of symptoms prior to pancreatic cancer diagnosis for the same patients. We show that the text mining of the clinical notes was able to complement the registry-based symptoms by capturing more symptoms prior to pancreatic cancer diagnosis. For example, ‘Blood pressure reading without diagnosis’, ‘Abnormalities of heartbeat’, and ‘Intestinal obstruction’ were not found for the registry-based analysis. Chaining symptoms together in trajectories identified two groups of patients with lower median survival ({$<$}90 days) following the trajectories ‘Cough→Jaundice→Intestinal obstruction’ and ‘Pain→Jaundice→Abnormal results of function studies’. These results provide a comprehensive comparison of the two types of pancreatic cancer symptom trajectories, which in combination can leverage the full potential of the health data and ultimately provide a fuller picture for detection of early risk factors for pancreatic cancer.},
  keywords = {disease progression,longitudinal analysis,pancreas cancer,patient stratification,symptomology}
}

@article{hochreiterLong1997,
  title = {Long {{Short-Term Memory}}},
  author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  date = {1997-11},
  journaltitle = {Neural Computation},
  volume = {9},
  number = {8},
  pages = {1735--1780},
  issn = {0899-7667},
  doi = {10.1162/neco.1997.9.8.1735},
  url = {https://ieeexplore.ieee.org/abstract/document/6795963},
  urldate = {2023-11-01},
  abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
  eventtitle = {Neural {{Computation}}},
  file = {C:\Users\sdp490\Zotero\storage\HUCY8JJK\6795963.html}
}

@article{hochreiterLong1997a,
  title = {Long {{Short-Term Memory}}},
  author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  date = {1997-11},
  journaltitle = {Neural Computation},
  volume = {9},
  number = {8},
  pages = {1735--1780},
  issn = {0899-7667},
  doi = {10.1162/neco.1997.9.8.1735},
  url = {https://ieeexplore.ieee.org/abstract/document/6795963},
  urldate = {2023-12-22},
  abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
  eventtitle = {Neural {{Computation}}},
  file = {C:\Users\sdp490\Zotero\storage\3ZUBFNDI\6795963.html}
}

@article{hokkenPrecision2020,
  title = {Precision {{Medicine}} in {{Interventional Cardiology}}},
  author = {Hokken, Thijmen W and Ribeiro, Joana M and De Jaegere, Peter P and Van Mieghem, Nicolas M},
  date = {2020-04-23},
  journaltitle = {Interventional Cardiology Review},
  shortjournal = {Interv Cardiol},
  volume = {15},
  eprint = {32382319},
  eprinttype = {pmid},
  pages = {e03},
  issn = {1756-1477},
  doi = {10.15420/icr.2019.23},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7203877/},
  urldate = {2023-10-12},
  abstract = {Precision medicine has recently become widely advocated. It revolves around the individual patient, taking into account genetic, biomarker, phenotypic or psychosocial characteristics and uses biological, mechanical and/or personal variables to optimise individual therapy. In silico testing, such as the Virtual Physiological Human project, is being promoted to predict risk and to test treatments and medical devices. It combines artificial intelligence and computational modelling to select the best therapeutic option for the individual patient.},
  pmcid = {PMC7203877},
  file = {C:\Users\sdp490\Zotero\storage\U3ZUWRVD\Hokken et al. - 2020 - Precision Medicine in Interventional Cardiology.pdf}
}

@online{holmDevelopment2023,
  title = {Development and Validation of a Neural Network-Based Survival Model for Mortality in Ischemic Heart Disease},
  author = {Holm, Peter C. and Haue, Amalie D. and Westergaard, David and Röder, Timo and Banasik, Karina and Tragante, Vinicius and Christensen, Alex H. and Thomas, Laurent and Nøst, Therese H. and Skogholt, Anne-Heidi and Iversen, Kasper K. and Pedersen, Frants and Høfsten, Dan E. and Pedersen, Ole B. and Ostrowski, Sisse Rye and Ullum, Henrik and Svendsen, Mette N. and Gjødsbøl, Iben M. and Gudnason, Thorarinn and Guðbjartsson, Daníel F. and Helgadottir, Anna and Hveem, Kristian and Køber, Lars V. and Holm, Hilma and Stefansson, Kari and Brunak, Søren and Bundgaard, Henning},
  date = {2023-06-20},
  eprinttype = {medRxiv},
  pages = {2023.06.16.23291527},
  doi = {10.1101/2023.06.16.23291527},
  url = {https://www.medrxiv.org/content/10.1101/2023.06.16.23291527v1},
  urldate = {2023-09-08},
  abstract = {Background Current risk prediction models for ischemic heart disease (IHD) use a limited set of established risk factors and are based on classical statistical techniques. Using machine-learning techniques and including a broader panel of features from electronic health records (EHRs) may improve prognostication. Objectives Developing and externally validating a neural network-based time-to-event model (PMHnet) for prediction of all-cause mortality in IHD. Methods We included 39,746 patients (training: 34,746, test: 5,000) with IHD from the Eastern Danish Heart Registry, who underwent coronary angiography (CAG) between 2006-2016. Clinical and genetic features were extracted from national registries, EHRs, and biobanks. The feature-selection process identified 584 features, including prior diagnosis and procedure codes, laboratory test results, and clinical measurements. Model performance was evaluated using time-dependent AUC (tdAUC) and the Brier score. PMHnet was benchmarked against GRACE Risk Score 2.0 (GRACE2.0), and externally validated using data from Iceland (n=8,287). Feature importance and model explainability were assessed using SHAP analysis. Findings On the test set, the tdAUC was 0.88 (95\% CI 0.86-0.90, case count, cc=196) at six months, 0.88(0.86-0.90, cc=261) at one year, 0.84(0.82-0.86, cc=395) at three years, and 0.82(0.80-0.84, cc=763) at five years. On the same data, GRACE2.0 had a lower performance: 0.77 (0.73-0.80) at six months, 0.77(0.74-0.80) at one year, and 0.73(0.70-0.75) at three years. PMHnet showed similar performance in the Icelandic data. Conclusion PMHnet significantly improved survival prediction in patients with IHD compared to GRACE2.0. Our findings support the use of deep phenotypic data as precision medicine tools in modern healthcare systems.},
  langid = {english},
  pubstate = {preprint},
  file = {C:\Users\sdp490\Zotero\storage\HAH4YHP7\Holm et al. - 2023 - Development and validation of a neural network-bas.pdf}
}

@software{holmDiscotime,
  title = {Discotime: {{Discrete-time}} Competing Risk Analysis with Neural Networks},
  shorttitle = {Discotime},
  author = {Holm, Peter},
  url = {https://github.com/peterchristofferholm/discotime},
  urldate = {2023-12-25},
  version = {0.1.0},
  file = {C:\Users\sdp490\Zotero\storage\KB5YGYQK\discotime.html}
}

@article{jensenIschemic2020,
  title = {Ischemic {{Heart Disease}}: {{An Update}}},
  shorttitle = {Ischemic {{Heart Disease}}},
  author = {Jensen, Rebekka Vibjerg and Hjortbak, Marie Vognstoft and Bøtker, Hans Erik},
  date = {2020-05},
  journaltitle = {Seminars in Nuclear Medicine},
  shortjournal = {Semin Nucl Med},
  volume = {50},
  number = {3},
  eprint = {32284106},
  eprinttype = {pmid},
  pages = {195--207},
  issn = {1558-4623},
  doi = {10.1053/j.semnuclmed.2020.02.007},
  abstract = {Ischemic heart disease is a dynamic process of atherosclerosis of the coronary arteries or functional alterations of coronary circulation that can be modified by lifestyle, pharmacological therapies, and revascularization. Such treatment may result in disease stabilization or regression. New terminology describes clinical presentations of Ischemic heart disease categorized as either acute coronary syndrome or chronic coronary syndrome. The reduction in prevalence of obstructive coronary artery disease in a symptomatic population causes a lower pretest probability and clinical likelihood of disease, influencing the diagnostic work-up. Noninvasive functional or anatomic imaging for myocardial ischemia is recommended as the initial test to diagnose coronary artery disease in symptomatic patients, where obstructive disease cannot be excluded by clinical assessment alone. Coronary computed tomography (CT) angiography has advanced and is first line in suitable patients, due to high rule-out power and further qualification of the diagnosis by functional assessment using noninvasive nuclear or magnetic resonance technology or CT-based fractional flow reserve (FFR-CT). Optimal medical treatment remains paramount, while FFR-guided myocardial revascularization in patients that are not responsive to antianginal treatment provides further symptom relieve as well as prognostic impact on prevention of spontaneous myocardial infarction.},
  langid = {english},
  keywords = {{Fractional Flow Reserve, Myocardial},Humans,Magnetic Resonance Imaging,Myocardial Ischemia,{Tomography, X-Ray Computed}}
}

@article{jensenMining2012,
  title = {Mining Electronic Health Records: Towards Better Research Applications and Clinical Care},
  shorttitle = {Mining Electronic Health Records},
  author = {Jensen, Peter B. and Jensen, Lars J. and Brunak, Søren},
  date = {2012-06},
  journaltitle = {Nature Reviews Genetics},
  shortjournal = {Nat Rev Genet},
  volume = {13},
  number = {6},
  pages = {395--405},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0064},
  doi = {10.1038/nrg3208},
  url = {https://www.nature.com/articles/nrg3208},
  urldate = {2023-11-29},
  abstract = {Electronic health record (EHR) systems are increasingly being implemented all over the world, but represent a vast, underused data resource for biomedical research.Structured EHR data, such as encoded diagnosis and medication information, are the easiest data sources to process, but advances in text-mining methods has made it possible to also use the narrative parts of patient records.Statistical studies of the distribution and co-occurrence of clinical features in large collections of patient records enables identification of correlations between, for example, diseases (comorbidities) or between medications and adverse drug reactions.Knowledge-discovery and machine-learning methods can be used both for discovering novel patterns in patient data and for classification and predictive purposes, such as outcome or risk assessment. This has the potential to extend current EHR decision support systems, which integrate available patient data with clinical guidelines to provide assistance to the physician at the point of care.Research platforms built on EHR data, alone or coupled to genotype data, provide an inexpensive and timely way to sample relevant case and control cohorts based on relevant clinical features. As EHR and DNA databases become increasingly interlinked, genotype–phenotype association studies may be designed and conducted by re-using existing data.The growing political focus on the adoption of EHR systems must be accompanied by funding and strategic research into data standards, interoperability and security. Legal matters such as data ownership, privacy and consent need to be addressed to find the right balance between public demands for autonomy and privacy, and manageable procedures for researchers to access data.Fulfilling the full potential of electronic health data for scientific discovery and improved public health will require collaboration across stakeholders and research groups.},
  issue = {6},
  langid = {english},
  keywords = {Bioinformatics,Clinical genetics,Data mining,Disease genetics,Genetic databases,Pharmacogenetics},
  file = {C:\Users\sdp490\Zotero\storage\7ZWD92S5\Jensen et al. - 2012 - Mining electronic health records towards better r.pdf}
}

@article{jensenTemporal2014,
  title = {Temporal Disease Trajectories Condensed from Population-Wide Registry Data Covering 6.2 Million Patients},
  author = {Jensen, Anders Boeck and Moseley, Pope L. and Oprea, Tudor I. and Ellesøe, Sabrina Gade and Eriksson, Robert and Schmock, Henriette and Jensen, Peter Bjødstrup and Jensen, Lars Juhl and Brunak, Søren},
  date = {2014-06-24},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {5},
  number = {1},
  pages = {4022},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/ncomms5022},
  url = {https://www.nature.com/articles/ncomms5022},
  urldate = {2023-12-31},
  abstract = {A key prerequisite for precision medicine is the estimation of disease progression from the current patient state. Disease correlations and temporal disease progression (trajectories) have mainly been analysed with focus on a small number of diseases or using large-scale approaches without time consideration, exceeding a few years. So far, no large-scale studies have focused on defining a comprehensive set of disease trajectories. Here we present a discovery-driven analysis of temporal disease progression patterns using data from an electronic health registry covering the whole population of Denmark. We use the entire spectrum of diseases and convert 14.9 years of registry data on 6.2 million patients into 1,171 significant trajectories. We group these into patterns centred on a small number of key diagnoses such as chronic obstructive pulmonary disease (COPD) and gout, which are central to disease progression and hence important to diagnose early to mitigate the risk of adverse outcomes. We suggest such trajectory analyses may be useful for predicting and preventing future diseases of individual patients.},
  issue = {1},
  langid = {english},
  keywords = {Health care,Medical research},
  file = {C:\Users\sdp490\Zotero\storage\GLZEKB5L\Jensen et al. - 2014 - Temporal disease trajectories condensed from popul.pdf}
}

@article{jordanMachine2015,
  title = {Machine Learning: {{Trends}}, Perspectives, and Prospects},
  shorttitle = {Machine Learning},
  author = {Jordan, M. I. and Mitchell, T. M.},
  date = {2015-07-17},
  journaltitle = {Science},
  volume = {349},
  number = {6245},
  pages = {255--260},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aaa8415},
  url = {https://www.science.org/doi/10.1126/science.aaa8415},
  urldate = {2023-10-24},
  abstract = {Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today’s most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.}
}

@article{kaas-hansenLanguageagnostic2022,
  title = {Language-Agnostic Pharmacovigilant Text Mining to Elicit Side Effects from Clinical Notes and Hospital Medication Records},
  author = {Kaas-Hansen, Benjamin Skov and Placido, Davide and Rodríguez, Cristina Leal and Thorsen-Meyer, Hans-Christian and Gentile, Simona and Nielsen, Anna Pors and Brunak, Søren and Jürgens, Gesche and Andersen, Stig Ejdrup},
  date = {2022},
  journaltitle = {Basic \& Clinical Pharmacology \& Toxicology},
  volume = {131},
  number = {4},
  pages = {282--293},
  issn = {1742-7843},
  doi = {10.1111/bcpt.13773},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/bcpt.13773},
  urldate = {2023-11-28},
  abstract = {We sought to craft a drug safety signalling pipeline associating latent information in clinical free text with exposures to single drugs and drug pairs. Data arose from 12 secondary and tertiary public hospitals in two Danish regions, comprising approximately half the Danish population. Notes were operationalised with a fastText embedding, based on which we trained 10 270 neural-network models (one for each distinct single-drug/drug-pair exposure) predicting the risk of exposure given an embedding vector. We included 2 905 251 admissions between May 2008 and June 2016, with 13 740 564 distinct drug prescriptions; the median number of prescriptions was 5 (IQR: 3–9) and in 1 184 340 (41\%) admissions patients used ≥5 drugs concomitantly. A total of 10 788 259 clinical notes were included, with 179 441 739 tokens retained after pruning. Of 345 single-drug signals reviewed, 28 (8.1\%) represented possibly undescribed relationships; 186 (54\%) signals were clinically meaningful. Sixteen (14\%) of the 115 drug-pair signals were possible interactions, and two (1.7\%) were known. In conclusion, we built a language-agnostic pipeline for mining associations between free-text information and medication exposure without manual curation, predicting not the likely outcome of a range of exposures but also the likely exposures for outcomes of interest. Our approach may help overcome limitations of text mining methods relying on curated data in English and can help leverage non-English free text for pharmacovigilance.},
  langid = {english},
  keywords = {data mining,machine learning,pharmacovigilance,safety signal detection,safety signal refinement},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\FRM87WTD\\Kaas-Hansen et al. - 2022 - Language-agnostic pharmacovigilant text mining to .pdf;C\:\\Users\\sdp490\\Zotero\\storage\\AJVVQCSH\\bcpt.html}
}

@book{kalbfleischStatistical2002,
  title = {The {{Statistical Analysis}} of {{Failure Time Data}}, 2nd {{Edition}}},
  author = {Kalbfleisch},
  date = {2002-08-26},
  edition = {2nd edition},
  publisher = {{Wiley-Interscience}},
  location = {{Hoboken, N.J}},
  abstract = {* Contains additional discussion and examples on left truncation as well as material on more general censoring and truncation patterns. * Introduces the martingale and counting process formulation swil lbe in a new chapter. * Develops multivariate failure time data in a separate chapter and extends the material on Markov and semi Markov formulations. * Presents new examples and applications of data analysis.},
  isbn = {978-0-471-36357-6},
  langid = {english},
  pagetotal = {462}
}

@article{kaplan1958nonparametric,
  title = {Nonparametric Estimation from Incomplete Observations},
  author = {Kaplan, Edward L and Meier, Paul},
  date = {1958},
  journaltitle = {Journal of the American statistical association},
  volume = {53},
  number = {282},
  pages = {457--481},
  publisher = {{Taylor \& Francis}}
}

@article{kattanIndex2018,
  title = {The Index of Prediction Accuracy: An Intuitive Measure Useful for Evaluating Risk Prediction Models},
  shorttitle = {The Index of Prediction Accuracy},
  author = {Kattan, Michael W. and Gerds, Thomas A.},
  date = {2018-05-04},
  journaltitle = {Diagnostic and Prognostic Research},
  shortjournal = {Diagnostic and Prognostic Research},
  volume = {2},
  number = {1},
  pages = {7},
  issn = {2397-7523},
  doi = {10.1186/s41512-018-0029-2},
  url = {https://doi.org/10.1186/s41512-018-0029-2},
  urldate = {2023-09-14},
  abstract = {Many measures of prediction accuracy have been developed. However, the most popular ones in typical medical outcome prediction settings require additional investigation of calibration.},
  keywords = {Accuracy,Brier score,Prediction},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\ALHPGQ8A\\Kattan and Gerds - 2018 - The index of prediction accuracy an intuitive mea.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\3PGRMB7S\\s41512-018-0029-2.html}
}

@article{katzmanDeepSurv2018a,
  title = {{{DeepSurv}}: Personalized Treatment Recommender System Using a {{Cox}} Proportional Hazards Deep Neural Network},
  shorttitle = {{{DeepSurv}}},
  author = {Katzman, Jared L. and Shaham, Uri and Cloninger, Alexander and Bates, Jonathan and Jiang, Tingting and Kluger, Yuval},
  date = {2018-02-26},
  journaltitle = {BMC Medical Research Methodology},
  shortjournal = {BMC Medical Research Methodology},
  volume = {18},
  number = {1},
  pages = {24},
  issn = {1471-2288},
  doi = {10.1186/s12874-018-0482-1},
  url = {https://doi.org/10.1186/s12874-018-0482-1},
  urldate = {2023-10-31},
  abstract = {Medical practitioners use survival models to explore and understand the relationships between patients’ covariates (e.g. clinical and genetic features) and the effectiveness of various treatment options. Standard survival models like the linear Cox proportional hazards model require extensive feature engineering or prior medical knowledge to model treatment interaction at an individual level. While nonlinear survival methods, such as neural networks and survival forests, can inherently model these high-level interaction terms, they have yet to be shown as effective treatment recommender systems.},
  keywords = {Deep learning,Survival analysis,Treatment recommendations},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\5VXAM8Y6\\Katzman et al. - 2018 - DeepSurv personalized treatment recommender syste.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\PL8Q6GPE\\s12874-018-0482-1.html}
}

@article{kellyKey2019,
  title = {Key Challenges for Delivering Clinical Impact with Artificial Intelligence},
  author = {Kelly, Christopher J. and Karthikesalingam, Alan and Suleyman, Mustafa and Corrado, Greg and King, Dominic},
  date = {2019-10-29},
  journaltitle = {BMC Medicine},
  shortjournal = {BMC Medicine},
  volume = {17},
  number = {1},
  pages = {195},
  issn = {1741-7015},
  doi = {10.1186/s12916-019-1426-2},
  url = {https://doi.org/10.1186/s12916-019-1426-2},
  urldate = {2023-05-18},
  abstract = {Artificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice.},
  keywords = {Algorithms,Artificial intelligence,Evaluation,Machine learning,Regulation,Translation},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\SKK988MN\\Kelly et al. - 2019 - Key challenges for delivering clinical impact with.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\4YG5I3MJ\\s12916-019-1426-2.html}
}

@article{kildemoesDanish2011,
  title = {The {{Danish National Prescription Registry}}},
  author = {Kildemoes, Helle Wallach and Sørensen, Henrik Toft and Hallas, Jesper},
  date = {2011-07},
  journaltitle = {Scandinavian Journal of Public Health},
  shortjournal = {Scand J Public Health},
  volume = {39},
  eprint = {21775349},
  eprinttype = {pmid},
  pages = {38--41},
  issn = {1651-1905},
  doi = {10.1177/1403494810394717},
  abstract = {INTRODUCTION: Individual-level data on all prescription drugs sold in Danish community pharmacies has since 1994 been recorded in the Register of Medicinal Products Statistics of the Danish Medicines Agency. CONTENT: The register subset, termed the Danish National Prescription Registry (DNPR), contains information on dispensed prescriptions, including variables at the level of the drug user, the prescriber, and the pharmacy. VALIDITY AND COVERAGE: Reimbursement-driven record keeping, with automated bar-code-based data entry provides data of high quality, including detailed information on the dispensed drug. CONCLUSION: The possibility of linkage with many other nationwide individual-level data sources renders the DNPR a very powerful pharmacoepidemiological tool.},
  issue = {7 Suppl},
  langid = {english},
  keywords = {Denmark,Drug Prescriptions,Humans,Pharmacoepidemiology,Registries,Research},
  file = {C:\Users\sdp490\Zotero\storage\QHRYNVCY\Kildemoes et al. - 2011 - The Danish National Prescription Registry.pdf}
}

@article{killipTreatment1967,
  title = {Treatment of Myocardial Infarction in a Coronary Care Unit: {{A Two}} Year Experience with 250 Patients},
  shorttitle = {Treatment of Myocardial Infarction in a Coronary Care Unit},
  author = {Killip, Thomas and Kimball, John T.},
  date = {1967-10-01},
  journaltitle = {The American Journal of Cardiology},
  shortjournal = {The American Journal of Cardiology},
  series = {Symposium on {{Coronary Care Units}}},
  volume = {20},
  number = {4},
  pages = {457--464},
  issn = {0002-9149},
  doi = {10.1016/0002-9149(67)90023-9},
  url = {https://www.sciencedirect.com/science/article/pii/0002914967900239},
  urldate = {2023-11-28},
  abstract = {The results of treatment of 250 patients with established acute myocardial infarction in a coronary care unit in a university hospital are described. The criteria for diagnosis have been carefully defined. In 62 per cent of patients admitted with a tentative diagnosis of acute infarction, the initial impression was confirmed. Fifteen per cent of patients admitted to the unit were classified as having possible infarction; in this group, the mortality rate was 3 per cent. A classification of functional severity based on clinical evidence of heart failure or shock is presented. Morbidity and mortality in acute myocardial infarction are related to the functional severity of the illness. Although arrhythmia is common, the overriding importance of five life-threatening arrhythmias is emphasized. Mortality of patients in the coronary care unit was not improved in comparison to those treated under regular care until strong central direction of therapeutic programs, immediate treatment of arrhythmia in cardiac arrest, and delegation of some medical authority to trained nurses was accomplished. The change in concept of the purposes and practices of special coronary care from resuscitation to prevention of arrhythmia is emphasized. The mortality in myocardial infarction complicated by shock remains high. In the absence of shock, aggressive medical treatment in the coronary care unit reduced mortality from 26 to 7 per cent. The implications of these data in the management of patients admitted to a hospital with a diagnosis of acute myocardial infarction are discussed.},
  file = {C:\Users\sdp490\Zotero\storage\8MAJU3BD\0002914967900239.html}
}

@article{kirkLinking2019,
  title = {Linking Glycemic Dysregulation in Diabetes to Symptoms, Comorbidities, and Genetics through {{EHR}} Data Mining},
  author = {Kirk, Isa Kristina and Simon, Christian and Banasik, Karina and Holm, Peter Christoffer and Haue, Amalie Dahl and Jensen, Peter Bjødstrup and Juhl Jensen, Lars and Rodríguez, Cristina Leal and Pedersen, Mette Krogh and Eriksson, Robert and Andersen, Henrik Ullits and Almdal, Thomas and Bork-Jensen, Jette and Grarup, Niels and Borch-Johnsen, Knut and Pedersen, Oluf and Pociot, Flemming and Hansen, Torben and Bergholdt, Regine and Rossing, Peter and Brunak, Søren},
  editor = {Valencia, Alfonso and Barkai, Naama},
  date = {2019-12-10},
  journaltitle = {eLife},
  volume = {8},
  pages = {e44941},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.44941},
  url = {https://doi.org/10.7554/eLife.44941},
  urldate = {2023-11-29},
  abstract = {Diabetes is a diverse and complex disease, with considerable variation in phenotypic manifestation and severity. This variation hampers the study of etiological differences and reduces the statistical power of analyses of associations to genetics, treatment outcomes, and complications. We address these issues through deep, fine-grained phenotypic stratification of a diabetes cohort. Text mining the electronic health records of 14,017 patients, we matched two controlled vocabularies (ICD-10 and a custom vocabulary developed at the clinical center Steno Diabetes Center Copenhagen) to clinical narratives spanning a 19 year period. The two matched vocabularies comprise over 20,000 medical terms describing symptoms, other diagnoses, and lifestyle factors. The cohort is genetically homogeneous (Caucasian diabetes patients from Denmark) so the resulting stratification is not driven by ethnic differences, but rather by inherently dissimilar progression patterns and lifestyle related risk factors. Using unsupervised Markov clustering, we defined 71 clusters of at least 50 individuals within the diabetes spectrum. The clusters display both distinct and shared longitudinal glycemic dysregulation patterns, temporal co-occurrences of comorbidities, and associations to single nucleotide polymorphisms in or near genes relevant for diabetes comorbidities.},
  keywords = {comorbidities,diabetes,diabetes subtypes,EHR,genotyping,text mining},
  file = {C:\Users\sdp490\Zotero\storage\YH2M254X\Kirk et al. - 2019 - Linking glycemic dysregulation in diabetes to symp.pdf}
}

@book{kleinbaumSurvival2011,
  title = {Survival {{Analysis}}: {{A Self-Learning Text}}, {{Third Edition}}},
  shorttitle = {Survival {{Analysis}}},
  author = {Kleinbaum, David G. and Klein, Mitchel},
  date = {2011-08-31},
  edition = {3rd edition},
  publisher = {{Springer}},
  location = {{New York, NY}},
  abstract = {An excellent introduction for all those coming to the subject for the first time.New material has been added to the second edition and the original six chapters have been modified.The previous edition sold 9500 copies world wide since its release in 1996.Based on numerous courses given by the author to students and researchers in the health sciences and is written with such readers in mind. Provides a "user-friendly" layout and includes numerous illustrations and exercises. Written in such a way so as to enable readers learn directly without the assistance of a classroom instructor. Throughout, there is an emphasis on presenting each new topic backed by real examples of a survival analysis investigation, followed up with thorough analyses of real data sets.},
  isbn = {978-1-4419-6645-2},
  langid = {english},
  pagetotal = {715}
}

@book{kleinSurvival2003,
  title = {Survival {{Analysis}}: {{Techniques}} for {{Censored}} and {{Truncated Data}}},
  shorttitle = {Survival {{Analysis}}},
  author = {Klein, John P. and Moeschberger, Melvin L.},
  date = {2003},
  series = {Statistics for {{Biology}} and {{Health}}},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/b97377},
  url = {http://link.springer.com/10.1007/b97377},
  urldate = {2023-08-31},
  isbn = {978-0-387-95399-1 978-0-387-21645-4},
  langid = {english},
  keywords = {Analysis,Censoring,Statistical Method,statistics,Survival analysis,Truncated Data},
  file = {C:\Users\sdp490\Zotero\storage\UTGM86TI\Klein and Moeschberger - 2003 - Survival Analysis Techniques for Censored and Tru.pdf}
}

@article{knuuti20192020,
  title = {2019 {{ESC Guidelines}} for the Diagnosis and Management of Chronic Coronary Syndromes},
  shorttitle = {2019 {{ESC Guidelines}} for the Diagnosis and Management of Chronic Coronary Syndromes},
  author = {Knuuti, Juhani and Wijns, William and Saraste, Antti and Capodanno, Davide and Barbato, Emanuele and Funck-Brentano, Christian and Prescott, Eva and Storey, Robert F and Deaton, Christi and Cuisset, Thomas and Agewall, Stefan and Dickstein, Kenneth and Edvardsen, Thor and Escaned, Javier and Gersh, Bernard J and Svitil, Pavel and Gilard, Martine and Hasdai, David and Hatala, Robert and Mahfoud, Felix and Masip, Josep and Muneretto, Claudio and Valgimigli, Marco and Achenbach, Stephan and Bax, Jeroen J and {ESC Scientific Document Group}},
  date = {2020-01-14},
  journaltitle = {European Heart Journal},
  shortjournal = {European Heart Journal},
  volume = {41},
  number = {3},
  pages = {407--477},
  issn = {0195-668X},
  doi = {10.1093/eurheartj/ehz425},
  url = {https://doi.org/10.1093/eurheartj/ehz425},
  urldate = {2023-10-05},
  abstract = {For the Supplementary Data which include background information and detailed discussion of the data that have provided the basis for the Guidelines see https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehz425\#supplementary-data},
  file = {C:\Users\sdp490\Zotero\storage\FJU7CN9D\Knuuti et al. - 2020 - 2019 ESC Guidelines for the diagnosis and manageme.pdf}
}

@article{konigWhat2017,
  title = {What Is Precision Medicine?},
  author = {König, Inke R. and Fuchs, Oliver and Hansen, Gesine and Von Mutius, Erika and Kopp, Matthias V.},
  date = {2017-10},
  journaltitle = {European Respiratory Journal},
  shortjournal = {Eur Respir J},
  volume = {50},
  number = {4},
  pages = {1700391},
  issn = {0903-1936, 1399-3003},
  doi = {10.1183/13993003.00391-2017},
  url = {http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00391-2017},
  urldate = {2023-05-11},
  abstract = {The term “precision medicine” has become very popular over recent years, fuelled by scientific as well as political perspectives. Despite its popularity, its exact meaning, and how it is different from other popular terms such as “stratified medicine”, “targeted therapy” or “deep phenotyping” remains unclear. Commonly applied definitions focus on the stratification of patients, sometimes referred to as a novel taxonomy, and this is derived using large-scale data including clinical, lifestyle, genetic and further biomarker information, thus going beyond the classical “signs-and-symptoms” approach.},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\8PRVCLXP\König et al. - 2017 - What is precision medicine.pdf}
}

@article{kosorokPrecision2019,
  title = {Precision {{Medicine}}},
  author = {Kosorok, Michael R. and Laber, Eric B.},
  date = {2019},
  journaltitle = {Annual Review of Statistics and Its Application},
  volume = {6},
  number = {1},
  pages = {263--286},
  doi = {10.1146/annurev-statistics-030718-105251},
  url = {https://doi.org/10.1146/annurev-statistics-030718-105251},
  urldate = {2023-10-11},
  abstract = {Precision medicine seeks to maximize the quality of health care by individualizing the health-care process to the uniquely evolving health status of each patient. This endeavor spans a broad range of scientific areas including drug discovery, genetics/genomics, health communication, and causal inference, all in support of evidence-based, i.e., data-driven, decision making. Precision medicine is formalized as a treatment regime that comprises a sequence of decision rules, one per decision point, which map up-to-date patient information to a recommended action. The potential actions could be the selection of which drug to use, the selection of dose, the timing of administration, the recommendation of a specific diet or exercise, or other aspects of treatment or care. Statistics research in precision medicine is broadly focused on methodological development for estimation of and inference for treatment regimes that maximize some cumulative clinical outcome. In this review, we provide an overview of this vibrant area of research and present important and emerging challenges.},
  file = {C:\Users\sdp490\Zotero\storage\CWA6STI5\Kosorok and Laber - 2019 - Precision Medicine.pdf}
}

@article{kuanIdentifying2023,
  title = {Identifying and Visualising Multimorbidity and Comorbidity Patterns in Patients in the {{English National Health Service}}: A Population-Based Study},
  shorttitle = {Identifying and Visualising Multimorbidity and Comorbidity Patterns in Patients in the {{English National Health Service}}},
  author = {Kuan, Valerie and Denaxas, Spiros and Patalay, Praveetha and Nitsch, Dorothea and Mathur, Rohini and Gonzalez-Izquierdo, Arturo and Sofat, Reecha and Partridge, Linda and Roberts, Amanda and Wong, Ian C. K. and Hingorani, Melanie and Chaturvedi, Nishi and Hemingway, Harry and Hingorani, Aroon D. and Alexander, Daniel C. and Asiimwe, Innocent G. and Ball, Simon and Bennett, Frances and Borges, Maria Carolina and Butterworth, Adam and Chaturvedi, Nishi and Chopade, Sandesh and Clarkson, Christopher and Cox, Martin and Dale, Caroline and Denaxas, Spiros and Dunca, Diana and Engmann, Jorgen E. and Fernandez-Sanles, Alba and Finan, Chris and Fitzpatrick, Natalie and Gallagher, Jean and Gonzalez-Izquierdo, Arturo and Gratton, Jasmine and Gross, Christian and Hemingway, Harry and Henry, Albert and Hidajat, Mira and Hingorani, Aroon and Hukerikar, Nikita and Jorgensen, Andrea and Joshi, Roshni and Katsoulis, Michail and Kuan, Valerie and Kumar, Rashmi and Lai, Alvina G. and Langenberg, Claudia and Lawlor, Deborah and Mancini, Mary and Miller, Diane and Ogden, Margaret and Ozyigit, Eda B. and Patel, Shilpa and Pirmohamed, Munir and Roberts, Amanda and Ryan, David and Schmidt, Amand F. and Shah, Anoop D. and Shah, Tina and Sofat, Reecha and Takhar, Rohan and Torralbo, Ana and Ullah, Ayath and Walker, Lauren E. and Warwick, Alasdair and Wheeler, Eleanor and Wright, Victoria L. and Wu, Honghan and Zwierzyna, Magdalena},
  date = {2023-01-01},
  journaltitle = {The Lancet Digital Health},
  shortjournal = {The Lancet Digital Health},
  volume = {5},
  number = {1},
  eprint = {36460578},
  eprinttype = {pmid},
  pages = {e16-e27},
  publisher = {{Elsevier}},
  issn = {2589-7500},
  doi = {10.1016/S2589-7500(22)00187-X},
  url = {https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00187-X/fulltext},
  urldate = {2023-11-30},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\JEXFN3PR\Kuan et al. - 2023 - Identifying and visualising multimorbidity and com.pdf}
}

@book{kumarRobbins2014,
  title = {Robbins and {{Cotran Pathologic Basis}} of {{Disease}}},
  author = {Kumar, Vinay and Abbas, Abul K. and Fausto, Nelson and Aster, Jon C.},
  date = {2014-08-27},
  eprint = {jJllBAAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Elsevier Health Sciences}},
  abstract = {Dependable, current, and complete, Robbins and Cotran Pathologic Basis of Disease, 9th Edition is the perennially best-selling text that you’ll use long after your medical student days are behind you. A world-class author team headed by Drs. Vinay Kumar, Abul Abbas, and Jon Aster, delivers the latest, most essential pathology knowledge in a readable, interesting manner, ensuring optimal understanding of the latest basic science and clinical content. High-quality photographs and full-color illustrations highlight new information in molecular biology, disease classifications, new drugs and drug therapies, and much more.Rely on uniquely authoritative and readable coverage, ideal for USMLE or specialty board preparation, as well as for course work.Simplify your study with an outstanding full-color, highly user-friendly design.Stay up to date with the latest information in molecular and genetic testing and mechanisms of disease.Consult new Targeted Therapy boxes online that discuss drug therapy for specific diseases.Gain a new perspective in key areas thanks to contributions from new authors at the top of their fields.Consult this title on your favorite e-reader, conduct rapid searches, and adjust font sizes for optimal readability.},
  isbn = {978-0-323-29639-7},
  langid = {english},
  pagetotal = {1413},
  keywords = {Medical / Pathology}
}

@book{kumarRobbins2017,
  title = {Robbins {{Basic Pathology E-Book}}: {{Robbins Basic Pathology E-Book}}},
  shorttitle = {Robbins {{Basic Pathology}}},
  author = {Kumar, Vinay and Abbas, Abul K. and Aster, Jon C.},
  date = {2017-03-08},
  eprint = {YYZMDgAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Elsevier Health Sciences}},
  abstract = {Part of the trusted Robbins and Cotran family, Robbins Basic Pathology provides a readable, well-illustrated and concise overview of the principles of human pathology that's ideal for today's busy students. This thoroughly revised edition continues with a strong emphasis on pathogenesis and the clinical features of disease, adding new artwork and more schematic diagrams to further aid in summarizing key pathologic processes and expand the already impressive illustration program. Excellent art program boasts high-quality photomicrographs, gross photos, and radiologic images to supplement the world-class illustrations.   Bulleted summary boxes provide quick access to key information and easy review of key concepts.    Highlights pathogenesis, morphology, and pathophysiologic content throughout.   Includes increased and updated clinical topics.   New artwork and more schematic diagrams summarize key pathologic processes.    An all-star editorial team enables you to gain a rich understanding of all essential pathology concepts.    Student Consult eBook version included with purchase. This enhanced eBook experience allows you to search all of the text, figures, and images from the book on a variety of devices. You'll also access virtual microscope slides, self-assessment questions, additional images, updated pathology case studies, and Targeted Therapy boxes.},
  isbn = {978-0-323-39413-0},
  langid = {english},
  pagetotal = {955},
  keywords = {Medical / Pathology}
}

@article{kvammeContinuous2021,
  title = {Continuous and Discrete-Time Survival Prediction with Neural Networks},
  author = {Kvamme, Håvard and Borgan, Ørnulf},
  date = {2021-10-01},
  journaltitle = {Lifetime Data Analysis},
  shortjournal = {Lifetime Data Anal},
  volume = {27},
  number = {4},
  pages = {710--736},
  issn = {1572-9249},
  doi = {10.1007/s10985-021-09532-6},
  url = {https://doi.org/10.1007/s10985-021-09532-6},
  urldate = {2021-12-22},
  abstract = {Due to rapid developments in machine learning, and in particular neural networks, a number of new methods for time-to-event predictions have been developed in the last few years. As neural networks are parametric models, it is more straightforward to integrate parametric survival models in the neural network framework than the popular semi-parametric Cox model. In particular, discrete-time survival models, which are fully parametric, are interesting candidates to extend with neural networks. The likelihood for discrete-time survival data may be parameterized by the probability mass function (PMF) or by the discrete hazard rate, and both of these formulations have been used to develop neural network-based methods for time-to-event predictions. In this paper, we review and compare these approaches. More importantly, we show how the discrete-time methods may be adopted as approximations for continuous-time data. To this end, we introduce two discretization schemes, corresponding to equidistant times or equidistant marginal survival probabilities, and two ways of interpolating the discrete-time predictions, corresponding to piecewise constant density functions or piecewise constant hazard rates. Through simulations and study of real-world data, the methods based on the hazard rate parametrization are found to perform slightly better than the methods that use the PMF parametrization. Inspired by these investigations, we also propose a continuous-time method by assuming that the continuous-time hazard rate is piecewise constant. The method, named PC-Hazard, is found to be highly competitive with the aforementioned methods in addition to other methods for survival prediction found in the literature.},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\TX9WR7IR\Kvamme and Borgan - 2021 - Continuous and discrete-time survival prediction w.pdf}
}

@inproceedings{lecunHandwritten1989,
  title = {Handwritten {{Digit Recognition}} with a {{Back-Propagation Network}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {LeCun, Yann and Boser, Bernhard and Denker, John and Henderson, Donnie and Howard, R. and Hubbard, Wayne and Jackel, Lawrence},
  date = {1989},
  volume = {2},
  publisher = {{Morgan-Kaufmann}},
  url = {https://proceedings.neurips.cc/paper_files/paper/1989/hash/53c3bce66e43be4f209556518c2fcb54-Abstract.html},
  urldate = {2023-10-29},
  abstract = {We present an application of back-propagation networks to hand(cid:173) written digit recognition. Minimal preprocessing of the data was  required, but architecture of the network was highly constrained  and specifically designed for the task. The input of the network  consists of normalized images of isolated digits. The method has  1 \% error rate and about a 9\% reject rate on zipcode digits provided  by the U.S. Postal Service.},
  file = {C:\Users\sdp490\Zotero\storage\8TCLYNNR\LeCun et al. - 1989 - Handwritten Digit Recognition with a Back-Propagat.pdf}
}

@article{ledleyReasoning1959,
  title = {Reasoning {{Foundations}} of {{Medical Diagnosis}}},
  author = {Ledley, Robert S. and Lusted, Lee B.},
  date = {1959},
  journaltitle = {Science},
  volume = {130},
  number = {3366},
  pages = {9--21},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  url = {https://www.jstor.org/stable/1758070},
  urldate = {2023-04-08},
  file = {C:\Users\sdp490\Zotero\storage\SPY7DDBY\Ledley and Lusted - 1959 - Reasoning Foundations of Medical Diagnosis.pdf}
}

@article{leeDeepHit2018,
  title = {{{DeepHit}}: {{A Deep Learning Approach}} to {{Survival Analysis With Competing Risks}}},
  shorttitle = {{{DeepHit}}},
  author = {Lee, Changhee and Zame, William and Yoon, Jinsung and family=Schaar, given=Mihaela, prefix=van der, useprefix=false},
  date = {2018-04-26},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {32},
  number = {1},
  issn = {2374-3468},
  doi = {10.1609/aaai.v32i1.11842},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/11842},
  urldate = {2023-09-08},
  abstract = {Survival analysis (time-to-event analysis) is widely used in economics and finance, engineering, medicine and many other areas. A fundamental problem is to understand the relationship between the covariates and the (distribution of) survival times(times-to-event). Much of the previous work has approached the problem by viewing the survival time as the first hitting time of a stochastic process, assuming a specific form for the underlying stochastic process, using available data to learn the relationship between the covariates and the parameters of the model, and then deducing the relationship between covariates and the distribution of first hitting times (the risk). However, previous models rely on strong parametric assumptions that are often violated. This paper proposes a very different approach to survival analysis, DeepHit, that uses a deep neural network to learn the distribution of survival times directly.DeepHit makes no assumptions about the underlying stochastic process and allows for the possibility that the relationship between covariates and risk(s) changes over time. Most importantly, DeepHit smoothly handles competing risks; i.e. settings in which there is more than one possible event of interest.Comparisons with previous models on the basis of real and synthetic datasets demonstrate that DeepHit achieves large and statistically significant performance improvements over previous state-of-the-art methods.},
  issue = {1},
  langid = {english},
  keywords = {first-hitting-time analysis},
  file = {C:\Users\sdp490\Zotero\storage\P2CD94KB\Lee et al. - 2018 - DeepHit A Deep Learning Approach to Survival Anal.pdf}
}

@article{lehneWhy2019,
  title = {Why Digital Medicine Depends on Interoperability},
  author = {Lehne, Moritz and Sass, Julian and Essenwanger, Andrea and Schepers, Josef and Thun, Sylvia},
  date = {2019-08-20},
  journaltitle = {npj Digital Medicine},
  shortjournal = {npj Digit. Med.},
  volume = {2},
  number = {1},
  pages = {1--5},
  publisher = {{Nature Publishing Group}},
  issn = {2398-6352},
  doi = {10.1038/s41746-019-0158-1},
  url = {https://www.nature.com/articles/s41746-019-0158-1},
  urldate = {2023-05-09},
  abstract = {Digital data are anticipated to transform medicine. However, most of today’s medical data lack interoperability: hidden in isolated databases, incompatible systems and proprietary software, the data are difficult to exchange, analyze, and interpret. This slows down medical progress, as technologies that rely on these data – artificial intelligence, big data or mobile applications – cannot be used to their full potential. In this article, we argue that interoperability is a prerequisite for the digital innovations envisioned for future medicine. We focus on four areas where interoperable data and IT systems are particularly important: (1) artificial intelligence and big data; (2) medical communication; (3) research; and (4) international cooperation. We discuss how interoperability can facilitate digital transformation in these areas to improve the health and well-being of patients worldwide.},
  issue = {1},
  langid = {english},
  keywords = {Health care,Health policy},
  file = {C:\Users\sdp490\Zotero\storage\UEGX5DYC\Lehne et al. - 2019 - Why digital medicine depends on interoperability.pdf}
}

@article{libbyPathophysiology2005,
  title = {Pathophysiology of {{Coronary Artery Disease}}},
  author = {Libby, Peter and Theroux, Pierre},
  date = {2005-06-28},
  journaltitle = {Circulation},
  volume = {111},
  number = {25},
  pages = {3481--3488},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIRCULATIONAHA.105.537878},
  url = {https://www.ahajournals.org/doi/full/10.1161/CIRCULATIONAHA.105.537878},
  urldate = {2023-10-05},
  abstract = {During the past decade, our understanding of the pathophysiology of coronary artery disease (CAD) has undergone a remarkable evolution. We review here how these advances have altered our concepts of and clinical approaches to both the chronic and acute phases of CAD. Previously considered a cholesterol storage disease, we currently view atherosclerosis as an inflammatory disorder. The appreciation of arterial remodeling (compensatory enlargement) has expanded attention beyond stenoses evident by angiography to encompass the biology of nonstenotic plaques. Revascularization effectively relieves ischemia, but we now recognize the need to attend to nonobstructive lesions as well. Aggressive management of modifiable risk factors reduces cardiovascular events and should accompany appropriate revascularization. We now recognize that disruption of plaques that may not produce critical stenoses causes many acute coronary syndromes (ACS). The disrupted plaque represents a “solid-state” stimulus to thrombosis. Alterations in circulating prothrombotic or antifibrinolytic mediators in the “fluid phase” of the blood can also predispose toward ACS. Recent results have established the multiplicity of “high-risk” plaques and the widespread nature of inflammation in patients prone to develop ACS. These findings challenge our traditional view of coronary atherosclerosis as a segmental or localized disease. Thus, treatment of ACS should involve 2 overlapping phases: first, addressing the culprit lesion, and second, aiming at rapid “stabilization” of other plaques that may produce recurrent events. The concept of “interventional cardiology” must expand beyond mechanical revascularization to embrace preventive interventions that forestall future events.},
  keywords = {acute coronary syndromes,atherogenesis,inflammation,ischemia,plaque},
  file = {C:\Users\sdp490\Zotero\storage\UWXS6D92\Libby and Theroux - 2005 - Pathophysiology of Coronary Artery Disease.pdf}
}

@online{loshchilovDecoupled2019,
  title = {Decoupled {{Weight Decay Regularization}}},
  author = {Loshchilov, Ilya and Hutter, Frank},
  date = {2019-01-04},
  eprint = {1711.05101},
  eprinttype = {arxiv},
  eprintclass = {cs, math},
  doi = {10.48550/arXiv.1711.05101},
  url = {http://arxiv.org/abs/1711.05101},
  urldate = {2023-09-14},
  abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is \textbackslash emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by \textbackslash emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Mathematics - Optimization and Control},
  file = {C:\Users\sdp490\Zotero\storage\Y5HWQLS8\1711.html}
}

@online{lpr2dok,
  title = {Landspatientregisteret, {{Dokumentation}}},
  url = {https://www.esundhed.dk/Dokumentation?rid=5},
  urldate = {2023-11-25},
  organization = {{eSundhed}},
  file = {C:\Users\sdp490\Zotero\storage\759E59W2\Dokumentation.html}
}

@inproceedings{lundbergUnified2017,
  title = {A {{Unified Approach}} to {{Interpreting Model Predictions}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lundberg, Scott M and Lee, Su-In},
  date = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html},
  urldate = {2023-11-02},
  abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
  file = {C:\Users\sdp490\Zotero\storage\XWUCHGMD\Lundberg and Lee - 2017 - A Unified Approach to Interpreting Model Predictio.pdf}
}

@article{lyngeDanish2011,
  title = {The {{Danish National Patient Register}}},
  author = {Lynge, Elsebeth and Sandegaard, Jakob Lynge and Rebolj, Matejka},
  date = {2011-07-01},
  journaltitle = {Scandinavian Journal of Public Health},
  shortjournal = {Scand J Public Health},
  volume = {39},
  pages = {30--33},
  publisher = {{SAGE Publications Ltd STM}},
  issn = {1403-4948},
  doi = {10.1177/1403494811401482},
  url = {https://doi.org/10.1177/1403494811401482},
  urldate = {2023-11-24},
  abstract = {Introduction: The Danish National Patient Register (NPR) was established in 1977, and it is considered to be the finest of its kind internationally. Content: At the onset the register included information on inpatient in somatic wards. The content of the register has gradually been expanded, and since 2007 the register has included information on all patients in Danish hospitals. Validity and coverage: Although the NPR is overall a sound data source, both the content and the definitions of single variables have changed over time. Changes in the organisation and provision of health services may affect both the type and the completeness of registrations. Conclusion: The NPR is a unique data source. Researchers using the data should carefully consider potential fallacies in the data before drawing conclusions.},
  issue = {7\_suppl},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\D2LDI7LF\Lynge et al. - 2011 - The Danish National Patient Register.pdf}
}

@article{magdalProperties2012,
  title = {Properties and Units in the Clinical Laboratory Sciences, {{Part XXIII}}. {{The NPU}} Terminology, Principles and Implementation –a User’s Guide ({{Technical Report}} 2011) ({{IFCC}}–{{IUPAC}}): {{International Federation}} of {{Clinical Chemistry}} and {{Laboratory Medicine}}: {{Scientifi}} c {{Division Committee}} on {{Nomenclature}} for {{Properties}} and {{Units}} ({{C-NPU}}) and {{International Union}} of {{Pure}} and {{Applied Chemistry}}: {{Chemistry}} and {{Human Health Division}} ({{VII}}) {{Subcommittee}} on {{Nomenclature}} for {{Properties}} and {{Units}} ({{SC-NPU}}) {{Project Number}}: 2006-012-1-700},
  shorttitle = {Properties and Units in the Clinical Laboratory Sciences, {{Part XXIII}}. {{The NPU}} Terminology, Principles and Implementation –a User’s Guide ({{Technical Report}} 2011) ({{IFCC}}–{{IUPAC}})},
  author = {Magdal, Ulla and Dybkaer, René and Olesen, Henrik},
  date = {2012-01-01},
  journaltitle = {Clinical Chemistry and Laboratory Medicine},
  volume = {50},
  number = {1},
  pages = {35--50},
  publisher = {{De Gruyter}},
  issn = {1437-4331},
  doi = {10.1515/cclm.2011.735},
  url = {https://www.degruyter.com/document/doi/10.1515/cclm.2011.735/html},
  urldate = {2023-11-28},
  abstract = {This document describes the application of the syntax, semantic rules and format of the NPU terminology for coded dedicated kinds-of-property in the various subject fields of the clinical laboratory sciences. The document sums up considerations and reasoning by the C-SC-NPU and collects the experience with the system through some 8~years of application in electronic health communication. Access to the NPU terminology in English is currently at www.labterm.dk, via the English download files from the Danish Release Centre under the National Board of Health. Updates to the terminology are usually presented once a month.},
  langid = {english},
  keywords = {clinical laboratory,coding scheme,dedicated kind-of-property,electronic transmission,examination,measurement unit,NPU entry,property,semantic rule,syntax}
}

@article{mcdonaldLOINC2003,
  title = {{{LOINC}}, a {{Universal Standard}} for {{Identifying Laboratory Observations}}: {{A}} 5-{{Year Update}}},
  shorttitle = {{{LOINC}}, a {{Universal Standard}} for {{Identifying Laboratory Observations}}},
  author = {McDonald, Clement J and Huff, Stanley M and Suico, Jeffrey G and Hill, Gilbert and Leavelle, Dennis and Aller, Raymond and Forrey, Arden and Mercer, Kathy and DeMoor, Georges and Hook, John and Williams, Warren and Case, James and Maloney, Pat and {for the Laboratory LOINC Developers}},
  date = {2003-04-01},
  journaltitle = {Clinical Chemistry},
  shortjournal = {Clinical Chemistry},
  volume = {49},
  number = {4},
  pages = {624--633},
  issn = {0009-9147},
  doi = {10.1373/49.4.624},
  url = {https://doi.org/10.1373/49.4.624},
  urldate = {2023-11-29},
  abstract = {The Logical Observation Identifier Names and Codes (LOINC®) database provides a universal code system for reporting laboratory and other clinical observations. Its purpose is to identify observations in electronic messages such as Health Level Seven (HL7) observation messages, so that when hospitals, health maintenance organizations, pharmaceutical manufacturers, researchers, and public health departments receive such messages from multiple sources, they can automatically file the results in the right slots of their medical records, research, and/or public health systems. For each observation, the database includes a code (of which 25 000 are laboratory test observations), a long formal name, a “short” 30-character name, and synonyms. The database comes with a mapping program called Regenstrief LOINC Mapping Assistant (RELMATM) to assist the mapping of local test codes to LOINC codes and to facilitate browsing of the LOINC results. Both LOINC and RELMA are available at no cost from http://www.regenstrief.org/loinc/. The LOINC medical database carries records for \&gt;30 000 different observations. LOINC codes are being used by large reference laboratories and federal agencies, e.g., the CDC and the Department of Veterans Affairs, and are part of the Health Insurance Portability and Accountability Act (HIPAA) attachment proposal. Internationally, they have been adopted in Switzerland, Hong Kong, Australia, and Canada, and by the German national standards organization, the Deutsches Instituts für Normung. Laboratories should include LOINC codes in their outbound HL7 messages so that clinical and research clients can easily integrate these results into their clinical and research repositories. Laboratories should also encourage instrument vendors to deliver LOINC codes in their instrument outputs and demand LOINC codes in HL7 messages they get from reference laboratories to avoid the need to lump so many referral tests under the “send out lab” code.},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\JB6H6ABU\\McDonald et al. - 2003 - LOINC, a Universal Standard for Identifying Labora.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\5MZC6ZIR\\5641953.html}
}

@article{mirosevicskvrceCYP2C92013,
  title = {{{CYP2C9}} and {{ABCG2}} Polymorphisms as Risk Factors for Developing Adverse Drug Reactions in Renal Transplant Patients Taking Fluvastatin: A Case-Control Study},
  shorttitle = {{{CYP2C9}} and {{ABCG2}} Polymorphisms as Risk Factors for Developing Adverse Drug Reactions in Renal Transplant Patients Taking Fluvastatin},
  author = {Miroševic Skvrce, Nikica and Božina, Nada and Zibar, Lada and Barišic, Ivan and Pejnovic, Lana and Macolic Šarinic, Viola},
  date = {2013-09},
  journaltitle = {Pharmacogenomics},
  shortjournal = {Pharmacogenomics},
  volume = {14},
  number = {12},
  eprint = {24024895},
  eprinttype = {pmid},
  pages = {1419--1431},
  issn = {1744-8042},
  doi = {10.2217/pgs.13.135},
  abstract = {AIM: To investigate whether an association exists between fluvastatin-induced adverse drug reactions (ADRs) and polymorphisms in genes encoding the metabolizing enzyme CYP2C9 and the drug transporter ABCG2 in renal transplant recipients (RTRs). MATERIALS \& METHODS: Fifty-two RTRs that experienced fluvastatin ADRs and 52 controls matched for age, gender, dose of fluvastatin and immunosuppressive use were enrolled in the study. Genotyping for CYP2C9*2, *3 and ABCG2 421C{$>$}A variants was performed by real-time PCR. RESULTS: CYP2C9 homozygous and heterozygous mutant allele (*2 or *3) carriers had 2.5-times greater odds of developing adverse effects (χ² = 4.370; degrees of freedom = 1; p = 0.037; φ = 0.21, odds ratio [OR]: 2.44; 95\% CI: 1.05-5.71). Patients who were the carriers of at least one mutant CYP2C9 allele (*2 or *3) and who were receiving CYP2C9 inhibitors, had more than six-times greater odds of having adverse effects than those without the inhibitor included in their therapy (p = 0.027; OR: 6.59; 95\% CI: 1.24-35.08). Patients with ABCG2 421CA or AA (taken together) had almost four-times greater odds of developing adverse effects than those with ABCG2 421CC genotype (χ² = 6.190; degrees of freedom = 1; p = 0.013; φ = 0.24, OR: 3.81; 95\% CI: 1.27-11.45). Patients with A allele had 2.75-times (95\% CI: 1.02-7.40) greater odds of developing adverse effects than those with C allele. CONCLUSION: Our preliminary data demonstrate an association between fluvastatin-induced ADRs in RTRs and genetic variants in the CYP2C9 and ABCG2 genes.},
  langid = {english},
  keywords = {Adult,Aryl Hydrocarbon Hydroxylases,{ATP Binding Cassette Transporter, Subfamily G, Member 2},ATP-Binding Cassette Transporters,Case-Control Studies,Cytochrome P-450 CYP2C9,Drug-Related Side Effects and Adverse Reactions,{Fatty Acids, Monounsaturated},Female,Fluvastatin,Genetic Association Studies,Humans,Indoles,Kidney Transplantation,Male,Middle Aged,Neoplasm Proteins,{Polymorphism, Single Nucleotide},Risk Factors}
}

@book{mitchellMachine1997,
  title = {Machine {{Learning}}},
  author = {Mitchell, Tom M.},
  date = {1997},
  eprint = {EoYBngEACAAJ},
  eprinttype = {googlebooks},
  publisher = {{McGraw-Hill}},
  abstract = {This book covers the field of machine learning, which is the study of algorithms that allow computer programs to automatically improve through experience. The book is intended to support upper level undergraduate and introductory level graduate courses in machine learning.},
  isbn = {978-0-07-115467-3},
  langid = {english},
  pagetotal = {414}
}

@article{mohammadDevelopment2022,
  title = {Development and Validation of an Artificial Neural Network Algorithm to Predict Mortality and Admission to Hospital for Heart Failure after Myocardial Infarction: A Nationwide Population-Based Study},
  shorttitle = {Development and Validation of an Artificial Neural Network Algorithm to Predict Mortality and Admission to Hospital for Heart Failure after Myocardial Infarction},
  author = {Mohammad, Moman A. and Olesen, Kevin K. W. and Koul, Sasha and Gale, Chris P. and Rylance, Rebecca and Jernberg, Tomas and Baron, Tomasz and Spaak, Jonas and James, Stefan and Lindahl, Bertil and Maeng, Michael and Erlinge, David},
  date = {2022-01-01},
  journaltitle = {The Lancet Digital Health},
  shortjournal = {The Lancet Digital Health},
  volume = {4},
  number = {1},
  eprint = {34952674},
  eprinttype = {pmid},
  pages = {e37-e45},
  publisher = {{Elsevier}},
  issn = {2589-7500},
  doi = {10.1016/S2589-7500(21)00228-4},
  url = {https://www.thelancet.com/journals/landig/article/PIIS2589-7500(21)00228-4/fulltext},
  urldate = {2023-11-30},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\K46JWHTL\Mohammad et al. - 2022 - Development and validation of an artificial neural.pdf}
}

@book{molnar2020interpretable,
  title = {Interpretable Machine Learning},
  author = {Molnar, Christoph},
  date = {2020},
  publisher = {{Lulu}}
}

@article{monteroDocetaxel2005,
  title = {Docetaxel for Treatment of Solid Tumours: A Systematic Review of Clinical Data},
  shorttitle = {Docetaxel for Treatment of Solid Tumours},
  author = {Montero, Alberto and Fossella, Frank and Hortobagyi, Gabriel and Valero, Vicente},
  date = {2005-04-01},
  journaltitle = {The Lancet Oncology},
  shortjournal = {The Lancet Oncology},
  volume = {6},
  number = {4},
  eprint = {15811618},
  eprinttype = {pmid},
  pages = {229--239},
  publisher = {{Elsevier}},
  issn = {1470-2045, 1474-5488},
  doi = {10.1016/S1470-2045(05)70094-2},
  url = {https://www.thelancet.com/journals/lanonc/article/PIIS1470-2045(05)70094-2/fulltext},
  urldate = {2023-12-06},
  langid = {english}
}

@book{murphyMachine2012,
  title = {Machine {{Learning}}: {{A Probabilistic Perspective}}},
  shorttitle = {Machine {{Learning}}},
  author = {Murphy, Kevin P.},
  date = {2012-09-07},
  eprint = {RC43AgAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{MIT Press}},
  abstract = {A comprehensive introduction to machine learning that uses probabilistic models and inference as a unifying approach.Today's Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach.The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package—PMTK (probabilistic modeling toolkit)—that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.},
  isbn = {978-0-262-30432-0},
  langid = {english},
  pagetotal = {1102},
  keywords = {Computers / Artificial Intelligence / General}
}

@article{musePopulationwide2023,
  title = {Population-Wide Analysis of Hospital Laboratory Tests to Assess Seasonal Variation and Temporal Reference Interval Modification},
  author = {Muse, Victorine P. and Aguayo-Orozco, Alejandro and Balaganeshan, Sedrah B. and Brunak, Søren},
  date = {2023-08-11},
  journaltitle = {Patterns},
  shortjournal = {PATTER},
  volume = {4},
  number = {8},
  publisher = {{Elsevier}},
  issn = {2666-3899},
  doi = {10.1016/j.patter.2023.100778},
  url = {https://www.cell.com/patterns/abstract/S2666-3899(23)00129-0},
  urldate = {2023-11-28},
  langid = {english},
  keywords = {DSML3: Development/pre-production: Data science output has been rolled out/validated across multiple domains/problems,health data science,hospital laboratory tests,mortality,reference intervals,seasonality},
  file = {C:\Users\sdp490\Zotero\storage\BSE9BMAI\Muse et al. - 2023 - Population-wide analysis of hospital laboratory te.pdf}
}

@article{nabelTale2012,
  title = {A {{Tale}} of {{Coronary Artery Disease}} and {{Myocardial Infarction}}},
  author = {Nabel, Elizabeth G. and Braunwald, Eugene},
  date = {2012-01-05},
  journaltitle = {New England Journal of Medicine},
  volume = {366},
  number = {1},
  eprint = {22216842},
  eprinttype = {pmid},
  pages = {54--63},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJMra1112570},
  url = {https://doi.org/10.1056/NEJMra1112570},
  urldate = {2023-10-05},
  abstract = {The remarkable facts, that the paroxysm, or indeed the disease itself, is excited more especially upon walking up hill, and after a meal; that thus excited, it is accompanied with a sensation, which threatens instant death if the motion is persisted in; and, that on stopping, the distress immediately abates, or altogether subsides; have . . . formed a constituent part of the character of Angina Pectoris.1 “Remarks on Angina Pectoris” by John Warren, M.D., appeared in 1812 as the first article in the first issue of The New England Journal of Medicine and Surgery.1 Warren's description of angina pectoris . . .},
  file = {C:\Users\sdp490\Zotero\storage\9CE8VLJN\Nabel and Braunwald - 2012 - A Tale of Coronary Artery Disease and Myocardial I.pdf}
}

@article{nakanishiMachine2021,
  title = {Machine {{Learning Adds}} to {{Clinical}} and {{CAC Assessments}} in {{Predicting}} 10-{{Year CHD}} and {{CVD Deaths}}},
  author = {Nakanishi, Rine and Slomka, Piotr J. and Rios, Richard and Betancur, Julian and Blaha, Michael J. and Nasir, Khurram and Miedema, Michael D. and Rumberger, John A. and Gransar, Heidi and Shaw, Leslee J. and Rozanski, Alan and Budoff, Matthew J. and Berman, Daniel S.},
  date = {2021-03},
  journaltitle = {JACC. Cardiovascular imaging},
  shortjournal = {JACC Cardiovasc Imaging},
  volume = {14},
  number = {3},
  eprint = {33129741},
  eprinttype = {pmid},
  pages = {615--625},
  issn = {1876-7591},
  doi = {10.1016/j.jcmg.2020.08.024},
  abstract = {OBJECTIVES: The aim of this study was to evaluate whether machine learning (ML) of noncontrast computed tomographic (CT) and clinical variables improves the prediction of atherosclerotic cardiovascular disease (ASCVD) and coronary heart disease (CHD) deaths compared with coronary artery calcium (CAC) Agatston scoring and clinical data. BACKGROUND: The CAC score provides a measure of the global burden of coronary atherosclerosis, and its long-term prognostic utility has been consistently shown to have incremental value over clinical risk assessment. However, current approaches fail to integrate all available CT and clinical variables for comprehensive risk assessment. METHODS: The study included data from 66,636 asymptomatic subjects (mean age 54 ± 11 years, 67\% men) without established ASCVD undergoing CAC scanning and followed for cardiovascular disease (CVD) and CHD deaths at 10 years. Clinical risk assessment incorporated the ASCVD risk score. For ML, an ensemble boosting approach was used to fit a predictive classifier for outcomes, followed by automated feature selection using information gain ratio. The model-building process incorporated all available clinical and CT data, including the CAC score; the number, volume, and density of CAC plaques; and extracoronary scores; comprising a total of 77 variables. The overall proposed model (ML all) was evaluated using a 10-fold cross-validation framework on the population data and area under the curve (AUC) as metrics. The prediction performance was also compared with 2 traditional scores (ASCVD risk and CAC score) and 2 additional models that were trained using all the clinical data (ML clinical) and CT variables (ML CT). RESULTS: The AUC by ML all (0.845) for predicting CVD death was superior compared with those obtained by ASCVD risk alone (0.821), CAC score alone (0.781), and ML CT alone (0.804) (p~{$<~$}0.001 for all). Similarly, for predicting CHD death, AUC by ML all (0.860) was superior to the other analyses (0.835 for ASCVD risk, 0.816 for CAC, and 0.827 for ML CT; p~{$<~$}0.001). CONCLUSIONS: The comprehensive ML model was superior to ASCVD risk, CAC score, and an ML model fitted using CT variables alone in the prediction of both CVD and CHD death.},
  langid = {english},
  pmcid = {PMC7987201},
  keywords = {Adult,Aged,Atherosclerosis,cardiovascular disease death,Cardiovascular Diseases,coronary artery calcification,Coronary Artery Disease,coronary heart disease death,Female,Humans,machine learning,Machine Learning,Male,Middle Aged,pooled cohort equation,Predictive Value of Tests},
  file = {C:\Users\sdp490\Zotero\storage\UIHBZVDF\Nakanishi et al. - 2021 - Machine Learning Adds to Clinical and CAC Assessme.pdf}
}

@article{neumann20182019,
  title = {2018 {{ESC}}/{{EACTS Guidelines}} on Myocardial Revascularization},
  author = {Neumann, Franz-Josef and Sousa-Uva, Miguel and Ahlsson, Anders and Alfonso, Fernando and Banning, Adrian P and Benedetto, Umberto and Byrne, Robert A and Collet, Jean-Philippe and Falk, Volkmar and Head, Stuart J and Jüni, Peter and Kastrati, Adnan and Koller, Akos and Kristensen, Steen D and Niebauer, Josef and Richter, Dimitrios J and Seferović, Petar M and Sibbing, Dirk and Stefanini, Giulio G and Windecker, Stephan and Yadav, Rashmi and Zembala, Michael O and {ESC Scientific Document Group}},
  date = {2019-01-07},
  journaltitle = {European Heart Journal},
  shortjournal = {European Heart Journal},
  volume = {40},
  number = {2},
  pages = {87--165},
  issn = {0195-668X},
  doi = {10.1093/eurheartj/ehy394},
  url = {https://doi.org/10.1093/eurheartj/ehy394},
  urldate = {2023-10-05},
  abstract = {The Task Force on myocardial revascularization of the European Society of Cardiology (ESC) and European Association for Cardio-Thoracic Surgery (EACTS)Developed with the special contribution of the European Association for Percutaneous Cardiovascular Interventions (EAPCI)},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\9QUPCQJG\\Neumann et al. - 2019 - 2018 ESCEACTS Guidelines on myocardial revascular.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\TXP36HZK\\5079120.html}
}

@online{nielsenLPR32018,
  title = {LPR3 går snart i luften},
  author = {Nielsen, Lisbeth},
  date = {2018-12-11},
  url = {sundhedsdatastyrelsen.dk},
  langid = {danish}
}

@article{norgeotCall2019,
  title = {A Call for Deep-Learning Healthcare},
  author = {Norgeot, Beau and Glicksberg, Benjamin S. and Butte, Atul J.},
  date = {2019-01},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {25},
  number = {1},
  pages = {14--15},
  publisher = {{Nature Publishing Group}},
  issn = {1546-170X},
  doi = {10.1038/s41591-018-0320-3},
  url = {https://www.nature.com/articles/s41591-018-0320-3},
  urldate = {2023-05-03},
  abstract = {Here we argue that now is the time to create smarter healthcare systems in which the best treatment decisions are computationally learned from electronic health record data by deep-learning methodologies.},
  issue = {1},
  langid = {english},
  keywords = {Health care,Machine learning}
}

@online{openaiGPT42023,
  title = {{{GPT-4 Technical Report}}},
  author = {OpenAI},
  date = {2023-03-27},
  eprint = {2303.08774},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2303.08774},
  url = {http://arxiv.org/abs/2303.08774},
  urldate = {2023-08-07},
  abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\R3LK7WYY\\OpenAI - 2023 - GPT-4 Technical Report.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\SJAKL688\\2303.html}
}

@online{orhanSkip2018,
  title = {Skip {{Connections Eliminate Singularities}}},
  author = {Orhan, A. Emin and Pitkow, Xaq},
  date = {2018-03-04},
  eprint = {1701.09175},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1701.09175},
  url = {http://arxiv.org/abs/1701.09175},
  urldate = {2023-12-27},
  abstract = {Skip connections made the training of very deep networks possible and have become an indispensable component in a variety of neural architectures. A completely satisfactory explanation for their success remains elusive. Here, we present a novel explanation for the benefits of skip connections in training very deep networks. The difficulty of training deep networks is partly due to the singularities caused by the non-identifiability of the model. Several such singularities have been identified in previous works: (i) overlap singularities caused by the permutation symmetry of nodes in a given layer, (ii) elimination singularities corresponding to the elimination, i.e. consistent deactivation, of nodes, (iii) singularities generated by the linear dependence of the nodes. These singularities cause degenerate manifolds in the loss landscape that slow down learning. We argue that skip connections eliminate these singularities by breaking the permutation symmetry of nodes, by reducing the possibility of node elimination and by making the nodes less linearly dependent. Moreover, for typical initializations, skip connections move the network away from the "ghosts" of these singularities and sculpt the landscape around them to alleviate the learning slow-down. These hypotheses are supported by evidence from simplified models, as well as from experiments with deep networks trained on real-world datasets.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\P9DDEEC9\\Orhan and Pitkow - 2018 - Skip Connections Eliminate Singularities.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\RM92B5UN\\1701.html}
}

@article{ozcanDanish2016,
  title = {The {{Danish Heart Registry}}},
  author = {Özcan, Cengiz and Juel, Knud and Lassen, Jens Flensted and family=Kappelgaard, given=Lene Mia, prefix=von, useprefix=false and Mortensen, Poul Erik and Gislason, Gunnar},
  date = {2016-10-25},
  journaltitle = {Clinical Epidemiology},
  shortjournal = {CLEP},
  volume = {8},
  pages = {503--508},
  publisher = {{Dove Press}},
  doi = {10.2147/CLEP.S99475},
  url = {https://www.dovepress.com/the-danish-heart-registry-peer-reviewed-fulltext-article-CLEP},
  urldate = {2023-11-28},
  abstract = {The Danish Heart Registry Cengiz \&Ouml;zcan,1,2\&nbsp;Knud Juel,1 Jens Flensted Lassen,3 Lene Mia von Kappelgaard,1 Poul Erik Mortensen,4 Gunnar Gislason1,2 1The National Institute of Public Health, University of Southern Denmark, Copenhagen K, Denmark; 2Department of Cardiology, Copenhagen University Hospital Gentofte, Hellerup, Denmark; 3Department of Cardiology, The Heart Center, Copenhagen University Hospital Rigshospitalet, Copenhagen \&Oslash;, Denmark; 4Department of Thoracic Surgery, Odense University Hospital, Odense C, Denmark  Aim: The Danish Heart Registry (DHR) seeks to monitor nationwide activity and quality of invasive diagnostic and treatment strategies in patients with ischemic heart disease as well as valvular heart disease and to provide data for research. Study population: All adult (\$15 years) patients undergoing coronary angiography (CAG), percutaneous coronary intervention (PCI), coronary artery bypass grafting, and heart valve surgery performed across all Danish hospitals were included. Main variables: The DHR contains a subset of the data stored in the Eastern and Western Denmark Heart Registries (EDHR and WDHR). For each type of procedure, up to 70 variables are registered in the DHR. Since 2010, the data quality protocol encompasses fulfillment of web-based validation rules of daily-submitted records and yearly approval of the data by the EDHR and WDHR. Descriptive data: The data collection on procedure has been complete for PCI and surgery since 2000, and for CAG as of 2006. From 2000 to 2014, the number of CAG, PCI, and surgical procedures changed by 231\%, 193\%, and 99\%, respectively. Until the end of 2014, a total of 357,476 CAG, 131,309 PCI, and 60,831 surgical procedures had been performed, corresponding to 249,445, 100,609, and 55,539 first-time patients, respectively. The DHR generally has a high level of completeness (1\&ndash;missing) of each procedure (.90\%) when compared to the National Patient Registry. Variables important for assessing the quality of care have a high level of completeness for surgery since 2000, and for CAG and PCI since 2010. Conclusion: The DHR contains valuable data on cardiac invasive procedures, which makes it an important national monitoring and quality system and at the same time serves as a platform for research projects in the cardiovascular field.Keywords: nationwide, coronary angiography, percutaneous coronary intervention, cardiac surgery},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\3U345JQX\Özcan et al. - 2016 - The Danish Heart Registry.pdf}
}

@article{paigeLandmark2018,
  title = {Landmark {{Models}} for {{Optimizing}} the {{Use}} of {{Repeated Measurements}} of {{Risk Factors}} in {{Electronic Health Records}} to {{Predict Future Disease Risk}}},
  author = {Paige, Ellie and Barrett, Jessica and Stevens, David and Keogh, Ruth H and Sweeting, Michael J and Nazareth, Irwin and Petersen, Irene and Wood, Angela M},
  date = {2018-07-01},
  journaltitle = {American Journal of Epidemiology},
  shortjournal = {American Journal of Epidemiology},
  volume = {187},
  number = {7},
  pages = {1530--1538},
  issn = {0002-9262},
  doi = {10.1093/aje/kwy018},
  url = {https://doi.org/10.1093/aje/kwy018},
  urldate = {2023-12-31},
  abstract = {The benefits of using electronic health records (EHRs) for disease risk screening and personalized health-care decisions are being increasingly recognized. Here we present a computationally feasible statistical approach with which to address the methodological challenges involved in utilizing historical repeat measures of multiple risk factors recorded in EHRs to systematically identify patients at high risk of future disease. The approach is principally based on a 2-stage dynamic landmark model. The first stage estimates current risk factor values from all available historical repeat risk factor measurements via landmark-age–specific multivariate linear mixed-effects models with correlated random intercepts, which account for sporadically recorded repeat measures, unobserved data, and measurement errors. The second stage predicts future disease risk from a sex-stratified Cox proportional hazards model, with estimated current risk factor values from the first stage. We exemplify these methods by developing and validating a dynamic 10-year cardiovascular disease risk prediction model using primary-care EHRs for age, diabetes status, hypertension treatment, smoking status, systolic blood pressure, total cholesterol, and high-density lipoprotein cholesterol in 41,373 persons from 10 primary-care practices in England and Wales contributing to The Health Improvement Network (1997–2016). Using cross-validation, the model was well-calibrated (Brier score = 0.041, 95\% confidence interval: 0.039, 0.042) and had good discrimination (C-index = 0.768, 95\% confidence interval: 0.759, 0.777).},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\AEWIXRSC\\Paige et al. - 2018 - Landmark Models for Optimizing the Use of Repeated.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\4TMZM8AQ\\4952104.html}
}

@article{pasanenSLCO1B12006,
  title = {{{SLCO1B1}} Polymorphism Markedly Affects the Pharmacokinetics of Simvastatin Acid},
  author = {Pasanen, Marja K. and Neuvonen, Mikko and Neuvonen, Pertti J. and Niemi, Mikko},
  date = {2006-12},
  journaltitle = {Pharmacogenetics and Genomics},
  shortjournal = {Pharmacogenet Genomics},
  volume = {16},
  number = {12},
  eprint = {17108811},
  eprinttype = {pmid},
  pages = {873--879},
  issn = {1744-6872},
  doi = {10.1097/01.fpc.0000230416.82349.90},
  abstract = {BACKGROUND AND OBJECTIVE: Organic anion transporting polypeptide 1B1 (OATP1B1) is an uptake transporter located at the sinusoidal membrane of human hepatocytes. This study aimed to investigate the effects of genetic polymorphism in the SLCO1B1 gene encoding OATP1B1 on the pharmacokinetics of simvastatin. METHODS: Four healthy volunteers with the homozygous SLCO1B1 c.521CC genotype, 12 with the heterozygous c.521TC genotype and 16 with the homozygous c.521TT genotype (controls) were recruited. Each study participant ingested a single 40-mg dose of simvastatin. Plasma concentrations of simvastatin (inactive lactone) and its active metabolite simvastatin acid were measured for 12 h. RESULTS: The AUC0-infinity of simvastatin acid was 120 and 221\% higher in participants with the SLCO1B1 c.521CC genotype than in those with the c.521TC and c.521TT (reference) genotypes, respectively (P{$<$}0.001). The Cmax of simvastatin acid was 162 and 200\% higher in participants with the c.521CC genotype than in those with the c.521TC and c.521TT genotypes (P{$<$}0.001). The Cmax of simvastatin acid occurred earlier in participants with the c.521CC and c.521TC genotypes than in those with the c.521TT genotype (P{$<$}0.05). No association existed between the SLCO1B1 genotype and the elimination half-life of simvastatin acid. Moreover, no statistically significant association was seen between the SLCO1B1 genotype and the pharmacokinetics of simvastatin lactone. CONCLUSIONS: SLCO1B1 polymorphism markedly affects the pharmacokinetics of active simvastatin acid, but has no significant effect on parent simvastatin. Raised plasma concentrations of simvastatin acid in patients carrying the SLCO1B1 c.521C variant allele may enhance the risk of systemic adverse effects during simvastatin treatment. In addition, reduced uptake of simvastatin acid by OATP1B1 into the liver in patients with the c.521C allele could reduce its cholesterol-lowering efficacy.},
  langid = {english},
  keywords = {Adult,Female,Genotype,Half-Life,Heterozygote,Homozygote,Humans,Hydroxymethylglutaryl-CoA Reductase Inhibitors,Liver-Specific Organic Anion Transporter 1,Male,Organic Anion Transporters,Pharmacogenetics,{Polymorphism, Single Nucleotide},Simvastatin}
}

@online{paszkePyTorch2019,
  title = {{{PyTorch}}: {{An Imperative Style}}, {{High-Performance Deep Learning Library}}},
  shorttitle = {{{PyTorch}}},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  date = {2019-12-03},
  eprint = {1912.01703},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1912.01703},
  url = {http://arxiv.org/abs/1912.01703},
  urldate = {2023-09-18},
  abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Mathematical Software,Statistics - Machine Learning},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\94R6NYUF\\Paszke et al. - 2019 - PyTorch An Imperative Style, High-Performance Dee.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\FTUANIVR\\1912.html}
}

@article{pedersenUnidirectional2023,
  title = {A Unidirectional Mapping of {{ICD-8}} to {{ICD-10}} Codes, for Harmonized Longitudinal Analysis of Diseases},
  author = {Pedersen, Mette Krogh and Eriksson, Robert and Reguant, Roc and Collin, Catherine and Pedersen, Helle Krogh and Sørup, Freja Karuna Hemmingsen and Simon, Christian and Birch, Anna Marie and Larsen, Michael and Nielsen, Anna Pors and Belling, Kirstine and Brunak, Søren},
  date = {2023-10},
  journaltitle = {European Journal of Epidemiology},
  shortjournal = {Eur J Epidemiol},
  volume = {38},
  number = {10},
  eprint = {37555907},
  eprinttype = {pmid},
  pages = {1043--1052},
  issn = {1573-7284},
  doi = {10.1007/s10654-023-01027-y},
  abstract = {Periodic revisions of the international classification of diseases (ICD) ensure that the classification reflects new practices and knowledge; however, this complicates retrospective research as diagnoses are coded in different versions. For longitudinal disease trajectory studies, a crosswalk is an essential tool and a comprehensive mapping between ICD-8 and ICD-10 has until now been lacking. In this study, we map all ICD-8 morbidity codes to ICD-10 in the expanded Danish ICD version. We mapped ICD-8 codes to ICD-10, using a many-to-one system inspired by general equivalence mappings such that each ICD-8 code maps to a single ICD-10 code. Each ICD-8 code was manually and unidirectionally mapped to a single ICD-10 code based on medical setting and context. Each match was assigned a score (1 of 4 levels) reflecting the quality of the match and, if applicable, a "flag" signalling choices made in the mapping. We provide the first complete mapping of the 8596 ICD-8 morbidity codes to ICD-10 codes. All Danish ICD-8 codes representing diseases were mapped and 5106 (59.4\%) achieved the highest consistency score. Only 334 (3.9\%) of the ICD-8 codes received the lowest mapping consistency score. The mapping provides a scaffold for translation of ICD-8 to ICD-10, which enable longitudinal disease studies back to and 1969 in Denmark and to 1965 internationally with further adaption.},
  langid = {english},
  pmcid = {PMC10570238},
  keywords = {Conversion table,Crosswalk,Data harmonization,Denmark,Diagnosis,Disease codes,ICD-10,ICD-8,International classification of diseases,Mapping},
  file = {C:\Users\sdp490\Zotero\storage\SSNPZJ2A\Pedersen et al. - 2023 - A unidirectional mapping of ICD-8 to ICD-10 codes,.pdf}
}

@article{pepeKaplan1993,
  title = {Kaplan—Meier, Marginal or Conditional Probability Curves in Summarizing Competing Risks Failure Time Data?},
  author = {Pepe, Margaret S. and Mori, Motomi},
  date = {1993},
  journaltitle = {Statistics in Medicine},
  volume = {12},
  number = {8},
  pages = {737--751},
  issn = {1097-0258},
  doi = {10.1002/sim.4780120803},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4780120803},
  urldate = {2023-11-08},
  abstract = {In the context of competing risks the Kaplan—Meier estimator is often unsuitable for summarizing failure time data. We discuss some alternative descriptive methods including marginal probability and conditional probability estimators. Two-sample test statistics are also presented.},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\EXBUEDV7\sim.html}
}

@article{popescuArrhythmic2022,
  title = {Arrhythmic Sudden Death Survival Prediction Using Deep Learning Analysis of Scarring in the Heart},
  author = {Popescu, Dan M. and Shade, Julie K. and Lai, Changxin and Aronis, Konstantinos N. and Ouyang, David and Moorthy, M. Vinayaga and Cook, Nancy R. and Lee, Daniel C. and Kadish, Alan and Albert, Christine M. and Wu, Katherine C. and Maggioni, Mauro and Trayanova, Natalia A.},
  date = {2022-04},
  journaltitle = {Nature Cardiovascular Research},
  shortjournal = {Nat Cardiovasc Res},
  volume = {1},
  number = {4},
  pages = {334--343},
  publisher = {{Nature Publishing Group}},
  issn = {2731-0590},
  doi = {10.1038/s44161-022-00041-9},
  url = {https://www.nature.com/articles/s44161-022-00041-9},
  urldate = {2023-12-08},
  abstract = {Sudden cardiac death from arrhythmia is a major cause of mortality worldwide. In this study, we developed a novel deep learning (DL) approach that blends neural networks and survival analysis to predict patient-specific survival curves from contrast-enhanced cardiac magnetic resonance images and clinical covariates for patients with ischemic heart disease. The DL-predicted survival curves offer accurate predictions at times up to 10 years and allow for estimation of uncertainty in predictions. The performance of this learning architecture was evaluated on multi-center internal validation data and tested on an independent test set, achieving concordance indexes of 0.83 and 0.74 and 10-year integrated Brier scores of 0.12 and 0.14. We demonstrate that our DL approach, with only raw cardiac images as input, outperforms standard survival models constructed using clinical covariates. This technology has the potential to transform clinical decision-making by offering accurate and generalizable predictions of patient-specific survival probabilities of arrhythmic death over time.},
  issue = {4},
  langid = {english},
  keywords = {Disease-free survival,Medical imaging,Ventricular tachycardia},
  file = {C:\Users\sdp490\Zotero\storage\HGSMKTB9\Popescu et al. - 2022 - Arrhythmic sudden death survival prediction using .pdf}
}

@online{pressCleaning,
  title = {Cleaning {{Big Data}}: {{Most Time-Consuming}}, {{Least Enjoyable Data Science Task}}, {{Survey Says}}},
  shorttitle = {Cleaning {{Big Data}}},
  author = {Press, Gil},
  url = {https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/},
  urldate = {2023-12-30},
  abstract = {A new survey of data scientists found that they spend most of their time massaging rather than mining or modeling data.},
  langid = {english},
  organization = {{Forbes}},
  file = {C:\Users\sdp490\Zotero\storage\C6KHRZBU\data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says.html}
}

@book{prince2023understanding,
  title = {Understanding Deep Learning},
  author = {Prince, Simon J.D.},
  date = {2023},
  publisher = {{MIT Press}},
  url = {http://udlbook.com}
}

@online{rameshZeroShot2021,
  title = {Zero-{{Shot Text-to-Image Generation}}},
  author = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  date = {2021-02-26},
  eprint = {2102.12092},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2102.12092},
  urldate = {2023-10-24},
  abstract = {Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufficient data and scale, our approach is competitive with previous domain-specific models when evaluated in a zero-shot fashion.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\TKE2HLQJ\\Ramesh et al. - 2021 - Zero-Shot Text-to-Image Generation.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\7WDDMVVV\\2102.html}
}

@article{raoSurvival2007,
  title = {Survival {{Methods}}},
  author = {Rao, Sowmya R. and Schoenfeld, David A.},
  date = {2007-01-02},
  journaltitle = {Circulation},
  volume = {115},
  number = {1},
  pages = {109--113},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIRCULATIONAHA.106.614859},
  url = {https://www.ahajournals.org/doi/full/10.1161/CIRCULATIONAHA.106.614859},
  urldate = {2023-11-08},
  keywords = {Kaplan-Meiers estimate,proportional hazards models,survival},
  file = {C:\Users\sdp490\Zotero\storage\BYQ67FTC\Rao and Schoenfeld - 2007 - Survival Methods.pdf}
}

@article{rapsomanikiPrognostic2014,
  title = {Prognostic Models for Stable Coronary Artery Disease Based on Electronic Health Record Cohort of 102 023 Patients},
  author = {Rapsomaniki, Eleni and Shah, Anoop and Perel, Pablo and Denaxas, Spiros and George, Julie and Nicholas, Owen and Udumyan, Ruzan and Feder, Gene Solomon and Hingorani, Aroon D. and Timmis, Adam and Smeeth, Liam and Hemingway, Harry},
  date = {2014-04-01},
  journaltitle = {European Heart Journal},
  shortjournal = {European Heart Journal},
  volume = {35},
  number = {13},
  pages = {844--852},
  issn = {0195-668X},
  doi = {10.1093/eurheartj/eht533},
  url = {https://doi.org/10.1093/eurheartj/eht533},
  urldate = {2023-10-09},
  abstract = {The population with stable coronary artery disease (SCAD) is growing but validated models to guide their clinical management are lacking. We developed and validated prognostic models for all-cause mortality and non-fatal myocardial infarction (MI) or coronary death in SCAD.Models were developed in a linked electronic health records cohort of 102 023 SCAD patients from the CALIBER programme, with mean follow-up of 4.4 (SD 2.8) years during which 20 817 deaths and 8856 coronary outcomes were observed. The Kaplan–Meier 5-year risk was 20.6\% (95\% CI, 20.3, 20.9) for mortality and 9.7\% (95\% CI, 9.4, 9.9) for non-fatal MI or coronary death. The predictors in the models were age, sex, CAD diagnosis, deprivation, smoking, hypertension, diabetes, lipids, heart failure, peripheral arterial disease, atrial fibrillation, stroke, chronic kidney disease, chronic pulmonary disease, liver disease, cancer, depression, anxiety, heart rate, creatinine, white cell count, and haemoglobin. The models had good calibration and discrimination in internal (external) validation with C-index 0.811 (0.735) for all-cause mortality and 0.778 (0.718) for non-fatal MI or coronary death. Using these models to identify patients at high risk (defined by guidelines as 3\% annual mortality) and support a management decision associated with hazard ratio 0.8 could save an additional 13–16 life years or 15–18 coronary event-free years per 1000 patients screened, compared with models with just age, sex, and deprivation.These validated prognostic models could be used in clinical practice to support risk stratification as recommended in clinical guidelines.},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\SIHPWXWZ\\Rapsomaniki et al. - 2014 - Prognostic models for stable coronary artery disea.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\5YX6T3PT\\633759.html}
}

@inreference{Regular2023,
  title = {Regular Expression},
  booktitle = {Wikipedia},
  date = {2023-11-24T12:48:01Z},
  url = {https://en.wikipedia.org/w/index.php?title=Regular_expression&oldid=1186625751},
  urldate = {2023-11-29},
  abstract = {A regular expression (shortened as regex or regexp), sometimes referred to as rational expression, is a sequence of characters that specifies a match pattern in text. Usually such patterns are used by string-searching algorithms for "find" or "find and replace" operations on strings, or for input validation. Regular expression techniques are developed in theoretical computer science and formal language theory. The concept of regular expressions began in the 1950s, when the American mathematician Stephen Cole Kleene formalized the concept of a regular language. They came into common use with Unix text-processing utilities. Different syntaxes for writing regular expressions have existed since the 1980s, one being the POSIX standard and another, widely used, being the Perl syntax. Regular expressions are used in search engines, in search and replace dialogs of word processors and text editors, in text processing utilities such as sed and AWK, and in lexical analysis. Regular expressions are supported in many programming languages.},
  langid = {english},
  annotation = {Page Version ID: 1186625751},
  file = {C:\Users\sdp490\Zotero\storage\JBPWRRS5\Regular_expression.html}
}

@article{richKnowledge2016,
  title = {Knowledge {{Gaps}} in {{Cardiovascular Care}} of the {{Older Adult Population}}},
  author = {Rich, Michael W. and Chyun, Deborah A. and Skolnick, Adam H. and Alexander, Karen P. and Forman, Daniel E. and Kitzman, Dalane W. and Maurer, Mathew S. and McClurken, James B. and Resnick, Barbara M. and Shen, Win K. and Tirschwell, David L.},
  date = {2016-05-24},
  journaltitle = {Circulation},
  volume = {133},
  number = {21},
  pages = {2103--2122},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIR.0000000000000380},
  url = {https://www.ahajournals.org/doi/full/10.1161/CIR.0000000000000380},
  urldate = {2023-11-30},
  abstract = {The incidence and prevalence of most cardiovascular disorders increase with age, and cardiovascular disease is the leading cause of death and major disability in adults ≥75 years of age; however, despite the large impact of cardiovascular disease on quality of life, morbidity, and mortality in older adults, patients aged ≥75 years have been markedly underrepresented in most major cardiovascular trials, and virtually all trials have excluded older patients with complex comorbidities, significant physical or cognitive disabilities, frailty, or residence in a nursing home or assisted living facility. As a result, current guidelines are unable to provide evidence-based recommendations for diagnosis and treatment of older patients typical of those encountered in routine clinical practice. The objectives of this scientific statement are to summarize current guideline recommendations as they apply to older adults, identify critical gaps in knowledge that preclude informed evidence-based decision making, and recommend future research to close existing knowledge gaps. To achieve these objectives, we conducted a detailed review of current American College of Cardiology/American Heart Association and American Stroke Association guidelines to identify content and recommendations that explicitly targeted older patients. We found that there is a pervasive lack of evidence to guide clinical decision making in older patients with cardiovascular disease, as well as a paucity of data on the impact of diagnostic and therapeutic interventions on key outcomes that are particularly important to older patients, such as quality of life, physical function, and maintenance of independence. Accordingly, there is a critical need for a multitude of large population-based studies and clinical trials that include a broad spectrum of older patients representative of those seen in clinical practice and that incorporate relevant outcomes important to older patients in the study design. The results of these studies will provide the foundation for future evidence-based guidelines applicable to older patients, thereby enhancing patient-centered evidence-based care of older people with cardiovascular disease in the United States and around the world.},
  keywords = {AHA Scientific Statements,elderly,heart failure,heart rhythm disorders,non-cardiac surgery,stroke,valvular heart disease},
  file = {C:\Users\sdp490\Zotero\storage\QJT3H4YH\Rich et al. - 2016 - Knowledge Gaps in Cardiovascular Care of the Older.pdf}
}

@article{riekeFuture2020,
  title = {The Future of Digital Health with Federated Learning},
  author = {Rieke, Nicola and Hancox, Jonny and Li, Wenqi and Milletarì, Fausto and Roth, Holger R. and Albarqouni, Shadi and Bakas, Spyridon and Galtier, Mathieu N. and Landman, Bennett A. and Maier-Hein, Klaus and Ourselin, Sébastien and Sheller, Micah and Summers, Ronald M. and Trask, Andrew and Xu, Daguang and Baust, Maximilian and Cardoso, M. Jorge},
  date = {2020-09-14},
  journaltitle = {npj Digital Medicine},
  shortjournal = {npj Digit. Med.},
  volume = {3},
  number = {1},
  pages = {1--7},
  publisher = {{Nature Publishing Group}},
  issn = {2398-6352},
  doi = {10.1038/s41746-020-00323-1},
  url = {https://www.nature.com/articles/s41746-020-00323-1},
  urldate = {2023-05-11},
  abstract = {Data-driven machine learning (ML) has emerged as a promising approach for building accurate and robust statistical models from medical data, which is collected in huge volumes by modern healthcare systems. Existing medical data is not fully exploited by ML primarily because it sits in data silos and privacy concerns restrict access to this data. However, without access to sufficient data, ML will be prevented from reaching its full potential and, ultimately, from making the transition from research to clinical practice. This paper considers key factors contributing to this issue, explores how federated learning (FL) may provide a solution for the future of digital health and highlights the challenges and considerations that need to be addressed.},
  issue = {1},
  langid = {english},
  keywords = {Medical imaging,Medical research},
  file = {C:\Users\sdp490\Zotero\storage\7BQBVCWE\Rieke et al. - 2020 - The future of digital health with federated learni.pdf}
}

@article{roccaPrevalence2014,
  title = {Prevalence of {{Multimorbidity}} in a {{Geographically Defined American Population}}: {{Patterns}} by {{Age}}, {{Sex}}, and {{Race}}/{{Ethnicity}}},
  shorttitle = {Prevalence of {{Multimorbidity}} in a {{Geographically Defined American Population}}},
  author = {Rocca, Walter A. and Boyd, Cynthia M. and Grossardt, Brandon R. and Bobo, William V. and Finney Rutten, Lila J. and Roger, Véronique L. and Ebbert, Jon O. and Therneau, Terry M. and Yawn, Barbara P. and St. Sauver, Jennifer L.},
  date = {2014-10-01},
  journaltitle = {Mayo Clinic Proceedings},
  shortjournal = {Mayo Clinic Proceedings},
  volume = {89},
  number = {10},
  pages = {1336--1349},
  issn = {0025-6196},
  doi = {10.1016/j.mayocp.2014.07.010},
  url = {https://www.sciencedirect.com/science/article/pii/S002561961400665X},
  urldate = {2023-12-02},
  abstract = {Objective To describe the prevalence of multimorbidity involving 20 selected chronic conditions in a geographically defined US population, emphasizing age, sex, and racial/ethnic differences. Patients and Methods Using the Rochester Epidemiology Project records linkage system, we identified all residents of Olmsted County, Minnesota, on April 1, 2010, and electronically extracted the International Classification of Diseases, Ninth Revision codes associated with all health care visits made between April 1, 2005, and March 31, 2010 (5-year capture frame). Using these codes, we defined the 20 common chronic conditions recommended by the US Department of Health and Human Services. We counted only persons who received at least 2 codes for a given condition separated by more than 30 days, and we calculated the age-, sex-, and race/ethnicity-specific prevalence of multimorbidity. Results Of the 138,858 study participants, 52.4\% were women (n=72,732) and 38.9\% had 1 or more conditions (n=54,012), 22.6\% had 2 or more conditions (n=31,444), and 4.9\% had 5 or more conditions (n=6853). The prevalence of multimorbidity (≥2 conditions) increased steeply with older age and reached 77.3\% at 65 years and older. However, the absolute number of people affected by multimorbidity was higher in those younger than 65 years. Although the prevalence of multimorbidity was similar in men and women overall, the most common dyads and triads of conditions varied by sex. Compared with white persons, the prevalence of multimorbidity was slightly higher in black persons and slightly lower in Asian persons. Conclusion Multimorbidity is common in the general population; it increases steeply with older age, has different patterns in men and women, and varies by race/ethnicity.},
  file = {C:\Users\sdp490\Zotero\storage\VRKNNX99\S002561961400665X.html}
}

@article{rodriguezDrug2023,
  title = {Drug Dosage Modifications in 24 Million In-Patient Prescriptions Covering Eight Years: {{A Danish}} Population-Wide Study of Polypharmacy},
  shorttitle = {Drug Dosage Modifications in 24 Million In-Patient Prescriptions Covering Eight Years},
  author = {Rodríguez, Cristina Leal and Haue, Amalie Dahl and Mazzoni, Gianluca and Eriksson, Robert and Biel, Jorge Hernansanz and Cantwell, Lisa and Westergaard, David and Belling, Kirstine G. and Brunak, Søren},
  date = {2023-09-07},
  journaltitle = {PLOS Digital Health},
  shortjournal = {PLOS Digital Health},
  volume = {2},
  number = {9},
  pages = {e0000336},
  publisher = {{Public Library of Science}},
  issn = {2767-3170},
  doi = {10.1371/journal.pdig.0000336},
  url = {https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000336},
  urldate = {2023-11-28},
  abstract = {Polypharmacy has generally been assessed by raw counts of different drugs administered concomitantly to the same patients; not with respect to the likelihood of dosage-adjustments. To address this aspect of polypharmacy, the objective of the present study was to identify co-medications associated with more frequent dosage adjustments. The data foundation was electronic health records from 3.2 million inpatient admissions at Danish hospitals (2008–2016). The likelihood of dosage-adjustments when two drugs were administered concomitantly were computed using Bayesian logistic regressions. We identified 3,993 co-medication pairs that associate significantly with dosage changes when administered together. Of these pairs, 2,412 (60\%) did associate with readmission, mortality or longer stays, while 308 (8\%) associated with reduced kidney function. In comparison to co-medications pairs that were previously classified as drug-drug interactions, pairs not classified as drug-drug interactions had higher odds ratios of dosage modifications than drug pairs with an established interaction. Drug pairs not corresponding to known drug-drug interactions while still being associated significantly with dosage changes were prescribed to fewer patients and mentioned more rarely together in the literature. We hypothesize that some of these pairs could be associated with yet to be discovered interactions as they may be harder to identify in smaller-scale studies.},
  langid = {english},
  keywords = {ACE inhibitor therapy,Antibiotics,Blood,Cardiovascular therapy,Drug administration,Drug metabolism,Drug therapy,Drug-drug interactions},
  file = {C:\Users\sdp490\Zotero\storage\PUJ72E6I\Rodríguez et al. - 2023 - Drug dosage modifications in 24 million in-patient.pdf}
}

@book{russellArtificial2009,
  title = {Artificial {{Intelligence}}: {{A Modern Approach}}},
  shorttitle = {Artificial {{Intelligence}}},
  author = {Russell, Stuart and Norvig, Peter},
  date = {2009-12-01},
  edition = {3rd edition},
  publisher = {{Pearson}},
  location = {{Upper Saddle River}},
  abstract = {Artificial Intelligence: A Modern Approach, 3e offers the most comprehensive, up-to-date introduction to the theory and practice of artificial intelligence. Number one in its field, this textbook is ideal for one or two-semester, undergraduate or graduate-level courses in Artificial Intelligence.Dr. Peter Norvig, contributing Artificial Intelligence author and Professor Sebastian Thrun, a Pearson author are offering a free online course at Stanford University on artificial intelligence. According to an article in The New York Times, the course on artificial intelligence is “one of three being offered experimentally by the Stanford computer science department to extend technology knowledge and skills beyond this elite campus to the entire world.” One of the other two courses, an introduction to database software, is being taught by Pearson author Dr. Jennifer Widom.Artificial Intelligence: A Modern Approach, 3e is available to purchase as an eText for your KindleTM, NOOKTM, and the iPhone®/iPad®. To learn more about the course on artificial intelligence, visit http://www.ai-class.com. To read the full New York Times article, click here.},
  isbn = {978-0-13-604259-4},
  langid = {english},
  pagetotal = {1152}
}

@article{saltonVector1975,
  title = {A Vector Space Model for Automatic Indexing},
  author = {Salton, G. and Wong, A. and Yang, C. S.},
  date = {1975-11-01},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {18},
  number = {11},
  pages = {613--620},
  issn = {0001-0782},
  doi = {10.1145/361219.361220},
  url = {https://dl.acm.org/doi/10.1145/361219.361220},
  urldate = {2023-12-03},
  abstract = {In a document retrieval, or other pattern matching environment where stored entities (documents) are compared with each other or with incoming patterns (search requests), it appears that the best indexing (property) space is one where each entity lies as far away from the others as possible; in these circumstances the value of an indexing system may be expressible as a function of the density of the object space; in particular, retrieval performance may correlate inversely with space density. An approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents. Typical evaluation results are shown, demonstating the usefulness of the model.},
  keywords = {automatic indexing,automatic information retrieval,content analysis,document space},
  file = {C:\Users\sdp490\Zotero\storage\CXZBLZZL\Salton et al. - 1975 - A vector space model for automatic indexing.pdf}
}

@article{savcisensUsing2023,
  title = {Using Sequences of Life-Events to Predict Human Lives},
  author = {Savcisens, Germans and Eliassi-Rad, Tina and Hansen, Lars Kai and Mortensen, Laust Hvas and Lilleholt, Lau and Rogers, Anna and Zettler, Ingo and Lehmann, Sune},
  date = {2023-12-18},
  journaltitle = {Nature Computational Science},
  shortjournal = {Nat Comput Sci},
  pages = {1--14},
  publisher = {{Nature Publishing Group}},
  issn = {2662-8457},
  doi = {10.1038/s43588-023-00573-5},
  url = {https://www.nature.com/articles/s43588-023-00573-5},
  urldate = {2023-12-31},
  abstract = {Here we represent human lives in a way that shares structural similarity to language, and we exploit this similarity to adapt natural language processing techniques to examine the evolution and predictability of human lives based on detailed event sequences. We do this by drawing on a comprehensive registry dataset, which is available for Denmark across several years, and that includes information about life-events related to health, education, occupation, income, address and working hours, recorded with day-to-day resolution. We create embeddings of life-events in a single vector space, showing that this embedding space is robust and highly structured. Our models allow us to predict diverse outcomes ranging from early mortality to personality nuances, outperforming state-of-the-art models by a wide margin. Using methods for interpreting deep learning models, we probe the algorithm to understand the factors that enable our predictions. Our framework allows researchers to discover potential mechanisms that impact life outcomes as well as the associated possibilities for personalized interventions.},
  langid = {english},
  keywords = {Computational science,Society},
  file = {C:\Users\sdp490\Zotero\storage\A4M7E9SV\Savcisens et al. - 2023 - Using sequences of life-events to predict human li.pdf}
}

@article{schmidtDanish2014,
  title = {The {{Danish Civil Registration System}} as a Tool in Epidemiology},
  author = {Schmidt, Morten and Pedersen, Lars and Sørensen, Henrik Toft},
  date = {2014-08-01},
  journaltitle = {European Journal of Epidemiology},
  shortjournal = {Eur J Epidemiol},
  volume = {29},
  number = {8},
  pages = {541--549},
  issn = {1573-7284},
  doi = {10.1007/s10654-014-9930-3},
  url = {https://doi.org/10.1007/s10654-014-9930-3},
  urldate = {2023-08-02},
  abstract = {The methodological advances in epidemiology have facilitated the use of the Danish Civil Registration System (CRS) in ways not previously described systematically. We reviewed the CRS and its use as a research tool in epidemiology. We obtained information from the Danish Law on Civil Registration and the Central Office of Civil Registration, and used existing literature to provide illustrative examples of its use. The CRS is an administrative register established on April 2, 1968. It contains individual-level information on all persons residing in Denmark (and Greenland as of May 1, 1972). By January 2014, the CRS had cumulatively registered 9.5 million individuals and more than 400 million person-years of follow-up. A unique ten-digit Civil Personal Register number assigned to all persons in the CRS allows for technically easy, cost-effective, and unambiguous individual-level record linkage of Danish registers. Daily updated information on migration and vital status allows for nationwide cohort studies with virtually complete long-term follow-up on emigration and death. The CRS facilitates sampling of general population comparison cohorts, controls in case–control studies, family cohorts, and target groups in population surveys. The data in the CRS are virtually complete, have high accuracy, and can be retrieved for research purposes while protecting the anonymity of Danish residents. In conclusion, the CRS is a key tool for epidemiological research in Denmark.},
  langid = {english},
  keywords = {Data linkage,Database,Epidemiological methods,Epidemiology,Follow-up,Registers},
  file = {C:\Users\sdp490\Zotero\storage\5D2DT99A\Schmidt et al. - 2014 - The Danish Civil Registration System as a tool in .pdf}
}

@article{schmidtDanish2015,
  title = {The {{Danish National Patient Registry}}: A Review of Content, Data Quality, and Research Potential},
  shorttitle = {The {{Danish National Patient Registry}}},
  author = {Schmidt, Morten and Schmidt, Sigrun Alba Johannesdottir and Sandegaard, Jakob Lynge and Ehrenstein, Vera and Pedersen, Lars and Sørensen, Henrik Toft},
  date = {2015-11-17},
  journaltitle = {Clinical Epidemiology},
  shortjournal = {Clin Epidemiol},
  volume = {7},
  eprint = {26604824},
  eprinttype = {pmid},
  pages = {449--490},
  issn = {1179-1349},
  doi = {10.2147/CLEP.S91125},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4655913/},
  urldate = {2023-11-24},
  abstract = {Background The Danish National Patient Registry (DNPR) is one of the world’s oldest nationwide hospital registries and is used extensively for research. Many studies have validated algorithms for identifying health events in the DNPR, but the reports are fragmented and no overview exists. Objectives To review the content, data quality, and research potential of the DNPR. Methods We examined the setting, history, aims, content, and classification systems of the DNPR. We searched PubMed and the Danish Medical Journal to create a bibliography of validation studies. We included also studies that were referenced in retrieved papers or known to us beforehand. Methodological considerations related to DNPR data were reviewed. Results During 1977–2012, the DNPR registered 8,085,603 persons, accounting for 7,268,857 inpatient, 5,953,405 outpatient, and 5,097,300 emergency department contacts. The DNPR provides nationwide longitudinal registration of detailed administrative and clinical data. It has recorded information on all patients discharged from Danish nonpsychiatric hospitals since 1977 and on psychiatric inpatients and emergency department and outpatient specialty clinic contacts since 1995. For each patient contact, one primary and optional secondary diagnoses are recorded according to the International Classification of Diseases. The DNPR provides a data source to identify diseases, examinations, certain in-hospital medical treatments, and surgical procedures. Long-term temporal trends in hospitalization and treatment rates can be studied. The positive predictive values of diseases and treatments vary widely ({$<$}15\%–100\%). The DNPR data are linkable at the patient level with data from other Danish administrative registries, clinical registries, randomized controlled trials, population surveys, and epidemiologic field studies – enabling researchers to reconstruct individual life and health trajectories for an entire population. Conclusion The DNPR is a valuable tool for epidemiological research. However, both its strengths and limitations must be considered when interpreting research results, and continuous validation of its clinical data is essential.},
  pmcid = {PMC4655913},
  file = {C:\Users\sdp490\Zotero\storage\RZPCWP2J\Schmidt et al. - 2015 - The Danish National Patient Registry a review of .pdf}
}

@article{schmidtDanish2019,
  title = {The {{Danish}} Health Care System and Epidemiological Research: From Health Care Contacts to Database Records},
  shorttitle = {{$<$}p{$>$}{{The Danish}} Health Care System and Epidemiological Research},
  author = {Schmidt, Morten and Schmidt, Sigrun Alba Johannesdottir and Adelborg, Kasper and Sundbøll, Jens and Laugesen, Kristina and Ehrenstein, Vera and Sørensen, Henrik Toft},
  date = {2019-07-12},
  journaltitle = {Clinical Epidemiology},
  shortjournal = {CLEP},
  volume = {11},
  pages = {563--591},
  publisher = {{Dove Press}},
  doi = {10.2147/CLEP.S179083},
  url = {https://www.dovepress.com/the-danish-health-care-system-and-epidemiological-research-from-health-peer-reviewed-fulltext-article-CLEP},
  urldate = {2023-11-25},
  abstract = {The Danish health care system and epidemiological research: from health care contacts to database records},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\2UCG7AYL\Schmidt et al. - 2019 - The Danish health care system and epidemiologic.pdf}
}

@article{searchcollaborativegroupSLCO1B12008,
  title = {{{SLCO1B1}} Variants and Statin-Induced Myopathy--a Genomewide Study},
  author = {{SEARCH Collaborative Group} and Link, E. and Parish, S. and Armitage, J. and Bowman, L. and Heath, S. and Matsuda, F. and Gut, I. and Lathrop, M. and Collins, R.},
  date = {2008-08-21},
  journaltitle = {The New England Journal of Medicine},
  shortjournal = {N Engl J Med},
  volume = {359},
  number = {8},
  eprint = {18650507},
  eprinttype = {pmid},
  pages = {789--799},
  issn = {1533-4406},
  doi = {10.1056/NEJMoa0801936},
  abstract = {BACKGROUND: Lowering low-density lipoprotein cholesterol with statin therapy results in substantial reductions in cardiovascular events, and larger reductions in cholesterol may produce larger benefits. In rare cases, myopathy occurs in association with statin therapy, especially when the statins are administered at higher doses and with certain other medications. METHODS: We carried out a genomewide association study using approximately 300,000 markers (and additional fine-mapping) in 85 subjects with definite or incipient myopathy and 90 controls, all of whom were taking 80 mg of simvastatin daily as part of a trial involving 12,000 participants. Replication was tested in a trial of 40 mg of simvastatin daily involving 20,000 participants. RESULTS: The genomewide scan yielded a single strong association of myopathy with the rs4363657 single-nucleotide polymorphism (SNP) located within SLCO1B1 on chromosome 12 (P=4x10(-9)). SLCO1B1 encodes the organic anion-transporting polypeptide OATP1B1, which has been shown to regulate the hepatic uptake of statins. The noncoding rs4363657 SNP was in nearly complete linkage disequilibrium with the nonsynonymous rs4149056 SNP (r(2)=0.97), which has been linked to statin metabolism. The prevalence of the rs4149056 C allele in the population was 15\%. The odds ratio for myopathy was 4.5 (95\% confidence interval [CI], 2.6 to 7.7) per copy of the C allele, and 16.9 (95\% CI, 4.7 to 61.1) in CC as compared with TT homozygotes. More than 60\% of these myopathy cases could be attributed to the C variant. The association of rs4149056 with myopathy was replicated in the trial of 40 mg of simvastatin daily, which also showed an association between rs4149056 and the cholesterol-lowering effects of simvastatin. No SNPs in any other region were clearly associated with myopathy. CONCLUSIONS: We have identified common variants in SLCO1B1 that are strongly associated with an increased risk of statin-induced myopathy. Genotyping these variants may help to achieve the benefits of statin therapy more safely and effectively. (Current Controlled Trials number, ISRCTN74348595.)},
  langid = {english},
  keywords = {Aged,Arterial Occlusive Diseases,{Chromosomes, Human, Pair 12},Diabetes Mellitus,Female,Genetic Markers,Genotype,Humans,Hydroxymethylglutaryl-CoA Reductase Inhibitors,Liver-Specific Organic Anion Transporter 1,Male,Middle Aged,Muscular Diseases,Myocardial Infarction,Organic Anion Transporters,{Polymorphism, Single Nucleotide},Risk,Simvastatin},
  file = {C:\Users\sdp490\Zotero\storage\LR5YC8DP\SEARCH Collaborative Group et al. - 2008 - SLCO1B1 variants and statin-induced myopathy--a ge.pdf}
}

@book{seifterConcepts2005,
  title = {Concepts in {{Medical Physiology}}},
  author = {Seifter, Julian and Sloane, David and Ratner, Austin},
  date = {2005},
  eprint = {A8H_9S4E0I4C},
  eprinttype = {googlebooks},
  publisher = {{Lippincott Williams \& Wilkins}},
  abstract = {Written through a collaboration of expert faculty and medical students from Harvard Medical School, this innovative text delivers a straightforward and clear overview of the major principles, agents, and processes governing human physiology. Emphasis is on understanding the higher-order processes in each organ system. Concepts in Medical Physiology avoids long lists of unprioritized information and undefined jargon by presenting fresh concept diagrams and figures alongside clear explanations of quantitative concepts. It can function equally well as a primary resource or as a review. Eight major sections, comprising a total of 36 chapters, cover general principles, muscle and bone, blood and the immune system, cardiovascular physiology, pulmonary physiology, renal physiology, gastrointestinal physiology, and endocrine physiology. Many useful features simplify mastery of difficult concepts:  Case studies for each major section present detailed cases with signs and symptoms, history, and laboratory data. Questions at the conclusion of each case reinforce important clinical concepts. Reviews of cell biology, basic science, and biochemistry refresh students on the foundations of physiological knowledge. Clinical Application boxes draw the connection between physiology to practical issues students face and help with preparation for the USMLE. Pathophysiology sections are featured in every chapter. Review questions with answers in each chapter aid in preparation for the examination. Integrative Physiology inserts highlight how specific systems, organs, and tissues work together. More than 350 illustrations aid with visual learning, including original schematic diagrams, photos, and tables. Concept-focused summaries conclude each chapter for more effective learning and review. Suggested readings in every chapter provide a valuable resource for further investigation in physiological and clinical ideas.},
  isbn = {978-0-7817-4489-8},
  langid = {english},
  pagetotal = {694},
  keywords = {Medical / Physiology}
}

@article{shapley1953value,
  title = {A Value for N-Person Games},
  author = {Shapley, Lloyd S},
  date = {1953},
  publisher = {{Princeton University Press Princeton}}
}

@online{smithSuperConvergence2018a,
  title = {Super-{{Convergence}}: {{Very Fast Training}} of {{Neural Networks Using Large Learning Rates}}},
  shorttitle = {Super-{{Convergence}}},
  author = {Smith, Leslie N. and Topin, Nicholay},
  date = {2018-05-17},
  eprint = {1708.07120},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1708.07120},
  url = {http://arxiv.org/abs/1708.07120},
  urldate = {2023-12-27},
  abstract = {In this paper, we describe a phenomenon, which we named "super-convergence", where neural networks can be trained an order of magnitude faster than with standard training methods. The existence of super-convergence is relevant to understanding why deep networks generalize well. One of the key elements of super-convergence is training with one learning rate cycle and a large maximum learning rate. A primary insight that allows super-convergence training is that large learning rates regularize the training, hence requiring a reduction of all other forms of regularization in order to preserve an optimal regularization balance. We also derive a simplification of the Hessian Free optimization method to compute an estimate of the optimal learning rate. Experiments demonstrate super-convergence for Cifar-10/100, MNIST and Imagenet datasets, and resnet, wide-resnet, densenet, and inception architectures. In addition, we show that super-convergence provides a greater boost in performance relative to standard training when the amount of labeled training data is limited. The architectures and code to replicate the figures in this paper are available at github.com/lnsmith54/super-convergence. See http://www.fast.ai/2018/04/30/dawnbench-fastai/ for an application of super-convergence to win the DAWNBench challenge (see https://dawn.cs.stanford.edu/benchmark/).},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\Y8T6DGQW\\Smith and Topin - 2018 - Super-Convergence Very Fast Training of Neural Ne.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\P7T2AEGG\\1708.html}
}

@article{sorupSex2020,
  title = {Sex Differences in Text-Mined Possible Adverse Drug Events Associated with Drugs for Psychosis},
  author = {Sørup, Freja Karuna Hemmingsen and Eriksson, Robert and Westergaard, David and Hallas, Jesper and Brunak, Søren and Ejdrup Andersen, Stig},
  date = {2020-05-01},
  journaltitle = {Journal of Psychopharmacology},
  shortjournal = {J Psychopharmacol},
  volume = {34},
  number = {5},
  pages = {532--539},
  publisher = {{SAGE Publications Ltd STM}},
  issn = {0269-8811},
  doi = {10.1177/0269881120903466},
  url = {https://doi.org/10.1177/0269881120903466},
  urldate = {2023-11-28},
  abstract = {Background: Understanding sex differences in adverse drug reactions to drugs for psychosis could potentially guide clinicians in optimal drug choices. Aims: By applying a text-mining approach, this study aimed to investigate the relationship between drugs for psychosis and biological sex differences in frequencies and co-occurrences of potential adverse drug events (ADEs). Methods: Electronic patient records of a psychiatric population (1427 men and 727 women) were text mined for potential ADEs. The relative risk of experiencing specific ADEs and co-occurrence of ADEs were calculated for each sex. Results: Findings included 55 potential ADEs with significantly different frequencies between the two sexes. Of these, 20 were more frequent in men, with relative risks of 1.10–7.64, and 35 were more frequent in women, with relative risks of 1.19–21.58. Frequent potential ADEs were psychiatric symptoms, including sexual dysfunction and disturbances in men, and gastrointestinal symptoms, suicidal and self-injurious behaviour and hyperprolactinemia-related events in women. Mention of different hyperprolactinemia-related ADEs often co-occurred in female patients but not in male patients. Conclusion: Several known sex-related ADEs were identified, as well as some previously not reported. When considering the risk–benefit profile of drugs for psychosis, the patient’s sex should be considered.},
  langid = {english}
}

@article{srivastava2014dropout,
  title = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  date = {2014},
  journaltitle = {The journal of machine learning research},
  volume = {15},
  number = {1},
  pages = {1929--1958},
  publisher = {{JMLR. org}}
}

@article{stegESC2012,
  title = {{{ESC Guidelines}} for the Management of Acute Myocardial Infarction in Patients Presenting with {{ST-segment}} Elevation},
  author = {Steg, Ph. Gabriel and James, Stefan K. and Atar, Dan and Badano, Luigi P. and Lundqvist, Carina Blomstrom and Borger, Michael A. and Di Mario, Carlo and Dickstein, Kenneth and Ducrocq, Gregory and Fernandez-Aviles, Francisco and Gershlick, Anthony H. and Giannuzzi, Pantaleo and Halvorsen, Sigrun and Huber, Kurt and Juni, Peter and Kastrati, Adnan and Knuuti, Juhani and Lenzen, Mattie J. and Mahaffey, Kenneth W. and Valgimigli, Marco and family=Hof, given=Arnoud, prefix=van't, useprefix=true and Widimsky, Petr and Zahger, Doron and Bax, Jeroen J. and Baumgartner, Helmut and Ceconi, Claudio and Dean, Veronica and Deaton, Christi and Fagard, Robert and Funck-Brentano, Christian and Hasdai, David and Hoes, Arno and Kirchhof, Paulus and Knuuti, Juhani and Kolh, Philippe and McDonagh, Theresa and Moulin, Cyril and Popescu, Bogdan A. and Reiner, Željko and Sechtem, Udo and Sirnes, Per Anton and Tendera, Michal and Torbicki, Adam and Vahanian, Alec and Windecker, Stephan and Hasdai, David and Astin, Felicity and Åström-Olsson, Karin and Budaj, Andrzej and Clemmensen, Peter and Collet, Jean-Philippe and Fox, Keith A. and Fuat, Ahmet and Gustiene, Olivija and Hamm, Christian W. and Kala, Petr and Lancellotti, Patrizio and Maggioni, Aldo Pietro and Merkely, Béla and Neumann, Franz-Josef and Piepoli, Massimo F. and Van de Werf, Frans and Verheugt, Freek and Wallentin, Lars},
  date = {2012-08-24},
  journaltitle = {European Heart Journal},
  volume = {33},
  number = {20},
  pages = {2569--2619},
  doi = {10.1093/eurheartj/ehs215},
  url = {https://doi.org/zkn},
  langid = {english},
  annotation = {This CSL Item was generated by Manubot v0.5.2 from its persistent identifier (standard\_id). standard\_id: doi:10.1093/eurheartj/ehs215 Loaded from an external bibliography file by Manubot. source\_bibliography: bibliography.csl.json original\_id: 1BcAPcJLn}
}

@article{stekhovenMissForest2012,
  title = {{{MissForest}}—Non-Parametric Missing Value Imputation for Mixed-Type Data},
  author = {Stekhoven, Daniel J. and Bühlmann, Peter},
  date = {2012-01-01},
  journaltitle = {Bioinformatics},
  volume = {28},
  number = {1},
  pages = {112--118},
  issn = {1367-4811, 1367-4803},
  doi = {10.1093/bioinformatics/btr597},
  url = {https://academic.oup.com/bioinformatics/article/28/1/112/219101},
  urldate = {2023-12-12},
  abstract = {Abstract             Motivation: Modern data acquisition based on high-throughput technology is often facing the problem of missing data. Algorithms commonly used in the analysis of such large-scale data often depend on a complete set. Missing value imputation offers a solution to this problem. However, the majority of available imputation methods are restricted to one type of variable only: continuous or categorical. For mixed-type data, the different types are usually handled separately. Therefore, these methods ignore possible relations between variable types. We propose a non-parametric method which can cope with different types of variables simultaneously.             Results: We compare several state of the art methods for the imputation of missing values. We propose and evaluate an iterative imputation method (missForest) based on a random forest. By averaging over many unpruned classification or regression trees, random forest intrinsically constitutes a multiple imputation scheme. Using the built-in out-of-bag error estimates of random forest, we are able to estimate the imputation error without the need of a test set. Evaluation is performed on multiple datasets coming from a diverse selection of biological fields with artificially introduced missing values ranging from 10\% to 30\%. We show that missForest can successfully handle missing values, particularly in datasets including different types of variables. In our comparative study, missForest outperforms other methods of imputation especially in data settings where complex interactions and non-linear relations are suspected. The out-of-bag imputation error estimates of missForest prove to be adequate in all settings. Additionally, missForest exhibits attractive computational efficiency and can cope with high-dimensional data.             Availability: The ℝ package missForest is freely available from http://stat.ethz.ch/CRAN/.             Contact: ~stekhoven@stat.math.ethz.ch; buhlmann@stat.math.ethz.ch},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\KU4GBV9A\Stekhoven and Bühlmann - 2012 - MissForest—non-parametric missing value imputation.pdf}
}

@article{steyerbergPrognosis2013,
  title = {Prognosis {{Research Strategy}} ({{PROGRESS}}) 3: {{Prognostic Model Research}}},
  shorttitle = {Prognosis {{Research Strategy}} ({{PROGRESS}}) 3},
  author = {Steyerberg, Ewout W. and Moons, Karel G. M. and family=Windt, given=Danielle A., prefix=van der, useprefix=false and Hayden, Jill A. and Perel, Pablo and Schroter, Sara and Riley, Richard D. and Hemingway, Harry and Altman, Douglas G. and Group, for the PROGRESS},
  date = {2013-02-05},
  journaltitle = {PLOS Medicine},
  shortjournal = {PLOS Medicine},
  volume = {10},
  number = {2},
  pages = {e1001381},
  publisher = {{Public Library of Science}},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.1001381},
  url = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001381},
  urldate = {2023-12-29},
  abstract = {In this article, the third in the PROGRESS series on prognostic factor research, Sara Schroter and colleagues review how prognostic models are developed and validated, and then address how prognostic models are assessed for their impact on practice and patient outcomes, illustrating these ideas with examples.},
  langid = {english},
  keywords = {Biomarkers,Breast cancer,Cancer risk factors,Cost-effectiveness analysis,Decision making,Medical risk factors,Prognosis,Traumatic injury risk factors},
  file = {C:\Users\sdp490\Zotero\storage\G4L7MQNJ\Steyerberg et al. - 2013 - Prognosis Research Strategy (PROGRESS) 3 Prognost.pdf}
}

@manual{survival-package,
  type = {manual},
  title = {A Package for Survival Analysis in {{R}}},
  author = {Therneau, Terry M},
  date = {2023},
  url = {https://CRAN.R-project.org/package=survival}
}

@inreference{Survival2023,
  title = {Survival Analysis},
  booktitle = {Wikipedia},
  date = {2023-10-12T12:14:30Z},
  url = {https://en.wikipedia.org/w/index.php?title=Survival_analysis&oldid=1179784738},
  urldate = {2023-11-09},
  abstract = {Survival analysis is a branch of statistics for analyzing the expected duration of time until one event occurs, such as death in biological organisms and failure in mechanical systems. This topic is called reliability theory or reliability analysis in engineering, duration analysis or duration modelling in economics, and event history analysis in sociology. Survival analysis attempts to answer certain questions, such as what is the proportion of a population which will survive past a certain time? Of those that survive, at what rate will they die or fail? Can multiple causes of death or failure be taken into account? How do particular circumstances or characteristics increase or decrease the probability of survival? To answer such questions, it is necessary to define "lifetime". In the case of biological survival, death is unambiguous, but for mechanical reliability, failure may not be well-defined, for there may well be mechanical systems in which failure is partial, a matter of degree, or not otherwise localized in time. Even in biological problems, some events (for example, heart attack or other organ failure) may have the same ambiguity. The theory outlined below assumes well-defined events at specific times; other cases may be better treated by models which explicitly account for ambiguous events. More generally, survival analysis involves the modelling of time to event data; in this context, death or failure is considered an "event" in the survival analysis literature – traditionally only a single event occurs for each subject, after which the organism or mechanism is dead or broken. Recurring event or repeated event models relax that assumption. The study of recurring events is relevant in systems reliability, and in many areas of social sciences and medical research.},
  langid = {english},
  annotation = {Page Version ID: 1179784738},
  file = {C:\Users\sdp490\Zotero\storage\UPE9J2K2\Survival_analysis.html}
}

@article{taylorStatins2013,
  title = {Statins for the Primary Prevention of Cardiovascular Disease},
  author = {Taylor, Fiona and Huffman, Mark D. and Macedo, Ana Filipa and Moore, Theresa HM and Burke, Margaret and Smith, George Davey and Ward, Kirsten and Ebrahim, Shah and Gay, Hawkins C.},
  date = {2013},
  journaltitle = {Cochrane Database of Systematic Reviews},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {1465-1858},
  doi = {10.1002/14651858.CD004816.pub5},
  url = {https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD004816.pub5/full},
  urldate = {2023-10-10},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\9DEK7WBN\Taylor et al. - 2013 - Statins for the primary prevention of cardiovascul.pdf}
}

@article{thanMachine2019,
  title = {Machine {{Learning}} to {{Predict}} the {{Likelihood}} of {{Acute Myocardial Infarction}}},
  author = {Than, Martin P. and Pickering, John W. and Sandoval, Yader and Shah, Anoop S.V. and Tsanas, Athanasios and Apple, Fred S. and Blankenberg, Stefan and Cullen, Louise and Mueller, Christian and Neumann, Johannes T. and Twerenbold, Raphael and Westermann, Dirk and Beshiri, Agim and Mills, Nicholas L. and {null}, null and George, Peter M and Richards, A Mark and Troughton, Richard W and Aldous, Sally J and Chapman, Andrew R and Anand, Atul and Greenslade, Jaimi and Parsonage, William and Boeddinghaus, Jasper and Wildi, Karin and Nestelberger, Thomas and Badertscher, Patrick and Du, Shaoqing and Huang, Janel and Smith, Stephen W and Sörensen, Nils A and Ojeda, Francisco},
  date = {2019-09-10},
  journaltitle = {Circulation},
  volume = {140},
  number = {11},
  pages = {899--909},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIRCULATIONAHA.119.041980},
  url = {https://www.ahajournals.org/doi/full/10.1161/CIRCULATIONAHA.119.041980},
  urldate = {2023-11-15},
  abstract = {Background: Variations in cardiac troponin concentrations by age, sex, and time between samples in patients with suspected myocardial infarction are not currently accounted for in diagnostic approaches. We aimed to combine these variables through machine learning to improve the assessment of risk for individual patients. Methods: A machine learning algorithm (myocardial-ischemic-injury-index [MI3]) incorporating age, sex, and paired high-sensitivity cardiac troponin I concentrations, was trained on 3013 patients and tested on 7998 patients with suspected myocardial infarction. MI3 uses gradient boosting to compute a value (0–100) reflecting an individual’s likelihood of a diagnosis of type 1 myocardial infarction and estimates the sensitivity, negative predictive value, specificity and positive predictive value for that individual. Assessment was by calibration and area under the receiver operating characteristic curve. Secondary analysis evaluated example MI3 thresholds from the training set that identified patients as low risk (99\% sensitivity) and high risk (75\% positive predictive value), and performance at these thresholds was compared in the test set to the 99th percentile and European Society of Cardiology rule-out pathways. Results: Myocardial infarction occurred in 404 (13.4\%) patients in the training set and 849 (10.6\%) patients in the test set. MI3 was well calibrated with a very high area under the receiver operating characteristic curve of 0.963 [0.956–0.971] in the test set and similar performance in early and late presenters. Example MI3 thresholds identifying low- and high-risk patients in the training set were 1.6 and 49.7, respectively. In the test set, MI3 values were {$<$}1.6 in 69.5\% with a negative predictive value of 99.7\% (99.5–99.8\%) and sensitivity of 97.8\% (96.7–98.7\%), and were ≥49.7 in 10.6\% with a positive predictive value of 71.8\% (68.9–75.0\%) and specificity of 96.7\% (96.3–97.1\%). Using these thresholds, MI3 performed better than the European Society of Cardiology 0/3-hour pathway (sensitivity, 82.5\% [74.5–88.8\%]; specificity, 92.2\% [90.7–93.5\%]) and the 99th percentile at any time point (sensitivity, 89.6\% [87.4–91.6\%]); specificity, 89.3\% [88.6–90.0\%]). Conclusions: Using machine learning, MI3 provides an individualized and objective assessment of the likelihood of myocardial infarction, which can be used to identify low- and high-risk patients who may benefit from earlier clinical decisions. Clinical Trial Registration: URL: https://www.anzctr.org.au. Unique identifier: ACTRN12616001441404.},
  keywords = {acute coronary syndrome,machine learning,myocardial infarction,troponin},
  file = {C:\Users\sdp490\Zotero\storage\4F8YPMCT\Than et al. - 2019 - Machine Learning to Predict the Likelihood of Acut.pdf}
}

@article{theemergingriskfactorscollaborationAssociation2015,
  title = {Association of {{Cardiometabolic Multimorbidity With Mortality}}},
  author = {{The Emerging Risk Factors Collaboration}},
  date = {2015-07-07},
  journaltitle = {JAMA},
  shortjournal = {JAMA},
  volume = {314},
  number = {1},
  pages = {52--60},
  issn = {0098-7484},
  doi = {10.1001/jama.2015.7008},
  url = {https://doi.org/10.1001/jama.2015.7008},
  urldate = {2023-12-03},
  abstract = {The prevalence of cardiometabolic multimorbidity is increasing.To estimate reductions in life expectancy associated with cardiometabolic multimorbidity.Age- and sex-adjusted mortality rates and hazard ratios (HRs) were calculated using individual participant data from the Emerging Risk Factors Collaboration (689\,300 participants; 91 cohorts; years of baseline surveys: 1960-2007; latest mortality follow-up: April 2013; 128\,843 deaths). The HRs from the Emerging Risk Factors Collaboration were compared with those from the UK Biobank (499\,808 participants; years of baseline surveys: 2006-2010; latest mortality follow-up: November 2013; 7995 deaths). Cumulative survival was estimated by applying calculated age-specific HRs for mortality to contemporary US age-specific death rates.A history of 2 or more of the following: diabetes mellitus, stroke, myocardial infarction (MI).All-cause mortality and estimated reductions in life expectancy.In participants in the Emerging Risk Factors Collaboration without a history of diabetes, stroke, or MI at baseline (reference group), the all-cause mortality rate adjusted to the age of 60 years was 6.8 per 1000 person-years. Mortality rates per 1000 person-years were 15.6 in participants with a history of diabetes, 16.1 in those with stroke, 16.8 in those with MI, 32.0 in those with both diabetes and MI, 32.5 in those with both diabetes and stroke, 32.8 in those with both stroke and MI, and 59.5 in those with diabetes, stroke, and MI. Compared with the reference group, the HRs for all-cause mortality were 1.9 (95\% CI, 1.8-2.0) in participants with a history of diabetes, 2.1 (95\% CI, 2.0-2.2) in those with stroke, 2.0 (95\% CI, 1.9-2.2) in those with MI, 3.7 (95\% CI, 3.3-4.1) in those with both diabetes and MI, 3.8 (95\% CI, 3.5-4.2) in those with both diabetes and stroke, 3.5 (95\% CI, 3.1-4.0) in those with both stroke and MI, and 6.9 (95\% CI, 5.7-8.3) in those with diabetes, stroke, and MI. The HRs from the Emerging Risk Factors Collaboration were similar to those from the more recently recruited UK Biobank. The HRs were little changed after further adjustment for markers of established intermediate pathways (eg, levels of lipids and blood pressure) and lifestyle factors (eg, smoking, diet). At the age of 60 years, a history of any 2 of these conditions was associated with 12 years of reduced life expectancy and a history of all 3 of these conditions was associated with 15 years of reduced life expectancy.Mortality associated with a history of diabetes, stroke, or MI was similar for each condition. Because any combination of these conditions was associated with multiplicative mortality risk, life expectancy was substantially lower in people with multimorbidity.},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\RJ5FII8R\\The Emerging Risk Factors Collaboration - 2015 - Association of Cardiometabolic Multimorbidity With.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\JT9AJYCG\\2382980.html}
}

@article{thompsonStatinAssociated2003,
  title = {Statin-{{Associated Myopathy}}},
  author = {Thompson, Paul D. and Clarkson, Priscilla and Karas, Richard H.},
  date = {2003-04-02},
  journaltitle = {JAMA},
  shortjournal = {JAMA},
  volume = {289},
  number = {13},
  pages = {1681--1690},
  issn = {0098-7484},
  doi = {10.1001/jama.289.13.1681},
  url = {https://doi.org/10.1001/jama.289.13.1681},
  urldate = {2023-10-18},
  abstract = {Statins (3-hydroxy-3-methylglutaryl coenzyme A reductase inhibitors) are associated with skeletal muscle complaints, including clinically important myositis and rhabdomyolysis, mild serum creatine kinase (CK) elevations, myalgia with and without elevated CK levels, muscle weakness, muscle cramps, and persistent myalgia and CK elevations after statin withdrawal. We performed a literature review to provide a clinical summary of statin-associated myopathy and discuss possible mediating mechanisms. We also update the US Food and Drug Administration (FDA) reports on statin-associated rhabdomyolysis. Articles on statin myopathy were identified via a PubMed search through November 2002 and articles on statin clinical trials, case series, and review articles were identified via a PubMed search through January 2003. Adverse event reports of statin-associated rhabdomyolysis were also collected from the FDA MEDWATCH database. The literature review found that reports of muscle problems during statin clinical trials are extremely rare. The FDA MEDWATCH Reporting System lists 3339 cases of statin-associated rhabdomyolysis reported between January 1, 1990, and March 31, 2002. Cerivastatin was the most commonly implicated statin. Few data are available regarding the frequency of less-serious events such as muscle pain and weakness, which may affect 1\% to 5\% of patients. The risk of rhabdomyolysis and other adverse effects with statin use can be exacerbated by several factors, including compromised hepatic and renal function, hypothyroidism, diabetes, and concomitant medications. Medications such as the fibrate gemfibrozil alter statin metabolism and increase statin plasma concentration. How statins injure skeletal muscle is not clear, although recent evidence suggests that statins reduce the production of small regulatory proteins that are important for myocyte maintenance.},
  file = {C:\Users\sdp490\Zotero\storage\TQIDEU82\196305.html}
}

@incollection{thornPharmGKB2013,
  title = {{{PharmGKB}}: {{The Pharmacogenomics Knowledge Base}}},
  shorttitle = {{{PharmGKB}}},
  booktitle = {Pharmacogenomics: {{Methods}} and {{Protocols}}},
  author = {Thorn, Caroline F. and Klein, Teri E. and Altman, Russ B.},
  editor = {Innocenti, Federico and family=Schaik, given=Ron H.N., prefix=van, useprefix=true},
  date = {2013},
  series = {Methods in {{Molecular Biology}}},
  pages = {311--320},
  publisher = {{Humana Press}},
  location = {{Totowa, NJ}},
  doi = {10.1007/978-1-62703-435-7_20},
  url = {https://doi.org/10.1007/978-1-62703-435-7_20},
  urldate = {2023-10-19},
  abstract = {The Pharmacogenomics Knowledge Base, PharmGKB, is an interactive tool for researchers investigating how genetic variation affects drug response. The PharmGKB Web site, http://www.pharmgkb.org, displays genotype, molecular, and clinical knowledge integrated into pathway representations and Very Important Pharmacogene (VIP) summaries with links to additional external resources. Users can search and browse the knowledgebase by genes, variants, drugs, diseases, and pathways. Registration is free to the entire research community, but subject to agreement to use for research purposes only and not to redistribute. Registered users can access and download data to aid in the design of future pharmacogenetics and pharmacogenomics studies.},
  isbn = {978-1-62703-435-7},
  langid = {english},
  keywords = {Database,Genotype,Pathways,Pharmacogenes,Pharmacogenetics,Pharmacogenomics,PharmGKB,Phenotype,VIP genes},
  file = {C:\Users\sdp490\Zotero\storage\5EIWWJ3I\Thorn et al. - 2013 - PharmGKB The Pharmacogenomics Knowledge Base.pdf}
}

@article{thygesenFourth2019,
  title = {Fourth Universal Definition of Myocardial Infarction (2018)},
  author = {Thygesen, Kristian and Alpert, Joseph S and Jaffe, Allan S and Chaitman, Bernard R and Bax, Jeroen J and Morrow, David A and White, Harvey D and {ESC Scientific Document Group}},
  date = {2019-01-14},
  journaltitle = {European Heart Journal},
  shortjournal = {European Heart Journal},
  volume = {40},
  number = {3},
  pages = {237--269},
  issn = {0195-668X},
  doi = {10.1093/eurheartj/ehy462},
  url = {https://doi.org/10.1093/eurheartj/ehy462},
  urldate = {2023-10-05},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\HKHWV4QB\\Thygesen et al. - 2019 - Fourth universal definition of myocardial infarcti.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\8J353BTK\\5079081.html}
}

@article{tomasevClinically2019,
  title = {A Clinically Applicable Approach to Continuous Prediction of Future Acute Kidney Injury},
  author = {Tomašev, Nenad and Glorot, Xavier and Rae, Jack W. and Zielinski, Michal and Askham, Harry and Saraiva, Andre and Mottram, Anne and Meyer, Clemens and Ravuri, Suman and Protsyuk, Ivan and Connell, Alistair and Hughes, Cían O. and Karthikesalingam, Alan and Cornebise, Julien and Montgomery, Hugh and Rees, Geraint and Laing, Chris and Baker, Clifton R. and Peterson, Kelly and Reeves, Ruth and Hassabis, Demis and King, Dominic and Suleyman, Mustafa and Back, Trevor and Nielson, Christopher and Ledsam, Joseph R. and Mohamed, Shakir},
  date = {2019-08},
  journaltitle = {Nature},
  volume = {572},
  number = {7767},
  pages = {116--119},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1390-1},
  url = {https://www.nature.com/articles/s41586-019-1390-1},
  urldate = {2023-09-01},
  abstract = {The early prediction of deterioration could have an important role in supporting healthcare professionals, as an estimated 11\% of deaths in hospital follow a failure to promptly recognize and treat deteriorating patients1. To achieve this goal requires predictions of patient risk that are continuously updated and accurate, and delivered at an individual level with sufficient context and enough time to act. Here we develop a deep learning approach for the continuous risk prediction of future deterioration in patients, building on recent work that models adverse events from electronic health records2–17 and using acute kidney injury—a common and potentially life-threatening condition18—as an exemplar. Our model was developed on a large, longitudinal dataset of electronic health records that cover diverse clinical environments, comprising 703,782~adult patients across 172~inpatient and 1,062~outpatient sites. Our model predicts 55.8\% of all inpatient episodes of acute kidney injury, and 90.2\% of all acute kidney injuries that required subsequent administration of dialysis, with a lead time of up to 48~h and a ratio of 2~false alerts for every true alert. In addition to predicting future acute kidney injury, our model provides confidence assessments and a list of the clinical features that are most salient to each prediction, alongside predicted future trajectories for clinically relevant blood tests9. Although the recognition and prompt treatment of acute kidney injury is known to be challenging, our approach may offer opportunities for identifying patients at risk within a time window that enables early treatment.},
  issue = {7767},
  langid = {english},
  keywords = {Predictive markers,Preventive medicine,Translational research},
  file = {C:\Users\sdp490\Zotero\storage\BD2KEQDL\Tomašev et al. - 2019 - A clinically applicable approach to continuous pre.pdf}
}

@article{tomasevUse2021,
  title = {Use of Deep Learning to Develop Continuous-Risk Models for Adverse Event Prediction from Electronic Health Records},
  author = {Tomašev, Nenad and Harris, Natalie and Baur, Sebastien and Mottram, Anne and Glorot, Xavier and Rae, Jack W. and Zielinski, Michal and Askham, Harry and Saraiva, Andre and Magliulo, Valerio and Meyer, Clemens and Ravuri, Suman and Protsyuk, Ivan and Connell, Alistair and Hughes, Cían O. and Karthikesalingam, Alan and Cornebise, Julien and Montgomery, Hugh and Rees, Geraint and Laing, Chris and Baker, Clifton R. and Osborne, Thomas F. and Reeves, Ruth and Hassabis, Demis and King, Dominic and Suleyman, Mustafa and Back, Trevor and Nielson, Christopher and Seneviratne, Martin G. and Ledsam, Joseph R. and Mohamed, Shakir},
  date = {2021-06},
  journaltitle = {Nature Protocols},
  shortjournal = {Nat Protoc},
  volume = {16},
  number = {6},
  pages = {2765--2787},
  publisher = {{Nature Publishing Group}},
  issn = {1750-2799},
  doi = {10.1038/s41596-021-00513-5},
  url = {https://www.nature.com/articles/s41596-021-00513-5},
  urldate = {2023-08-31},
  abstract = {Early prediction of patient outcomes is important for targeting preventive care. This protocol describes a practical workflow for developing deep-learning risk models that can predict various clinical and operational outcomes from structured electronic health record (EHR) data. The protocol comprises five main stages: formal problem definition, data pre-processing, architecture selection, calibration and uncertainty, and generalizability evaluation. We have applied the workflow to four endpoints (acute kidney injury, mortality, length of stay and 30-day hospital readmission). The workflow can enable continuous (e.g., triggered every 6 h) and static (e.g., triggered at 24 h after admission) predictions. We also provide an open-source codebase that illustrates some key principles in EHR modeling. This protocol can be used by interdisciplinary teams with programming and clinical expertise to build deep-learning prediction models with alternate data sources and prediction tasks.},
  issue = {6},
  langid = {english},
  keywords = {Machine learning,Predictive markers,Software,Translational research},
  file = {C:\Users\sdp490\Zotero\storage\ICC3UGDA\Tomašev et al. - 2021 - Use of deep learning to develop continuous-risk mo.pdf}
}

@article{topolHighperformance2019,
  title = {High-Performance Medicine: The Convergence of Human and Artificial Intelligence},
  shorttitle = {High-Performance Medicine},
  author = {Topol, Eric J.},
  date = {2019-01},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {25},
  number = {1},
  pages = {44--56},
  publisher = {{Nature Publishing Group}},
  doi = {10.1038/s41591-018-0300-7},
  url = {https://www.nature.com/articles/s41591-018-0300-7},
  urldate = {2023-04-08},
  abstract = {The use of artificial intelligence, and the deep-learning subtype in particular, has been enabled by the use of labeled big data, along with markedly enhanced computing power and cloud storage, across all sectors. In medicine, this is beginning to have an impact at three levels: for clinicians, predominantly via rapid, accurate image interpretation; for health systems, by improving workflow and the potential for reducing medical errors; and for patients, by enabling them to process their own data to promote health. The current limitations, including bias, privacy and security, and lack of transparency, along with the future directions of these applications will be discussed in this article. Over time, marked improvements in accuracy, productivity, and workflow will likely be actualized, but whether that will be used to improve the patient–doctor relationship or facilitate its erosion remains to be seen.},
  issue = {1},
  langid = {english},
  keywords = {Health care,Machine learning}
}

@article{turchinUsing2006,
  title = {Using {{Regular Expressions}} to {{Abstract Blood Pressure}} and {{Treatment Intensification Information}} from the {{Text}} of {{Physician Notes}}},
  author = {Turchin, Alexander and Kolatkar, Nikheel S. and Grant, Richard W. and Makhni, Eric C. and Pendergrass, Merri L. and Einbinder, Jonathan S.},
  date = {2006},
  journaltitle = {Journal of the American Medical Informatics Association : JAMIA},
  shortjournal = {J Am Med Inform Assoc},
  volume = {13},
  number = {6},
  eprint = {16929043},
  eprinttype = {pmid},
  pages = {691--695},
  issn = {1067-5027},
  doi = {10.1197/jamia.M2078},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1656954/},
  urldate = {2023-11-29},
  abstract = {This case study examined the utility of regular expressions to identify clinical data relevant to the epidemiology of treatment of hypertension. We designed a software tool that employed regular expressions to identify and extract instances of documented blood pressure values and anti-hypertensive treatment intensification from the text of physician notes. We determined sensitivity, specificity and precision of identification of blood pressure values and anti-hypertensive treatment intensification using a gold standard of manual abstraction of 600 notes by two independent reviewers. The software processed 370 Mb of text per hour, and identified elevated blood pressure documented in free text physician notes with sensitivity and specificity of 98\%, and precision of 93.2\%. Anti-hypertensive treatment intensification was identified with sensitivity 83.8\%, specificity of 95.0\%, and precision of 85.9\%. Regular expressions can be an effective method for focused information extraction tasks related to high-priority disease areas such as hypertension.},
  pmcid = {PMC1656954},
  file = {C:\Users\sdp490\Zotero\storage\ALLVVC4V\Turchin et al. - 2006 - Using Regular Expressions to Abstract Blood Pressu.pdf}
}

@book{tutzModeling2016,
  title = {Modeling {{Discrete Time-to-Event Data}}},
  author = {Tutz, Gerhard and Schmid, Matthias},
  date = {2016-06-22},
  edition = {1st ed. 2016 edition},
  publisher = {{Springer}},
  location = {{New York, NY}},
  abstract = {This book focuses on statistical methods for the analysis of discrete failure times. Failure time analysis is one of the most important fields in statistical research, with applications affecting a wide range of disciplines, in particular, demography, econometrics, epidemiology and clinical research. Although there are a large variety of statistical methods for failure time analysis, many techniques are designed for failure times that are measured on a continuous scale. In empirical studies, however, failure times are often discrete, either because they have been measured in intervals (e.g., quarterly or yearly) or because they have been rounded or grouped. The book covers well-established methods like life-table analysis and discrete hazard regression models, but also introduces state-of-the art techniques for model evaluation, nonparametric estimation and variable selection. Throughout, the methods are illustrated by real life applications, and relationships to survival analysis in continuous time are explained. Each section includes a set of exercises on the respective topics. Various functions and tools for the analysis of discrete survival data are collected in the R package discSurv that accompanies the book.},
  isbn = {978-3-319-28156-8},
  langid = {english},
  pagetotal = {257}
}

@article{ullmannValidation2022,
  title = {Validation of Cluster Analysis Results on Validation Data: {{A}} Systematic Framework},
  shorttitle = {Validation of Cluster Analysis Results on Validation Data},
  author = {Ullmann, Theresa and Hennig, Christian and Boulesteix, Anne-Laure},
  date = {2022},
  journaltitle = {WIREs Data Mining and Knowledge Discovery},
  volume = {12},
  number = {3},
  pages = {e1444},
  issn = {1942-4795},
  doi = {10.1002/widm.1444},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1444},
  urldate = {2023-12-30},
  abstract = {Cluster analysis refers to a wide range of data analytic techniques for class discovery and is popular in many application fields. To assess the quality of a clustering result, different cluster validation procedures have been proposed in the literature. While there is extensive work on classical validation techniques, such as internal and external validation, less attention has been given to validating and replicating a clustering result using a validation dataset. Such a dataset may be part of the original dataset, which is separated before analysis begins, or it could be an independently collected dataset. We present a systematic, structured review of the existing literature about this topic. For this purpose, we outline a formal framework that covers most existing approaches for validating clustering results on validation data. In particular, we review classical validation techniques such as internal and external validation, stability analysis, and visual validation, and show how they can be interpreted in terms of our framework. We define and formalize different types of validation of clustering results on a validation dataset, and give examples of how clustering studies from the applied literature that used a validation dataset can be seen as instances of our framework. This article is categorized under: Technologies {$>$} Structure Discovery and Clustering Algorithmic Development {$>$} Statistics Technologies {$>$} Machine Learning},
  langid = {english},
  keywords = {cluster stability,cluster validation,clustering,independent data,replication},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\E9MJBNTU\\Ullmann et al. - 2022 - Validation of cluster analysis results on validati.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\6WE9PFEJ\\widm.html}
}

@article{upalaGallstone2017,
  title = {Gallstone {{Disease}} and the {{Risk}} of {{Cardiovascular Disease}}: {{A Systematic Review}} and {{Meta-Analysis}} of {{Observational Studies}}},
  shorttitle = {Gallstone {{Disease}} and the {{Risk}} of {{Cardiovascular Disease}}},
  author = {Upala, S. and Sanguankeo, A. and Jaruvongvanich, V.},
  date = {2017-03-01},
  journaltitle = {Scandinavian Journal of Surgery},
  shortjournal = {Scand J Surg},
  volume = {106},
  number = {1},
  pages = {21--27},
  publisher = {{SAGE Publications Ltd}},
  issn = {1457-4969},
  doi = {10.1177/1457496916650998},
  url = {https://doi.org/10.1177/1457496916650998},
  urldate = {2023-12-06},
  abstract = {Objectives: Gallstone disease shares certain risk factors with cardiovascular disease, particularly metabolic risk factors. Patients with gallstone disease may be at increased risk of cardiovascular disease. Several recent studies exploring the effect of gallstone disease on cardiovascular disease outcomes demonstrated inconsistent results. Design: We conducted a systematic review and meta-analysis of cohort, case–control, and cross-sectional studies that compared the risk of developing cardiovascular disease events in patients with gallstone disease versus non-gallstone disease controls. Data from each study were combined using the random-effects, generic inverse variance method of DerSimonian and Laird to calculate the pooled hazard ratio, odd ratio, and 95\% confidence interval. Results: Data were extracted from six studies involving 176,734 cases and 803,714 controls. The pooled hazard ratio of cardiovascular events in patients with gallstone disease was 1.28 (95\% confidence interval: 1.23–1.33, I2\,=\,42\%). The pooled odd ratio of cardiovascular events in patients with gallstone disease was 1.82 (95\% confidence interval: 1.47–2.24, I2\,=\,68\%). Conclusions: Our study demonstrated a statistically significant increase in the risk of cardiovascular disease among patients with gallstone disease.},
  langid = {english},
  file = {C:\Users\sdp490\Zotero\storage\5RIVGKNG\Upala et al. - 2017 - Gallstone Disease and the Risk of Cardiovascular D.pdf}
}

@article{vanderveldenExplainable2022,
  title = {Explainable Artificial Intelligence ({{XAI}}) in Deep Learning-Based Medical Image Analysis},
  author = {family=Velden, given=Bas H. M., prefix=van der, useprefix=true and Kuijf, Hugo J. and Gilhuijs, Kenneth G. A. and Viergever, Max A.},
  date = {2022-07-01},
  journaltitle = {Medical Image Analysis},
  shortjournal = {Medical Image Analysis},
  volume = {79},
  pages = {102470},
  issn = {1361-8415},
  doi = {10.1016/j.media.2022.102470},
  url = {https://www.sciencedirect.com/science/article/pii/S1361841522001177},
  urldate = {2023-04-11},
  abstract = {With an increase in deep learning-based methods, the call for explainability of such methods grows, especially in high-stakes decision making areas such as medical image analysis. This survey presents an overview of explainable artificial intelligence (XAI) used in deep learning-based medical image analysis. A framework of XAI criteria is introduced to classify deep learning-based medical image analysis methods. Papers on XAI techniques in medical image analysis are then surveyed and categorized according to the framework and according to anatomical location. The paper concludes with an outlook of future opportunities for XAI in medical image analysis.},
  langid = {english},
  keywords = {Deep learning,Explainable artificial intelligence,Interpretable deep learning,Medical image analysis,Survey},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\VBMTIC9N\\van der Velden et al. - 2022 - Explainable artificial intelligence (XAI) in deep .pdf;C\:\\Users\\sdp490\\Zotero\\storage\\ZZ4VXBJK\\S1361841522001177.html}
}

@article{vandongenGraph2008,
  title = {Graph {{Clustering Via}} a {{Discrete Uncoupling Process}}},
  author = {Van Dongen, Stijn},
  date = {2008-01},
  journaltitle = {SIAM Journal on Matrix Analysis and Applications},
  shortjournal = {SIAM J. Matrix Anal. Appl.},
  volume = {30},
  number = {1},
  pages = {121--141},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0895-4798},
  doi = {10.1137/040608635},
  url = {https://epubs.siam.org/doi/10.1137/040608635},
  urldate = {2023-12-03},
  abstract = {Recently, Hoffmann and Kriegel proved an important combinatorial theorem [SIAM J. Discrete Math., 9 (1996), pp. 210--224]: Every 2-connected bipartite plane multigraph G without 2-cycle faces has a triangulation in which all vertices have even degree (this is called an even triangulation). Combined with the classical Whitney's theorem, this result implies that every such graph has a 3-colorable plane triangulation. Using this theorem, Hoffmann and Kriegel significantly improved the upper bounds of several art gallery and prison guard problems. A complicated O(n2 ) time algorithm was obtained in [SIAM J. Discrete Math., 9 (1996), pp. 210--224] for constructing an even triangulation of G. Hoffmann and Kriegel conjectured that there is an O(n3/2 ) time algorithm for solving this problem.In this paper, we develop a simple proof of the above theorem. Our proof reveals and relies on a natural correspondence between even triangulations of G and certain orientations of G. Based on this new proof, we obtain a very simple O(n) time algorithm for finding an even triangulation of G. We also extend our proof to show the existence of even triangulations for similar graphs on high genus surface.}
}

@article{vanhouwelingenDynamic2007,
  title = {Dynamic {{Prediction}} by {{Landmarking}} in {{Event History Analysis}}},
  author = {Van Houwelingen, Hans C.},
  date = {2007},
  journaltitle = {Scandinavian Journal of Statistics},
  volume = {34},
  number = {1},
  pages = {70--85},
  issn = {1467-9469},
  doi = {10.1111/j.1467-9469.2006.00529.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9469.2006.00529.x},
  urldate = {2023-12-31},
  abstract = {Abstract. This article advocates the landmarking approach that dynamically adjusts predictive models for survival data during the follow up. This updating is achieved by directly fitting models for the individuals still at risk at the landmark point. Using this approach, simple proportional hazards models are able to catch the development over time for models with time-varying effects of covariates or data with time-dependent covariates (biomarkers). To smooth the effect of the landmarking, sequences of models are considered with parametric effects of the landmark time point and fitted by maximizing appropriate pseudo log-likelihoods that extend the partial log-likelihood to cover the landmarking approach.},
  langid = {english},
  keywords = {landmark analysis,landmarking,pseudo-partial likelihood,survival analysis,time-dependent covariates,time-varying effects},
  file = {C:\Users\sdp490\Zotero\storage\EM8U9QAD\Van Houwelingen - 2007 - Dynamic Prediction by Landmarking in Event History.pdf}
}

@inproceedings{vaswaniAttention2017,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  date = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
  urldate = {2023-12-22},
  abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
  file = {C:\Users\sdp490\Zotero\storage\HEYISFPY\Vaswani et al. - 2017 - Attention is All you Need.pdf}
}

@article{visseren20212021,
  title = {2021 {{ESC Guidelines}} on Cardiovascular Disease Prevention in Clinical Practice},
  shorttitle = {2021 {{ESC Guidelines}} on Cardiovascular Disease Prevention in Clinical Practice},
  author = {Visseren, Frank L J and Mach, François and Smulders, Yvo M and Carballo, David and Koskinas, Konstantinos C and Bäck, Maria and Benetos, Athanase and Biffi, Alessandro and Boavida, José-Manuel and Capodanno, Davide and Cosyns, Bernard and Crawford, Carolyn and Davos, Constantinos H and Desormais, Ileana and Di Angelantonio, Emanuele and Franco, Oscar H and Halvorsen, Sigrun and Hobbs, F D Richard and Hollander, Monika and Jankowska, Ewa A and Michal, Matthias and Sacco, Simona and Sattar, Naveed and Tokgozoglu, Lale and Tonstad, Serena and Tsioufis, Konstantinos P and family=Dis, given=Ineke, prefix=van, useprefix=true and family=Gelder, given=Isabelle C, prefix=van, useprefix=true and Wanner, Christoph and Williams, Bryan and {ESC Scientific Document Group}},
  date = {2021-09-07},
  journaltitle = {European Heart Journal},
  shortjournal = {European Heart Journal},
  volume = {42},
  number = {34},
  pages = {3227--3337},
  issn = {0195-668X},
  doi = {10.1093/eurheartj/ehab484},
  url = {https://doi.org/10.1093/eurheartj/ehab484},
  urldate = {2023-10-09},
  abstract = {All experts involved in the development of these guidelines have submitted declarations of interest. These have been compiled in a report and published in a supplementary document simultaneously to the guidelines. The report is also available on the ESC website www.escardio.org/guidelines},
  file = {C:\Users\sdp490\Zotero\storage\DAKXS85B\Visseren et al. - 2021 - 2021 ESC Guidelines on cardiovascular disease prev.pdf}
}

@article{whittyMap2020,
  title = {Map Clusters of Diseases to Tackle Multimorbidity},
  author = {Whitty, Christopher J. M. and Watt, Fiona M.},
  date = {2020-03},
  journaltitle = {Nature},
  volume = {579},
  number = {7800},
  pages = {494--496},
  publisher = {{Nature Publishing Group}},
  doi = {10.1038/d41586-020-00837-4},
  url = {https://www.nature.com/articles/d41586-020-00837-4},
  urldate = {2023-12-06},
  abstract = {Many people now have two or more diseases at once. It is time to rethink funding, research, publishing, training and treatment for this growing problem.},
  issue = {7800},
  langid = {english},
  keywords = {Health care,Medical research,Public health},
  annotation = {Bandiera\_abtest: a Cg\_type: Comment Subject\_term: Health care, Medical research, Public health},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\X6AVF3SX\\Whitty and Watt - 2020 - Map clusters of diseases to tackle multimorbidity.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\84GGK26C\\d41586-020-00837-4.html}
}

@online{wiegrebeDeep2023,
  title = {Deep {{Learning}} for {{Survival Analysis}}: {{A Review}}},
  shorttitle = {Deep {{Learning}} for {{Survival Analysis}}},
  author = {Wiegrebe, Simon and Kopper, Philipp and Sonabend, Raphael and Bischl, Bernd and Bender, Andreas},
  date = {2023-07-12},
  eprint = {2305.14961},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2305.14961},
  urldate = {2023-09-14},
  abstract = {The influx of deep learning (DL) techniques into the field of survival analysis in recent years has led to substantial methodological progress; for instance, learning from unstructured or high-dimensional data such as images, text or omics data. In this work, we conduct a comprehensive systematic review of DL-based methods for time-to-event analysis, characterizing them according to both survival- and DL-related attributes. In summary, the reviewed methods often address only a small subset of tasks relevant to time-to-event data - e.g., single-risk right-censored data - and neglect to incorporate more complex settings. Our findings are summarized in an editable, open-source, interactive table: https://survival-org.github.io/DL4Survival. As this research area is advancing rapidly, we encourage community contribution in order to keep this database up to date.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\GDXYM2Q3\\Wiegrebe et al. - 2023 - Deep Learning for Survival Analysis A Review.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\URAKYSQW\\2305.html}
}

@online{wiegrebeDeep2023a,
  title = {Deep {{Learning}} for {{Survival Analysis}}: {{A Review}}},
  shorttitle = {Deep {{Learning}} for {{Survival Analysis}}},
  author = {Wiegrebe, Simon and Kopper, Philipp and Sonabend, Raphael and Bischl, Bernd and Bender, Andreas},
  date = {2023-07-12},
  eprint = {2305.14961},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2305.14961},
  urldate = {2023-11-17},
  abstract = {The influx of deep learning (DL) techniques into the field of survival analysis in recent years has led to substantial methodological progress; for instance, learning from unstructured or high-dimensional data such as images, text or omics data. In this work, we conduct a comprehensive systematic review of DL-based methods for time-to-event analysis, characterizing them according to both survival- and DL-related attributes. In summary, the reviewed methods often address only a small subset of tasks relevant to time-to-event data - e.g., single-risk right-censored data - and neglect to incorporate more complex settings. Our findings are summarized in an editable, open-source, interactive table: https://survival-org.github.io/DL4Survival. As this research area is advancing rapidly, we encourage community contribution in order to keep this database up to date.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\CAWUSTWG\\Wiegrebe et al. - 2023 - Deep Learning for Survival Analysis A Review.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\TCP2Z7AM\\2305.html}
}

@article{wirthPresence2015,
  title = {Presence of Gallstones and the Risk of Cardiovascular Diseases: {{The EPIC-Germany}} Cohort Study},
  shorttitle = {Presence of Gallstones and the Risk of Cardiovascular Diseases},
  author = {Wirth, Janine and family=Giuseppe, given=Romina, prefix=di, useprefix=false and Wientzek, Angelika and Katzke, Verena A and Kloss, Manja and Kaaks, Rudolf and Boeing, Heiner and Weikert, Cornelia},
  date = {2015-03-01},
  journaltitle = {European Journal of Preventive Cardiology},
  shortjournal = {European Journal of Preventive Cardiology},
  volume = {22},
  number = {3},
  pages = {326--334},
  issn = {2047-4873},
  doi = {10.1177/2047487313512218},
  url = {https://doi.org/10.1177/2047487313512218},
  urldate = {2023-12-06},
  abstract = {Gallstones are common disorders associated with several cardiovascular risk factors. Gallstone formation and atherosclerosis may share key pathways, but studies on putative associations between gallstones and the risk of cardiovascular disease are sparse and non-conclusive. We studied the relationship between gallstones and the risk of subsequent cardiovascular diseases in the German arm of the European Prospective Investigation into Cancer and Nutrition (EPIC).The study comprises 46,468 participants from EPIC-Potsdam and EPIC-Heidelberg aged 35-65 years, free of cardiovascular diseases and diabetes at baseline. Information about the gallstone status at baseline was ascertained via questionnaires. For all incident cases of myocardial infarction and stroke confirmation was obtained from the treating physician. Relative risks were estimated using Cox proportional hazards regression.During eight years of follow-up, 919 participants suffered a stroke or myocardial infarction. After multivariable adjustment for established risk factors, subjects with reported gallstones (n\,=\,4828) had an increased risk of cardiovascular diseases (hazard rate ratio (HR)\,=\,1.24, 95\% confidence interval (CI): 1.02, 1.50). In individuals, who underwent a cholecystectomy before baseline a 1.32-fold increase in risk was observed (95\%CI: 1.05, 1.65). HRs differed depending on the presence of selected established risk factors (e.g. HR for cardiovascular diseases regarding gallstones in smokers\,=\,1.66, 95\%CI: 1.20, 2.30, and non-smokers\,=\,1.09, 95\%CI: 0.86, 1.38).Our results indicate an increased cardiovascular risk for gallstone formers, which cannot be counteracted by gallbladder removal and opens up perspectives for individualized prevention strategies.},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\6ITB7BBQ\\Wirth et al. - 2015 - Presence of gallstones and the risk of cardiovascu.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\X5GVI7UB\\5984121.html}
}

@article{yangHyperparameter2020,
  title = {On Hyperparameter Optimization of Machine Learning Algorithms: {{Theory}} and Practice},
  shorttitle = {On Hyperparameter Optimization of Machine Learning Algorithms},
  author = {Yang, Li and Shami, Abdallah},
  date = {2020-11-20},
  journaltitle = {Neurocomputing},
  shortjournal = {Neurocomputing},
  volume = {415},
  pages = {295--316},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2020.07.061},
  url = {https://www.sciencedirect.com/science/article/pii/S0925231220311693},
  urldate = {2023-11-01},
  abstract = {Machine learning algorithms have been used widely in various applications and areas. To fit a machine learning model into different problems, its hyper-parameters must be tuned. Selecting the best hyper-parameter configuration for machine learning models has a direct impact on the model’s performance. It often requires deep knowledge of machine learning algorithms and appropriate hyper-parameter optimization techniques. Although several automatic optimization techniques exist, they have different strengths and drawbacks when applied to different types of problems. In this paper, optimizing the hyper-parameters of common machine learning models is studied. We introduce several state-of-the-art optimization techniques and discuss how to apply them to machine learning algorithms. Many available libraries and frameworks developed for hyper-parameter optimization problems are provided, and some open challenges of hyper-parameter optimization research are also discussed in this paper. Moreover, experiments are conducted on benchmark datasets to compare the performance of different optimization methods and provide practical examples of hyper-parameter optimization. This survey paper will help industrial users, data analysts, and researchers to better develop machine learning models by identifying the proper hyper-parameter configurations effectively.},
  keywords = {Bayesian optimization,Genetic algorithm,Grid search,Hyper-parameter optimization,Machine learning,Particle swarm optimization},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\AP99QZRH\\Yang and Shami - 2020 - On hyperparameter optimization of machine learning.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\FP3WMAC9\\S0925231220311693.html}
}

@inproceedings{yuLearning2011,
  title = {Learning {{Patient-Specific Cancer Survival Distributions}} as a {{Sequence}} of {{Dependent Regressors}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Yu, Chun-Nam and Greiner, Russell and Lin, Hsiu-Chin and Baracos, Vickie},
  date = {2011},
  volume = {24},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2011/hash/1019c8091693ef5c5f55970346633f92-Abstract.html},
  urldate = {2023-11-16},
  abstract = {An accurate model of patient survival time can help in the treatment and care of cancer patients. The common practice of providing survival time estimates based only on population averages for the site and stage of cancer ignores many important individual differences among patients. In this paper, we propose a local regression method for learning patient-specific survival time distribution based on patient attributes such as blood tests and clinical assessments. When tested on a cohort of more than 2000 cancer patients, our method gives survival time predictions that are much more accurate than popular survival analysis models such as the Cox and Aalen regression models. Our results also show that using patient-specific attributes can reduce the prediction error on survival time by as much as 20\% when compared to using cancer site and stage only.},
  file = {C:\Users\sdp490\Zotero\storage\U8YRFLDE\Yu et al. - 2011 - Learning Patient-Specific Cancer Survival Distribu.pdf}
}

@article{zamorano20162016,
  title = {2016 {{ESC Position Paper}} on Cancer Treatments and Cardiovascular Toxicity Developed under the Auspices of the {{ESC Committee}} for {{Practice Guidelines}}: \hspace{0.6em}{{The Task Force}} for Cancer Treatments and Cardiovascular Toxicity of the {{European Society}} of {{Cardiology}} ({{ESC}})},
  shorttitle = {2016 {{ESC Position Paper}} on Cancer Treatments and Cardiovascular Toxicity Developed under the Auspices of the {{ESC Committee}} for {{Practice Guidelines}}},
  author = {Zamorano, Jose Luis and Lancellotti, Patrizio and Rodriguez Muñoz, Daniel and Aboyans, Victor and Asteggiano, Riccardo and Galderisi, Maurizio and Habib, Gilbert and Lenihan, Daniel J. and Lip, Gregory Y. H. and Lyon, Alexander R. and Lopez Fernandez, Teresa and Mohty, Dania and Piepoli, Massimo F. and Tamargo, Juan and Torbicki, Adam and Suter, Thomas M. and {ESC Scientific Document Group}},
  date = {2016-09-21},
  journaltitle = {European Heart Journal},
  shortjournal = {Eur Heart J},
  volume = {37},
  number = {36},
  eprint = {27567406},
  eprinttype = {pmid},
  pages = {2768--2801},
  issn = {1522-9645},
  doi = {10.1093/eurheartj/ehw211},
  langid = {english},
  keywords = {Advisory Committees,Antineoplastic Agents,arrhythmias,Cancer Survivors,cancer therapy,cardio-oncology,Cardiology,cardiotoxicity,Cardiotoxicity,chemotherapy,early detection,European Society of Cardiology,Humans,Immunotherapy,ischaemia,myocardial dysfunction,Neoplasms,Radiotherapy,{Societies, Medical},surveillance,Vascular Endothelial Growth Factor A},
  file = {C:\Users\sdp490\Zotero\storage\RWCM2YZZ\Zamorano et al. - 2016 - 2016 ESC Position Paper on cancer treatments and c.pdf}
}

@article{zhaoDeep2020,
  title = {Deep {{Neural Networks}} for {{Survival Analysis Using Pseudo Values}}},
  author = {Zhao, Lili and Feng, Dai},
  date = {2020-11},
  journaltitle = {IEEE Journal of Biomedical and Health Informatics},
  volume = {24},
  number = {11},
  pages = {3308--3314},
  issn = {2168-2208},
  doi = {10.1109/JBHI.2020.2980204},
  abstract = {There has been increasing interest in modelling survival data using deep learning methods in medical research. Current approaches have focused on designing special cost functions to handle censored survival data. We propose a very different method with two simple steps. In the first step, we transform each subject's survival time into a series of jackknife pseudo conditional survival probabilities and then use these pseudo probabilities as a quantitative response variable in the deep neural network model. By using the pseudo values, we reduce a complex survival analysis to a standard regression problem, which greatly simplifies the neural network construction. Our two-step approach is simple, yet very flexible in making risk predictions for survival data, which is very appealing from the practice point of view. The source code is freely available at http://github.com/lilizhaoUM/DNNSurv.},
  eventtitle = {{{IEEE Journal}} of {{Biomedical}} and {{Health Informatics}}},
  keywords = {Adaptation models,Analytical models,Biological system modeling,Data models,Deep learning,Hazards,Informatics,IPCW,neural network,Neural networks,pseudo probability,risk prediction,survival outcome},
  file = {C\:\\Users\\sdp490\\Zotero\\storage\\UBZ94MHZ\\Zhao and Feng - 2020 - Deep Neural Networks for Survival Analysis Using P.pdf;C\:\\Users\\sdp490\\Zotero\\storage\\AD7MIKBS\\9034100.html}
}

@article{zhengGallstones2016,
  title = {Gallstones and {{Risk}} of {{Coronary Heart Disease}}},
  author = {Zheng, Yan and Xu, Min and Li, Yanping and Hruby, Adela and Rimm, Eric B. and Hu, Frank B. and Wirth, Janine and Albert, Christine M. and Rexrode, Kathryn M. and Manson, JoAnn E. and Qi, Lu},
  date = {2016-09},
  journaltitle = {Arteriosclerosis, Thrombosis, and Vascular Biology},
  volume = {36},
  number = {9},
  pages = {1997--2003},
  publisher = {{American Heart Association}},
  doi = {10.1161/ATVBAHA.116.307507},
  url = {https://www.ahajournals.org/doi/full/10.1161/ATVBAHA.116.307507},
  urldate = {2023-12-06},
  abstract = {Objective— Gallstone disease has been related to cardiovascular risk factors; however, whether presence of gallstones predicts coronary heart disease (CHD) is not well established. Approach and Results— We followed up 269\,142 participants who were free of cancer and cardiovascular disease at baseline from 3 US cohorts: the Nurses’ Health Study (112\,520 women; 1980–2010), Nurses’ Health Study II (112\,919 women; 1989–2011), and the Health Professionals Follow-up Study (43\,703 men; 1986–2010) and documented 21\,265 incident CHD cases. After adjustment for potential confounders, the hazard ratio for the participants with a history of gallstone disease compared with those without was 1.15 (95\% confidence interval, 1.10−1.21) in Nurses’ Health Study, 1.33 (95\% confidence interval, 1.17−1.51) in Nurses’ Health Study II, and 1.11 (95\% confidence interval, 1.04−1.20) in Health Professionals Follow-up Study. The associations seemed to be stronger in individuals who were not obese, not diabetic, or were normotensive, compared with their counterparts. We identified 4 published prospective studies by searching PUBMED and EMBASE up to October 2015, coupled with our 3 cohorts, involving 842\,553 participants and 51\,123 incident CHD cases. The results from meta-analysis revealed that a history of gallstone disease was associated with a 23\% (15\%–33\%) increased CHD risk. Conclusion— Our findings support that a history of gallstone disease is associated with increased CHD risk, independently of traditional risk factors.},
  keywords = {adult,bile,cohort study,coronary disease,gallstones},
  file = {C:\Users\sdp490\Zotero\storage\E9VVIFDX\Zheng et al. - 2016 - Gallstones and Risk of Coronary Heart Disease.pdf}
}
